{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPython 2.7.6\n",
      "IPython 5.2.2\n",
      "\n",
      "tensorflow 1.0.0\n",
      "numpy 1.12.0\n",
      "\n",
      "compiler   : GCC 4.8.4\n",
      "system     : Linux\n",
      "release    : 4.4.43-boot2docker\n",
      "machine    : x86_64\n",
      "processor  : x86_64\n",
      "CPU cores  : 1\n",
      "interpreter: 64bit\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -p tensorflow,numpy -v -m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import jieba\n",
    "from jieba import posseg as pseg\n",
    "from collections import defaultdict, Counter\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "NEG = 'N'\n",
    "POS = 'P'\n",
    "\n",
    "train_files = {}\n",
    "train_files[NEG] = 'neg_train.txt'\n",
    "train_files[POS] = 'pos_train.txt'\n",
    "\n",
    "test_files = {}\n",
    "test_files[NEG] = 'neg_test.txt'\n",
    "test_files[POS] = 'pos_test.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#读取文件，分词\n",
    "def load_file(file_name, line_num=0):\n",
    "    f = open(file_name, 'r')    \n",
    "    lines = f.readlines()\n",
    "    cnt = len(lines)\n",
    "    if line_num >0:\n",
    "        cnt = line_num\n",
    "    f.close()\n",
    "    segs = []\n",
    "    seg_lines = []\n",
    "    for line in lines[:cnt]:\n",
    "        line = line.strip()\n",
    "        words = pseg.cut(line)\n",
    "        seg_per_line = []\n",
    "        for (key, flag) in words:\n",
    "            if flag == 'x':\n",
    "                continue           \n",
    "            segs.append(key)\n",
    "            seg_per_line.append(key)\n",
    "        seg_lines.append(seg_per_line)\n",
    "    return segs, seg_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def load_train_dataset(input_data, line_num=0):\n",
    "    segs = {}\n",
    "    seg_lines = {}\n",
    "    for k, v in input_data.items():\n",
    "         segs[k], seg_lines[k] = load_file(v, line_num)\n",
    "    return segs, seg_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.317 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146.058840036\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "segs_dict, seg_lines_dict = load_train_dataset(train_files)\n",
    "\n",
    "t1 = time.time()\n",
    "print(t1-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "449708\n",
      "508469\n",
      "13003\n",
      "11583\n"
     ]
    }
   ],
   "source": [
    "print(len(segs_dict[NEG]))\n",
    "print(len(segs_dict[POS]))\n",
    "print(len(seg_lines_dict[NEG]))\n",
    "print(len(seg_lines_dict[POS]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "UNKNOWN_WORD = u'UNK'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#建立vocabulary dict\n",
    "def build_word_dict(input_segs):\n",
    "    all_segs = []\n",
    "    temp = []\n",
    "    for (k, v) in input_segs.items():\n",
    "        all_segs.extend(v)\n",
    "    word_cnt = Counter(all_segs)\n",
    "    word_dict = {}\n",
    "    word_dict[UNKNOWN_WORD] = 0\n",
    "    index_dict = {}\n",
    "    index_dict[0] = UNKNOWN_WORD\n",
    "    i = 1\n",
    "    for (k, v) in word_cnt.most_common()[:4999]:\n",
    "        word_dict[k] = i\n",
    "        index_dict[i] = k\n",
    "        i += 1\n",
    "    return word_dict, index_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "all_word_dict, all_index_dict = build_word_dict(segs_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#把语句转换为词索引\n",
    "def build_line_data(lines, word_dict, isTestdata=False):\n",
    "    lines_index = {}\n",
    "    labels_index = {}\n",
    "    i = 0\n",
    "    max_len = 0\n",
    "    for (k,v) in lines.items():\n",
    "        label = 0\n",
    "        if (k==POS):\n",
    "            label = 1\n",
    "        for line in v:\n",
    "            seg_index = []\n",
    "            labels_index[i] = label            \n",
    "            for word in line:\n",
    "                if isTestdata:                    \n",
    "                    if word in word_dict.keys():\n",
    "                        seg_index.append(word_dict[word])\n",
    "                    else:\n",
    "                        seg_index.append(0)\n",
    "                else:\n",
    "                    seg_index.append(word_dict[word])\n",
    "            lines_index[i] = seg_index\n",
    "            if (max_len < len(seg_index)):\n",
    "                max_len = len(seg_index)                \n",
    "            i+=1\n",
    "    return max_len, lines_index, labels_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "max_sentence_len, train_sentences, train_labels = build_line_data(seg_lines_dict, all_word_dict, True)\n",
    "t1 = time.time()\n",
    "print(t1-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1479\n",
      "24586\n",
      "24586\n",
      "19568\n",
      "5018\n",
      "20.4099894249\n"
     ]
    }
   ],
   "source": [
    "print(max_sentence_len)\n",
    "print(len(train_sentences))\n",
    "print(len(train_labels))\n",
    "\n",
    "i=0\n",
    "#句子长度设为60，训练语料中80%句子长度小于60\n",
    "SENTENCE_LEN=60\n",
    "\n",
    "for (k,s) in train_sentences.items():\n",
    "    \n",
    "    if len(s)<=SENTENCE_LEN:\n",
    "        i+=1\n",
    "\n",
    "total_sentence = len(train_sentences)\n",
    "print i\n",
    "outsider = total_sentence - i\n",
    "print outsider\n",
    "print 100.0 * outsider / total_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#把每行语料变成固定长度，短句后面补未命中词，长句直接截断\n",
    "def build_input_train_data(sentences, max_len):\n",
    "    input_ = {}\n",
    "    for (k,v) in sentences.items():\n",
    "        input_[k] = v[:max_len]\n",
    "        if (len(v) < max_len):\n",
    "            padding = [0] *(max_len-len(v))\n",
    "            input_[k].extend(padding)\n",
    "    return input_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "input_train_data = build_input_train_data(train_sentences, SENTENCE_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.3838391304\n"
     ]
    }
   ],
   "source": [
    "#读入测试语料\n",
    "t0 = time.time()\n",
    "test_segs, test_lines = load_train_dataset(test_files,1000)\n",
    "t1 = time.time()\n",
    "print(t1-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.48693609238\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "s_len, test_sentences, test_labels = build_line_data(test_lines, all_word_dict,isTestdata=True)\n",
    "t1 = time.time()\n",
    "print(t1-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "692\n",
      "2000\n",
      "2000\n"
     ]
    }
   ],
   "source": [
    "print(s_len)\n",
    "print(len(test_sentences))\n",
    "print(len(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "input_test_data = build_input_train_data(test_sentences, SENTENCE_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(all_word_dict)\n",
    "word_embed_size = 64\n",
    "\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#将label变成one-hot matrix格式\n",
    "def get_label_matrix(input_label, num_l):\n",
    "    out_ = []\n",
    "    for label in input_label:\n",
    "        line = [0] * num_l\n",
    "        line[label] = 1\n",
    "        out_.append(line)    \n",
    "    return out_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_all_test_data(data, labels):\n",
    "    output_ = []\n",
    "    labels_ = []\n",
    "    for (k,v) in data.items():\n",
    "        output_.append(v)\n",
    "    for (k,v) in labels.items():\n",
    "        labels_.append(v)\n",
    "    return output_, get_label_matrix(labels_, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def shuffle_data(input_data, input_labels):\n",
    "    output_data = []\n",
    "    for (index,v) in input_data.items():\n",
    "        label = input_labels[index]\n",
    "        output_data.append((index, label, v))\n",
    "    np.random.shuffle(output_data)\n",
    "    return output_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24586\n",
      "2000\n"
     ]
    }
   ],
   "source": [
    "#对输入数据作shuffle处理\n",
    "shuffled_train_data = shuffle_data(input_train_data, train_labels)\n",
    "shuffled_test_data = shuffle_data(input_test_data, test_labels)\n",
    "\n",
    "print(len(shuffled_train_data))\n",
    "print(len(shuffled_test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#获取单批训练/测试数据\n",
    "def get_batch_data(input_data, index, size, num_l):\n",
    "    data_ = []\n",
    "    labels_ = []\n",
    "    indexs_ = []\n",
    "    for (i, k,v) in input_data[index:index+size]:\n",
    "        data_.append(v)\n",
    "        labels_.append(k)\n",
    "        indexs_.append(i)\n",
    "    return indexs_, data_, get_label_matrix(labels_, num_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def accuracy(predictions, labels):\n",
    "      return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1))\n",
    "          / predictions.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"input_data:0\", shape=(?, 60), dtype=int32)\n",
      "Tensor(\"labels:0\", shape=(?, 2), dtype=int32)\n",
      "Tensor(\"embedding_lookup:0\", shape=(?, 60, 64), dtype=float32)\n",
      "Tensor(\"ExpandDims:0\", shape=(?, 60, 64, 1), dtype=float32)\n",
      "Tensor(\"conv:0\", shape=(?, 58, 1, 64), dtype=float32)\n",
      "Tensor(\"pool:0\", shape=(?, 1, 1, 64), dtype=float32)\n",
      "Tensor(\"dense/Tanh:0\", shape=(?, 1, 1, 10), dtype=float32)\n",
      "Tensor(\"output/Reshape_1:0\", shape=(?, 1, 1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "graph = tf.Graph()\n",
    "sentence_length = SENTENCE_LEN\n",
    "# max_pool\n",
    "with graph.as_default():\n",
    "    filter_num = 64\n",
    "    window_size = 3\n",
    "    num_labels = 2\n",
    "    num_fc_hidden = 10\n",
    "    \n",
    "    tf_input_data = tf.placeholder(tf.int32, shape=[None, sentence_length], name='input_data')    \n",
    "    tf_labels = tf.placeholder(tf.int32, shape=[None, num_labels], name='labels')\n",
    "    \n",
    "    word_embeds = tf.Variable(tf.random_uniform([vocab_size, word_embed_size], -1.0, 1.0), name=\"Word_embed\")\n",
    "    input_embeds = tf.nn.embedding_lookup(word_embeds, tf_input_data)\n",
    "   \n",
    "    tf_embeds_expand = tf.expand_dims(input_embeds, -1)\n",
    "    \n",
    "    print(tf_input_data)\n",
    "    print(tf_labels)\n",
    "    print(input_embeds)\n",
    "    print(tf_embeds_expand)\n",
    "\n",
    "    filter_shape = [window_size, word_embed_size, 1, filter_num]\n",
    "    # W 和 b 是卷积的参数\n",
    "    W = tf.Variable(tf.random_uniform(filter_shape, -1.0, 1.0), name=\"W\")\n",
    "    # bias 和 filter_num 个数是一样的\n",
    "    b = tf.Variable(tf.constant(0.0, shape=[filter_num]), name=\"b\")\n",
    "    # 步长为1，这里不做 Padding，因此句子太短的话可能要丢掉。可自行尝试加 padding（不加也不影响作业评分）\n",
    "    conv = tf.nn.conv2d(\n",
    "                    tf_embeds_expand,\n",
    "                    W,\n",
    "                    strides=[1, 1, 1, 1],\n",
    "                    padding=\"VALID\",\n",
    "                    name=\"conv\")\n",
    "    # 卷积出来的结果加上 bias\n",
    "    conv_hidden = tf.nn.tanh(tf.add(conv, b), name=\"tanh\")\n",
    "    \n",
    "    print(conv)\n",
    "\n",
    "    # 因为没有 padding，出来的结果个数是 sequence_length - window_size + 1，如果加了 padding 这里要对应更改。\n",
    "    pool = tf.nn.max_pool(\n",
    "                    conv_hidden,\n",
    "                    ksize=[1, sentence_length - window_size + 1, 1, 1],\n",
    "                    strides=[1, 1, 1, 1],\n",
    "                    padding='VALID',\n",
    "                    name=\"pool\")\n",
    "    \n",
    "    print(pool)\n",
    "    \n",
    "    #增加一个全连接层\n",
    "    fc = tf.layers.dense(pool, num_fc_hidden, activation=tf.nn.tanh)\n",
    "    \n",
    "    print(fc)\n",
    "   \n",
    "    raw_output = tf.layers.dense(fc, num_labels, name='output')\n",
    "    print(raw_output)\n",
    "    \n",
    "    \n",
    "    cost = tf.nn.softmax_cross_entropy_with_logits(logits=raw_output, labels=tf_labels)\n",
    "    \n",
    "    cost_summary = tf.summary.scalar('cost', tf.reduce_mean(cost))\n",
    "    embed_summary = tf.summary.histogram('embed',input_embeds)\n",
    "    merged = tf.summary.merge_all()\n",
    "\n",
    "    train_step = tf.train.GradientDescentOptimizer(0.005).minimize(cost)\n",
    "    \n",
    "    tf_prediction = tf.nn.softmax(raw_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "writer = tf.summary.FileWriter(\"/root/log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def train_model(num_epoch, batch_size_num):\n",
    "    num_labels = 2\n",
    "    total_train_batch = len(shuffled_train_data) / batch_size_num\n",
    "    if len(input_train_data) % batch_size_num > 0:\n",
    "        total_train_batch += 1\n",
    "   \n",
    "    total_test_batch = len(shuffled_test_data) / batch_size_num\n",
    "    if len(shuffled_test_data) % batch_size_num > 0:\n",
    "        total_test_batch += 1\n",
    "  \n",
    "    with tf.Session(graph=graph) as session:\n",
    "        tf.global_variables_initializer().run()\n",
    "       \n",
    "        train_start = time.time()\n",
    "        costs = []\n",
    "        for epoch in range(num_epoch):\n",
    "            start_index = 0\n",
    "\n",
    "            train_acc = []\n",
    "            for i in range(total_train_batch):            \n",
    "                batch_index, batch_data, batch_labels = get_batch_data(shuffled_train_data, start_index, batch_size_num, num_labels)\n",
    "\n",
    "                start_index += batch_size_num\n",
    "\n",
    "                feed_dict = {tf_input_data : batch_data, tf_labels : batch_labels}\n",
    "                _, c, predictions = session.run(\n",
    "                  [train_step, cost, tf_prediction], feed_dict=feed_dict)\n",
    "\n",
    "                acc = accuracy(np.reshape(predictions,[len(batch_labels),num_labels]), batch_labels)\n",
    "                train_acc.append(np.mean(acc))\n",
    "                \n",
    "            costs.append(np.mean(c))\n",
    "\n",
    "        train_end = time.time()\n",
    "        duration = (train_end - train_start)\n",
    "        \n",
    "        print(\"Batch size=%d\" % batch_size_num)\n",
    "        print(\"Epoches=%d\" % num_epoch)\n",
    "        print(\"Training duration=%.2f\" % duration)\n",
    "        print(\"Training accuracy=%.2f\" % train_acc[-1])\n",
    "        print(\"Training cost=%.2f\" % costs[-1])\n",
    "        \n",
    "        return duration, train_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size=125\n",
      "Epoches=1\n",
      "Training duration=11.06\n",
      "Training accuracy=59.30\n",
      "Training cost=0.69\n"
     ]
    }
   ],
   "source": [
    "t0, acc0 =  train_model(1, 125)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size=1\n",
      "Epoches=1\n",
      "Training duration=29.12\n",
      "Training accuracy=100.00\n",
      "Training cost=0.59\n"
     ]
    }
   ],
   "source": [
    "t0, acc0 =  train_model(1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size=125\n",
      "Epoches=10\n",
      "Training duration=109.45\n",
      "Training accuracy=59.30\n",
      "Training cost=0.71\n"
     ]
    }
   ],
   "source": [
    "t0, acc0 =  train_model(10, 125)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size=1\n",
      "Epoches=10\n",
      "Training duration=311.88\n",
      "Training accuracy=100.00\n",
      "Training cost=0.63\n"
     ]
    }
   ],
   "source": [
    "t0, acc0 =  train_model(10, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Summary\n",
    "\n",
    "             Epoches=1  Epoches=10\n",
    "Batch size = 1     29       312\n",
    "Batch size = 125    11       109\n",
    "\n",
    "其他数据不变的情况下，Batch size从1改成125，训练时间可以节约65%左右"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
