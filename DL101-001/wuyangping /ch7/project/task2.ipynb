{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPython 2.7.6\n",
      "IPython 5.2.2\n",
      "\n",
      "tensorflow 1.0.0\n",
      "numpy 1.12.0\n",
      "\n",
      "compiler   : GCC 4.8.4\n",
      "system     : Linux\n",
      "release    : 4.4.43-boot2docker\n",
      "machine    : x86_64\n",
      "processor  : x86_64\n",
      "CPU cores  : 1\n",
      "interpreter: 64bit\n"
     ]
    }
   ],
   "source": [
    "# 示例代码运行环境\n",
    "%load_ext watermark\n",
    "%watermark -p tensorflow,numpy -v -m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.contrib.legacy_seq2seq import basic_rnn_seq2seq, embedding_rnn_seq2seq, sequence_loss\n",
    "from tensorflow.python.ops import variable_scope\n",
    "import jieba\n",
    "from jieba import posseg as pseg\n",
    "from collections import defaultdict, Counter\n",
    "import random\n",
    "import time\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "FILE_TRAIN_EN = 'TED_en_train.txt'\n",
    "FILE_TRAIN_ZH = 'TED_zh_train.txt'\n",
    "FILE_TEST_EN = 'TED_en_test.txt'\n",
    "FILE_TEST_ZH = 'TED_zh_test.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#读取英文语料，分词\n",
    "def load_en_file(file_name):\n",
    "    with open(file_name, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        words_all = []\n",
    "        lines_dict = []\n",
    "        for line in lines:\n",
    "            try:\n",
    "                words = nltk.tokenize.word_tokenize(line.strip())   \n",
    "            except:\n",
    "                #处理训练语料中的非assii字符，替换后再分词\n",
    "                #print line\n",
    "                new_line = re.sub(r'\\xa1\\xaf', '\\'', line.strip())\n",
    "                #print new_line\n",
    "                words = nltk.tokenize.word_tokenize(new_line.strip())            \n",
    "                \n",
    "            words_all += words\n",
    "            lines_dict.append(words)\n",
    "        return words_all, lines_dict\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.03207087517\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "words_test_en, lines_test_en = load_en_file(FILE_TEST_EN)\n",
    "t1 = time.time()\n",
    "print(t1-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36.3412718773\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "words_train_en, lines_train_en = load_en_file(FILE_TRAIN_EN)\n",
    "t1 = time.time()\n",
    "print(t1-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2694428\n",
      "300000\n",
      "54059\n",
      "['My', 'TED', 'wish', '.', 'There', \"'s\", 'a', 'vital', 'story', 'that', 'needs', 'to', 'be', 'told']\n",
      "['It', 'can', 'be', 'a', 'very', 'complicated', 'thing', ',', 'the', 'ocean']\n",
      "[['It', 'can', 'be', 'a', 'very', 'complicated', 'thing', ',', 'the', 'ocean', '.'], ['And', 'it', 'can', 'be', 'a', 'very', 'complicated', 'thing', ',', 'what', 'human', 'health', 'is', '.'], ['And', 'bringing', 'those', 'two', 'together', 'might', 'seem', 'a', 'very', 'daunting', 'task', ',']]\n"
     ]
    }
   ],
   "source": [
    "print(len(words_train_en))\n",
    "print(len(lines_train_en))\n",
    "\n",
    "total_en_words = Counter(words_train_en)\n",
    "print(len(total_en_words))\n",
    "\n",
    "print lines_train_en[81988]\n",
    "\n",
    "print words_train_en[:10]\n",
    "print lines_train_en[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130471\n",
      "14872\n",
      "['We', 'could', 'use', 'sales', ',', 'anything', 'you', 'like', '.', 'There']\n",
      "[['We', 'could', 'use', 'sales', ',', 'anything', 'you', 'like', '.'], ['There', 'it', 'is', ':', 'after', 'some', 'little', 'fluctuations', 'at', 'the', 'beginning', ',']]\n"
     ]
    }
   ],
   "source": [
    "print(len(words_test_en))\n",
    "print(len(lines_test_en))\n",
    "\n",
    "print words_test_en[:10]\n",
    "print lines_test_en[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def load_zh_file(file_name):\n",
    "    with open(file_name, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        words_all = []\n",
    "        lines_dict = []        \n",
    "        for line in lines:\n",
    "            words = [w for (w,x) in pseg.cut(line.strip().decode('utf-8'))]\n",
    "            words_all += words\n",
    "            lines_dict.append(words)\n",
    "        return words_all, lines_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.350 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.6360740662\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "words_test_zh, lines_test_zh = load_zh_file(FILE_TEST_ZH)\n",
    "t1 = time.time()\n",
    "print(t1-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115659\n",
      "14872\n",
      "我们 还 可以 用 销售量   什么 都行\n",
      "看   当 公司 进行 革新\n"
     ]
    }
   ],
   "source": [
    "print(len(words_test_zh))\n",
    "print(len(lines_test_zh))\n",
    "\n",
    "for l in lines_test_zh[:2]:\n",
    "    text = ' '.join(l)\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202.379176855\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "words_train_zh, lines_train_zh = load_zh_file(FILE_TRAIN_ZH)\n",
    "t1 = time.time()\n",
    "print(t1-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2450264\n",
      "300000\n",
      "67317\n",
      "海洋 是 一个 非常复杂 的 事物 。\n",
      "人类 的 健康 也 是 一件 非常复杂 的 事情 。\n"
     ]
    }
   ],
   "source": [
    "print(len(words_train_zh))\n",
    "print(len(lines_train_zh))\n",
    "\n",
    "total_zh_words = Counter(words_train_zh)\n",
    "print(len(total_zh_words))\n",
    "\n",
    "for l in lines_train_zh[:2]:\n",
    "    text = ' '.join(l)\n",
    "    print(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "UNK_WORD = u'<UNK>'\n",
    "PADDING_WORD = u'<PAD>'\n",
    "START_WORD = u'<GO>'\n",
    "END_WORD = u'<EOS>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def build_dataset(segs, sentences, vocab_size, is_decoder=False):    \n",
    "    word_cnt = Counter(segs).most_common(vocab_size - 4)    \n",
    "    word_dict = dict()  \n",
    "    word_dict[PADDING_WORD] = 0 \n",
    "    for word, _ in word_cnt:\n",
    "        word_dict[word] = len(word_dict)    \n",
    "    word_dict[UNK_WORD] = len(word_dict)\n",
    "    word_dict[START_WORD] = len(word_dict)\n",
    "    word_dict[END_WORD] = len(word_dict)\n",
    "    sentence_data = []\n",
    "    unk_count = 0\n",
    "    for sentence in sentences:\n",
    "        cur_sentence = []\n",
    "        if is_decoder:\n",
    "            cur_sentence.append(word_dict[START_WORD])\n",
    "        for word in sentence:\n",
    "            if word in word_dict:\n",
    "                index = word_dict[word]\n",
    "            else:\n",
    "                index = word_dict[UNK_WORD]  # UNK_WORD\n",
    "                unk_count += 1\n",
    "            cur_sentence.append(index)\n",
    "        if is_decoder:\n",
    "            cur_sentence.append(word_dict[END_WORD])\n",
    "        sentence_data.append(cur_sentence)    \n",
    "    reverse_dict = dict(zip(word_dict.values(), word_dict.keys())) \n",
    "    return sentence_data, word_cnt, word_dict, reverse_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def build_test_dataset(sentences, word_dict, id_dict, is_decoder=False):\n",
    "    sentence_data = []\n",
    "    for sentence in sentences:\n",
    "        cur_sentence = []\n",
    "        for word in sentence:\n",
    "            if word in word_dict:\n",
    "                index = word_dict[word]\n",
    "            else:\n",
    "                index = word_dict[UNK_WORD]  # UNK_WORD\n",
    "            cur_sentence.append(index)\n",
    "        if is_decoder:\n",
    "            cur_sentence = word_dict[START_WORD] + cur_sentence + word_dict[END_WORD]\n",
    "        sentence_data.append(cur_sentence)    \n",
    "    reverse_dict = dict(zip(word_dict.values(), word_dict.keys())) \n",
    "    return sentence_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "EN_VOCAB_SIZE = 10000\n",
    "ZH_VOCAB_SIZE = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.74033594131\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "train_en_sentences, train_en_word_count, train_en_dict, train_en_reverse_dict = build_dataset(words_train_en, lines_train_en, EN_VOCAB_SIZE)\n",
    "t1 = time.time()\n",
    "print(t1-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300000\n",
      "9996\n",
      "10000\n",
      "10000\n",
      "[[40, 32, 33, 6, 51, 942, 114, 1, 3, 553, 2], [16, 13, 32, 33, 6, 51, 942, 114, 1, 30, 182, 425, 11, 2], [16, 1454, 124, 119, 220, 213, 754, 6, 51, 9165, 1414, 1]]\n",
      "(',', 156395)\n",
      "('.', 137284)\n",
      "('the', 104573)\n",
      "('to', 64287)\n",
      "('of', 60913)\n",
      "('learner', 10)\n",
      "('Fall', 10)\n",
      "('criticize', 10)\n",
      "('rationality', 10)\n",
      "('lifestyles', 10)\n"
     ]
    }
   ],
   "source": [
    "print(len(train_en_sentences))\n",
    "print(len(train_en_word_count))\n",
    "print(len(train_en_dict))\n",
    "print(len(train_en_reverse_dict))\n",
    "\n",
    "print(train_en_sentences[:3])\n",
    "\n",
    "for (w,v) in train_en_word_count[:5]:\n",
    "    print(w,v)\n",
    "for (w,v) in train_en_word_count[-5:]:\n",
    "    print(w,v)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.90747404099\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "train_zh_sentences, train_zh_word_count, train_zh_dict, train_zh_reverse_dict = build_dataset(\n",
    "    words_train_zh, lines_train_zh, ZH_VOCAB_SIZE, is_decoder=True)\n",
    "t1 = time.time()\n",
    "print(t1-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.1675466667\n",
      "104514\n",
      "56\n",
      "[9998, 7450, 12, 9997, 65, 12, 9997, 12, 9997, 38, 9997, 9997, 9997, 37, 65, 12, 9997, 12, 9997, 38, 9997, 626, 15, 953, 2626, 5176, 37, 38, 10, 229, 22, 20, 1973, 142, 2957, 1963, 760, 9997, 1, 626, 100, 1155, 9997, 37, 2, 9997, 984, 220, 30, 1806, 14, 7, 292, 341, 60, 9999]\n",
      "<GO> Al   <UNK> ,   <UNK>   <UNK> （ <UNK> <UNK> <UNK> ） ,   <UNK>   <UNK> （ <UNK> 能源 和 商业 委员会 主席 ） （ 这 两个 人 都 致力于 通过 国会 推动 一项 <UNK> 的 能源 与 气候 <UNK> ） ， <UNK> 家伙 完全 不 懂得 他们 在 讲 些 什么 <EOS> \n"
     ]
    }
   ],
   "source": [
    "train_zh_len = []\n",
    "for s in train_zh_sentences:\n",
    "    train_zh_len.append(len(s))\n",
    "\n",
    "max_index = np.argmax(train_zh_len)\n",
    "print(np.mean(train_zh_len))\n",
    "print(max_index)\n",
    "print(len(train_zh_sentences[max_index]))\n",
    "print(train_zh_sentences[max_index])\n",
    "text = '';\n",
    "for i in train_zh_sentences[max_index]:\n",
    "    text += train_zh_reverse_dict[i] + ' '\n",
    "print text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.98142666667\n",
      "118160\n",
      "30\n",
      "[4940, 1, 3677, 1, 3677, 1, 3677, 1, 3677, 1, 3677, 1, 3677, 1, 3677, 1, 3677, 1, 3677, 1, 3677, 1, 3677, 1, 3677, 1, 3677, 1, 3677, 262]\n",
      "Ooh , ooh , ooh , ooh , ooh , ooh , ooh , ooh , ooh , ooh , ooh , ooh , ooh , ooh , ooh ! \n"
     ]
    }
   ],
   "source": [
    "train_en_len = []\n",
    "for s in train_en_sentences:\n",
    "    train_en_len.append(len(s))\n",
    "\n",
    "max_index = np.argmax(train_en_len)\n",
    "print(np.mean(train_en_len))\n",
    "print(max_index)\n",
    "print(len(train_en_sentences[max_index]))\n",
    "print(train_en_sentences[max_index])\n",
    "text = '';\n",
    "for i in train_en_sentences[max_index]:\n",
    "    text += train_en_reverse_dict[i] + ' '\n",
    "print text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300000\n",
      "9996\n",
      "10000\n",
      "10000\n",
      "[[9998, 515, 5, 11, 3671, 1, 409, 3, 9999], [9998, 154, 1, 438, 26, 5, 353, 3671, 1, 114, 3, 9999], [9998, 63, 1654, 2709, 201, 415, 5, 353, 6083, 1, 882, 3, 9999]]\n",
      "的 166966\n",
      "， 123108\n",
      "。 86019\n",
      "我 52326\n",
      "是 48229\n",
      "童子军 13\n",
      "前排 13\n",
      "偏向 13\n",
      "有件事 13\n",
      "夜 13\n"
     ]
    }
   ],
   "source": [
    "print(len(train_zh_sentences))\n",
    "print(len(train_zh_word_count))\n",
    "print(len(train_zh_dict))\n",
    "print(len(train_zh_reverse_dict))\n",
    "\n",
    "print(train_zh_sentences[:3])\n",
    "\n",
    "for (w,v) in train_zh_word_count[:5]:\n",
    "    print w,v\n",
    "for (w,v) in train_zh_word_count[-5:]:\n",
    "    print w,v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0541579723358\n",
      "14872\n",
      "[[53, 100, 164, 3225, 1, 314, 12, 42, 2], [138, 13, 11, 48, 194, 95, 115, 6594, 34, 3, 570, 1], [74, 682, 21, 9997, 1], [23, 636, 4326, 2], [16, 15, 81, 405, 34, 9997, 682]]\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "test_en_sentences = build_test_dataset(lines_test_en, train_en_dict, train_en_reverse_dict)\n",
    "t1 = time.time()\n",
    "print(t1-t0)\n",
    "\n",
    "print(len(test_en_sentences))\n",
    "print(test_en_sentences[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.056036233902\n",
      "14872\n",
      "[[6, 92, 23, 74, 9997, 12, 60, 7539], [120, 12, 70, 243, 176, 3329], [131, 77, 287, 5909, 9997], [67, 9997, 2350], [6, 530, 8, 9997, 772]]\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "test_zh_sentences = build_test_dataset(lines_test_zh, train_zh_dict, train_zh_reverse_dict)\n",
    "t1 = time.time()\n",
    "print(t1-t0)\n",
    "\n",
    "print(len(test_zh_sentences))\n",
    "print(test_zh_sentences[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "num_encoder_symbols = len(train_en_dict)\n",
    "num_decoder_symbols = len(train_zh_dict)\n",
    "embedding_size = 128\n",
    "\n",
    "print(num_encoder_symbols)\n",
    "print(num_decoder_symbols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def pad_sentence(data, length, pad_index, end_index, is_encode=True):\n",
    "    result_ = []\n",
    "    data_len = len(data)\n",
    "    if (data_len >= length):\n",
    "        result_ = data[:length] #长句做截断处理\n",
    "        if not is_encode:\n",
    "            result_[length-1] = end_index\n",
    "    else:\n",
    "        pad_len = length - data_len\n",
    "        padding = [pad_index] * pad_len\n",
    "        if is_encode:\n",
    "            result_ = padding + data\n",
    "        else:\n",
    "            result_ = data + padding\n",
    "    \n",
    "    return result_\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_batch_data(offset, size, input_data, output_data, input_len, output_len):\n",
    "    input_ = input_data[offset:offset + size]\n",
    "    output_ = output_data[offset:offset + size]    \n",
    "    \n",
    "    for i in range(len(input_)):\n",
    "        input_[i] = pad_sentence(input_[i], input_len, 0, EN_VOCAB_SIZE-1)\n",
    "        output_[i] = pad_sentence(output_[i], output_len, 0, ZH_VOCAB_SIZE-1, False)\n",
    "    return input_, output_   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#BasicRNNCell\n",
    "tf.reset_default_graph()\n",
    "\n",
    "RNN_CELL_TYPE = 'BasicRNNCell'\n",
    "learning_rate = 0.1\n",
    "\n",
    "encoder_length = 15\n",
    "decoder_length = 20\n",
    "embed_dim = 64\n",
    "\n",
    "cell = tf.contrib.rnn.BasicRNNCell(embed_dim)\n",
    "num_encoder_symbols = EN_VOCAB_SIZE\n",
    "num_decoder_symbols = ZH_VOCAB_SIZE\n",
    "embedding_size = embed_dim\n",
    "\n",
    "encoder_len_placeholder = tf.placeholder(tf.int32)\n",
    "\n",
    "encoder_placeholders = [tf.placeholder(tf.int32, shape=[None],\n",
    "                                       name=\"encoder_%d\" % i) for i in range(encoder_length)]\n",
    "decoder_placeholders = [tf.placeholder(tf.int32, shape=[None],\n",
    "                                       name=\"decoder_%d\" % i) for i in range(decoder_length)]\n",
    "target_placeholders = [tf.placeholder(tf.int32, shape=[None],\n",
    "                                       name=\"target_%d\" % i) for i in range(decoder_length)]\n",
    "target_weights_placeholders = [tf.placeholder(tf.float32, shape=[None],\n",
    "                                       name=\"decoder_weight_%d\" % i) for i in range(decoder_length)]\n",
    "outputs, states = embedding_rnn_seq2seq(\n",
    "    encoder_placeholders, decoder_placeholders, cell,\n",
    "    num_encoder_symbols, num_decoder_symbols,\n",
    "    embedding_size, output_projection=None,\n",
    "    feed_previous=False)\n",
    "\n",
    "loss = sequence_loss(outputs, target_placeholders, target_weights_placeholders)\n",
    "train_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#GRUCell\n",
    "tf.reset_default_graph()\n",
    "\n",
    "RNN_CELL_TYPE = 'GRUCell'\n",
    "learning_rate = 1.0\n",
    "\n",
    "encoder_length = 15\n",
    "decoder_length = 20\n",
    "embed_dim = 64\n",
    "\n",
    "cell = tf.contrib.rnn.GRUCell(embed_dim)\n",
    "num_encoder_symbols = EN_VOCAB_SIZE\n",
    "num_decoder_symbols = ZH_VOCAB_SIZE\n",
    "embedding_size = embed_dim\n",
    "\n",
    "encoder_len_placeholder = tf.placeholder(tf.int32)\n",
    "\n",
    "encoder_placeholders = [tf.placeholder(tf.int32, shape=[None],\n",
    "                                       name=\"encoder_%d\" % i) for i in range(encoder_length)]\n",
    "decoder_placeholders = [tf.placeholder(tf.int32, shape=[None],\n",
    "                                       name=\"decoder_%d\" % i) for i in range(decoder_length)]\n",
    "target_placeholders = [tf.placeholder(tf.int32, shape=[None],\n",
    "                                       name=\"target_%d\" % i) for i in range(decoder_length)]\n",
    "target_weights_placeholders = [tf.placeholder(tf.float32, shape=[None],\n",
    "                                       name=\"decoder_weight_%d\" % i) for i in range(decoder_length)]\n",
    "outputs, states = embedding_rnn_seq2seq(\n",
    "    encoder_placeholders, decoder_placeholders, cell,\n",
    "    num_encoder_symbols, num_decoder_symbols,\n",
    "    embedding_size, output_projection=None,\n",
    "    feed_previous=False)\n",
    "\n",
    "loss = sequence_loss(outputs, target_placeholders, target_weights_placeholders)\n",
    "train_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def left_shift(decoder_inputs, pad_idx):\n",
    "    # for generating targets\n",
    "    return [list(input_[1:]) + [pad_idx] for input_ in decoder_inputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def generate_feed_dict(batch_encoder_inputs, batch_decoder_inputs, pad_index):\n",
    "    encoder_inputs_ = zip(*batch_encoder_inputs)  \n",
    "\n",
    "    target_inputs_ = zip(*left_shift(batch_decoder_inputs, pad_index))\n",
    "    decoder_inputs_ = zip(*batch_decoder_inputs)\n",
    "\n",
    "    feed_dict = dict()\n",
    "    # Prepare input data    \n",
    "    for (i, placeholder) in enumerate(encoder_placeholders):\n",
    "        # 这里用 placeholder 或者 placeholder.name 都可以\n",
    "        feed_dict[placeholder.name] = np.asarray(encoder_inputs_[i], dtype=int)\n",
    "        for i in range(len(decoder_placeholders)):\n",
    "            feed_dict[decoder_placeholders[i].name] = np.asarray(decoder_inputs_[i], dtype=int)\n",
    "            feed_dict[target_placeholders[i].name] = np.asarray(target_inputs_[i], dtype=int)        \n",
    "            # 这里使用 weights 把 <PAD> 的损失屏蔽了\n",
    "            feed_dict[target_weights_placeholders[i].name] = np.asarray([float(idx != pad_index) for idx in target_inputs_[i]],\n",
    "                                                              dtype=float)\n",
    "    return feed_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def print_translated_result(reverse_dict, output):\n",
    "    text = ''\n",
    "    for i in reverse_dict[output]:\n",
    "        text += i\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300000\n",
      "30\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "epoch_num = 100\n",
    "batch_size = 10\n",
    "sample_ratio = 1000 #为节约训练时间，只用 1/ Sample_ratio的样本数据训练\n",
    "\n",
    "train_data_size = len(train_en_sentences)\n",
    "iteration_num = train_data_size / batch_size / sample_ratio\n",
    "#if train_data_size % batch_size > 0:\n",
    "#    iteration_num += 1\n",
    "\n",
    "display_step = iteration_num / 3 \n",
    "\n",
    "print train_data_size\n",
    "print iteration_num\n",
    "print display_step\n",
    "\n",
    "\n",
    "pad_index = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training, Cell type=GRUCell, Learning rate=1.000000\n",
      "epoch 0, cost=6.116482\n",
      "epoch 1, cost=5.538084\n",
      "epoch 2, cost=5.447281\n",
      "epoch 3, cost=5.296375\n",
      "epoch 4, cost=5.137961\n",
      "epoch 5, cost=4.723701\n",
      "epoch 6, cost=4.531603\n",
      "epoch 7, cost=4.775733\n",
      "epoch 8, cost=4.334773\n",
      "epoch 9, cost=4.029653\n",
      "epoch 10, cost=3.850163\n",
      "epoch 11, cost=3.705874\n",
      "epoch 12, cost=3.582166\n",
      "epoch 13, cost=3.459566\n",
      "epoch 14, cost=3.343997\n",
      "epoch 15, cost=3.210530\n",
      "epoch 16, cost=3.086693\n",
      "epoch 17, cost=2.964902\n",
      "epoch 18, cost=2.849318\n",
      "epoch 19, cost=2.733878\n",
      "epoch 20, cost=2.649535\n",
      "epoch 21, cost=2.671373\n",
      "epoch 22, cost=2.435429\n",
      "epoch 23, cost=2.372858\n",
      "epoch 24, cost=2.226807\n",
      "epoch 25, cost=2.154705\n",
      "epoch 26, cost=2.043576\n",
      "epoch 27, cost=1.926313\n",
      "epoch 28, cost=1.800859\n",
      "epoch 29, cost=1.727226\n",
      "epoch 30, cost=1.628427\n",
      "epoch 31, cost=1.712189\n",
      "epoch 32, cost=1.462310\n",
      "epoch 33, cost=1.365443\n",
      "epoch 34, cost=1.280562\n",
      "epoch 35, cost=1.234641\n",
      "epoch 36, cost=1.150338\n",
      "epoch 37, cost=1.076319\n",
      "epoch 38, cost=1.009145\n",
      "epoch 39, cost=1.020094\n",
      "epoch 40, cost=0.914622\n",
      "epoch 41, cost=0.848540\n",
      "epoch 42, cost=0.824123\n",
      "epoch 43, cost=0.774470\n",
      "epoch 44, cost=0.707678\n",
      "epoch 45, cost=0.685417\n",
      "epoch 46, cost=0.632513\n",
      "epoch 47, cost=0.598449\n",
      "epoch 48, cost=0.575731\n",
      "epoch 49, cost=0.536982\n",
      "epoch 50, cost=0.509466\n",
      "epoch 51, cost=0.478691\n",
      "epoch 52, cost=0.460087\n",
      "epoch 53, cost=0.453597\n",
      "epoch 54, cost=0.439575\n",
      "epoch 55, cost=0.408057\n",
      "epoch 56, cost=0.385083\n",
      "epoch 57, cost=0.370435\n",
      "epoch 58, cost=0.358259\n",
      "epoch 59, cost=0.344208\n",
      "epoch 60, cost=0.331171\n",
      "epoch 61, cost=0.315933\n",
      "epoch 62, cost=0.302115\n",
      "epoch 63, cost=0.290628\n",
      "epoch 64, cost=0.293803\n",
      "epoch 65, cost=0.311931\n",
      "epoch 66, cost=0.316120\n",
      "epoch 67, cost=0.275713\n",
      "epoch 68, cost=0.246358\n",
      "epoch 69, cost=0.242127\n",
      "epoch 70, cost=0.246156\n",
      "epoch 71, cost=0.233730\n",
      "epoch 72, cost=0.231894\n",
      "epoch 73, cost=0.223384\n",
      "epoch 74, cost=0.206378\n",
      "epoch 75, cost=0.195428\n",
      "epoch 76, cost=0.190508\n",
      "epoch 77, cost=0.187087\n",
      "epoch 78, cost=0.188985\n",
      "epoch 79, cost=0.192145\n",
      "epoch 80, cost=0.197767\n",
      "epoch 81, cost=0.193155\n",
      "epoch 82, cost=0.178672\n",
      "epoch 83, cost=0.161486\n",
      "epoch 84, cost=0.149593\n",
      "epoch 85, cost=0.143994\n",
      "epoch 86, cost=0.139921\n",
      "epoch 87, cost=0.136261\n",
      "epoch 88, cost=0.132803\n",
      "epoch 89, cost=0.129546\n",
      "epoch 90, cost=0.126594\n",
      "epoch 91, cost=0.123577\n",
      "epoch 92, cost=0.120600\n",
      "epoch 93, cost=0.117618\n",
      "epoch 94, cost=0.114896\n",
      "epoch 95, cost=0.112226\n",
      "epoch 96, cost=0.109662\n",
      "epoch 97, cost=0.107241\n",
      "epoch 98, cost=0.104905\n",
      "epoch 99, cost=0.102647\n",
      "Training duration:839\n",
      "Modeled saved to: GRUCell_model\n"
     ]
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "sess = tf.Session()\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "print(\"Start training, Cell type=%s, Learning rate=%f\" % (RNN_CELL_TYPE, learning_rate))\n",
    "\n",
    "costs = []\n",
    "t0 = time.time()\n",
    "for epoch in range(epoch_num):\n",
    "    #print(\"Start epoch %d\" % epoch)\n",
    "        \n",
    "    offset = 0\n",
    "    #iteration_num = 1\n",
    "    for i in range(iteration_num):            \n",
    "        encoder_inputs, decoder_inputs = get_batch_data(\n",
    "            offset, batch_size, \n",
    "            train_en_sentences, train_zh_sentences, \n",
    "            encoder_length, decoder_length)\n",
    "        offset += batch_size\n",
    "\n",
    "        feed_dict1 = generate_feed_dict(encoder_inputs, decoder_inputs, pad_index)\n",
    "\n",
    "        sess.run(train_step, feed_dict1)\n",
    "        \n",
    "        #if i % display_step == 0:\n",
    "        #    print(\"%d, %f\" % (i, sess.run(loss, feed_dict1)))\n",
    "    c = sess.run(loss, feed_dict1)\n",
    "    costs.append(c)\n",
    "    print(\"epoch %d, cost=%f\" %(epoch, c))\n",
    "            \n",
    "\n",
    "t1 = time.time()\n",
    "print(\"Training duration:%d\" % (t1-t0))\n",
    "\n",
    "saved_model = saver.save(sess, RNN_CELL_TYPE+'_model')\n",
    "print(\"Modeled saved to: %s\" % saved_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f0761992b10>]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAD8CAYAAABXe05zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nglFxi4gkmP8PWzd5pynPimMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f075fe1ffd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(len(costs))\n",
    "plt.plot(costs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def decode_data(session, offset, size, encode_input, decode_input):\n",
    "    # Decoding\n",
    "    with variable_scope.variable_scope(variable_scope.get_variable_scope(), reuse=True):\n",
    "        outputs, states = embedding_rnn_seq2seq(\n",
    "             encoder_placeholders, decoder_placeholders, cell,\n",
    "            num_encoder_symbols, num_decoder_symbols,\n",
    "            embedding_size, output_projection=None,\n",
    "            feed_previous=True)\n",
    "         \n",
    "        test_encoder_inputs, test_decoder_inputs = get_batch_data(\n",
    "                offset, size, \n",
    "                encode_input, decode_input, \n",
    "                encoder_length, decoder_length)\n",
    "\n",
    "        feed_dict_test = generate_feed_dict(test_encoder_inputs, test_decoder_inputs, pad_index)        \n",
    "      \n",
    "        result = []\n",
    "        for o in outputs:\n",
    "            # 注意这里也需要提供 feed_dict\n",
    "            m = np.argmax(o.eval(feed_dict_test, session=sess), axis=1)\n",
    "            result.append(m[0])\n",
    "\n",
    "        return result            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def index_to_words(data, dictionary):\n",
    "    text = ' '.join([dictionary[i] for i in data])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def decode_lines(line_count, offset, encode_input, decode_input, encode_dict, decode_dict):\n",
    "    for i in range(line_count):\n",
    "        index = offset+i\n",
    "        output = decode_data(sess, index, 1, encode_input, decode_input)\n",
    "        print(\"Line#: %d\" % (index+1))\n",
    "        print(\"Input: %s\" % index_to_words(encode_input[index], encode_dict))\n",
    "        print(\"Result: %s\" % index_to_words(output, decode_dict))\n",
    "        print(\"Expect: %s\" % index_to_words(decode_input[index], decode_dict)) \n",
    "        print(\"----------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Line#: 101\n",
      "Input: and we had those instead .\n",
      "Result: 来 替代 它们 。 <EOS> 。 <EOS> 。 <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> 。 <EOS> <EOS> <EOS> 。\n",
      "Expect: <GO> 来 替代 它们 。 <EOS>\n",
      "----------------------------------\n",
      "Line#: 102\n",
      "Input: Well , some of us would be eating those <UNK>\n",
      "Result: 嗯 ， 我们 之中 的 一些 人会 把 巧克力 吃 了 <EOS> 巧克力 的 巧克力 <EOS> 吗 ， <EOS> 吗\n",
      "Expect: <GO> 嗯 ， 我们 之中 的 一些 人会 把 巧克力 吃 了 <EOS>\n",
      "----------------------------------\n",
      "Line#: 103\n",
      "Input: instead of passing them around ,\n",
      "Result: 而 不 给 别人 。 <EOS> 顶部 。 <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> 。 <EOS> <EOS> <EOS> <EOS>\n",
      "Expect: <GO> 而 不 给 别人 。 <EOS>\n",
      "----------------------------------\n"
     ]
    }
   ],
   "source": [
    "#训练数据集翻译测试\n",
    "decode_lines(3, 100, train_en_sentences, train_zh_sentences, train_en_reverse_dict, train_zh_reverse_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Line#: 21\n",
      "Input: If it has this <UNK> scaling ,\n",
      "Result: 最 <UNK> 这里 ， <EOS> ， <EOS> 的 <EOS> ， <EOS> 。 <EOS> 。 <EOS> <EOS> <EOS> 。 <EOS> <EOS>\n",
      "Expect: 如果 其 规模 的 增长 呈 次 线性\n",
      "----------------------------------\n",
      "Line#: 22\n",
      "Input: the theory says\n",
      "Result: <UNK> 的 <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS>\n",
      "Expect: 依照 原理\n",
      "----------------------------------\n",
      "Line#: 23\n",
      "Input: we should have <UNK> growth .\n",
      "Result: 巧克力 巧克力 巧克力 的 <UNK> 巧克力 。 <EOS> 体内 <EOS> 。 <EOS> <EOS> <EOS> 。 <EOS> <EOS> <EOS> 。 <EOS>\n",
      "Expect: 我们 应该 会 得到 一个 S 型 的 增长\n",
      "----------------------------------\n"
     ]
    }
   ],
   "source": [
    "#测试数据集翻译测试\n",
    "decode_lines(3, 20, test_en_sentences, test_zh_sentences, train_en_reverse_dict, train_zh_reverse_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
