{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPython 2.7.6\n",
      "IPython 5.2.2\n",
      "\n",
      "tensorflow 1.0.0\n",
      "numpy 1.12.0\n",
      "\n",
      "compiler   : GCC 4.8.4\n",
      "system     : Linux\n",
      "release    : 4.4.43-boot2docker\n",
      "machine    : x86_64\n",
      "processor  : x86_64\n",
      "CPU cores  : 1\n",
      "interpreter: 64bit\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -p tensorflow,numpy -v -m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import jieba\n",
    "from jieba import posseg as pseg\n",
    "from collections import defaultdict, Counter\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "NEG = 'N'\n",
    "POS = 'P'\n",
    "\n",
    "train_files = {}\n",
    "train_files[NEG] = 'neg_train.txt'\n",
    "train_files[POS] = 'pos_train.txt'\n",
    "\n",
    "test_files = {}\n",
    "test_files[NEG] = 'neg_test.txt'\n",
    "test_files[POS] = 'pos_test.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#读取文件，分词\n",
    "def load_file(file_name, line_num=0):\n",
    "    f = open(file_name, 'r')    \n",
    "    lines = f.readlines()\n",
    "    cnt = len(lines)\n",
    "    if line_num >0:\n",
    "        cnt = line_num\n",
    "    f.close()\n",
    "    segs = []\n",
    "    seg_lines = []\n",
    "    for line in lines[:cnt]:\n",
    "        line = line.strip()\n",
    "        words = pseg.cut(line)\n",
    "        seg_per_line = []\n",
    "        for (key, flag) in words:\n",
    "            if flag == 'x':\n",
    "                continue           \n",
    "            segs.append(key)\n",
    "            seg_per_line.append(key)\n",
    "        seg_lines.append(seg_per_line)\n",
    "    return segs, seg_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def load_train_dataset(input_data, line_num=0):\n",
    "    segs = {}\n",
    "    seg_lines = {}\n",
    "    for k, v in input_data.items():\n",
    "         segs[k], seg_lines[k] = load_file(v, line_num)\n",
    "    return segs, seg_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.301 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146.244341135\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "segs_dict, seg_lines_dict = load_train_dataset(train_files)\n",
    "\n",
    "t1 = time.time()\n",
    "print(t1-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "449708\n",
      "508469\n",
      "13003\n",
      "11583\n"
     ]
    }
   ],
   "source": [
    "print(len(segs_dict[NEG]))\n",
    "print(len(segs_dict[POS]))\n",
    "print(len(seg_lines_dict[NEG]))\n",
    "print(len(seg_lines_dict[POS]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "UNKNOWN_WORD = u'UNK'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#建立vocabulary dict\n",
    "def build_word_dict(input_segs):\n",
    "    all_segs = []\n",
    "    temp = []\n",
    "    for (k, v) in input_segs.items():\n",
    "        all_segs.extend(v)\n",
    "    word_cnt = Counter(all_segs)\n",
    "    word_dict = {}\n",
    "    word_dict[UNKNOWN_WORD] = 0\n",
    "    index_dict = {}\n",
    "    index_dict[0] = UNKNOWN_WORD\n",
    "    i = 1\n",
    "    for (k, v) in word_cnt.most_common()[:4999]:\n",
    "        word_dict[k] = i\n",
    "        index_dict[i] = k\n",
    "        i += 1\n",
    "    return word_dict, index_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "all_word_dict, all_index_dict = build_word_dict(segs_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n",
      "5000\n"
     ]
    }
   ],
   "source": [
    "print(len(all_word_dict))\n",
    "print(len(all_index_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#把语句转换为词索引\n",
    "def build_line_data(lines, word_dict, isTestdata=False):\n",
    "    lines_index = {}\n",
    "    labels_index = {}\n",
    "    i = 0\n",
    "    max_len = 0\n",
    "    for (k,v) in lines.items():\n",
    "        label = 0\n",
    "        if (k==POS):\n",
    "            label = 1\n",
    "        for line in v:\n",
    "            seg_index = []\n",
    "            labels_index[i] = label            \n",
    "            for word in line:\n",
    "                if isTestdata:                    \n",
    "                    if word in word_dict.keys():\n",
    "                        seg_index.append(word_dict[word])\n",
    "                    else:\n",
    "                        seg_index.append(0)\n",
    "                else:\n",
    "                    seg_index.append(word_dict[word])\n",
    "            lines_index[i] = seg_index\n",
    "            if (max_len < len(seg_index)):\n",
    "                max_len = len(seg_index)                \n",
    "            i+=1\n",
    "    return max_len, lines_index, labels_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "max_sentence_len, train_sentences, train_labels = build_line_data(seg_lines_dict, all_word_dict, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1479\n",
      "24586\n",
      "24586\n",
      "19568\n",
      "5018\n",
      "20.4099894249\n"
     ]
    }
   ],
   "source": [
    "print(max_sentence_len)\n",
    "print(len(train_sentences))\n",
    "print(len(train_labels))\n",
    "\n",
    "i=0\n",
    "#句子长度设为60，训练语料中80%句子长度小于60\n",
    "SENTENCE_LEN=60\n",
    "\n",
    "for (k,s) in train_sentences.items():\n",
    "    \n",
    "    if len(s)<=SENTENCE_LEN:\n",
    "        i+=1\n",
    "\n",
    "total_sentence = len(train_sentences)\n",
    "print i\n",
    "outsider = total_sentence - i\n",
    "print outsider\n",
    "print 100.0 * outsider / total_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#把每行语料变成固定长度，短句后面补未命中词，长句直接截断\n",
    "def build_input_train_data(sentences, max_len):\n",
    "    input_ = {}\n",
    "    for (k,v) in sentences.items():\n",
    "        input_[k] = v[:max_len]\n",
    "        if (len(v) < max_len):\n",
    "            padding = [0] *(max_len-len(v))\n",
    "            input_[k].extend(padding)\n",
    "    return input_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "input_train_data = build_input_train_data(train_sentences, SENTENCE_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24586\n",
      "0 60 [121, 2, 457, 88, 62, 15, 522, 1580, 21, 1, 142, 127, 121, 1, 409, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "装 了 xp 系统 后 没有 出现 网友 说 的 驱动 不好 装 的 情况 \n",
      "1 60 [829, 32, 211, 76, 421, 5, 17, 1031, 1683, 1517, 3939, 95, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "总的来说 比较 干净 而且 地理位置 很 好 市区 繁华 地段 进出 方便 \n"
     ]
    }
   ],
   "source": [
    "print len(input_train_data)\n",
    "for (k,v) in input_train_data.items()[:2]:\n",
    "    print k, len(v), v\n",
    "    s = ''\n",
    "    for w in v:        \n",
    "        if w>0:\n",
    "            s += all_index_dict[w] + ' '\n",
    "    print s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.0676429272\n"
     ]
    }
   ],
   "source": [
    "#读入测试语料\n",
    "t0 = time.time()\n",
    "test_segs, test_lines = load_train_dataset(test_files,1000)\n",
    "t1 = time.time()\n",
    "print(t1-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.50440406799\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "s_len, test_sentences, test_labels = build_line_data(test_lines, all_word_dict,isTestdata=True)\n",
    "t1 = time.time()\n",
    "print(t1-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "692\n",
      "2000\n",
      "2000\n"
     ]
    }
   ],
   "source": [
    "print(s_len)\n",
    "print(len(test_sentences))\n",
    "print(len(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "input_test_data = build_input_train_data(test_sentences, SENTENCE_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(all_word_dict)\n",
    "word_embed_size = 64\n",
    "\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_all_test_data(data, labels):\n",
    "    output_ = []\n",
    "    labels_ = []\n",
    "    for (k,v) in data.items():\n",
    "        output_.append(v)\n",
    "    for (k,v) in labels.items():\n",
    "        labels_.append(v)\n",
    "    return output_, get_label_matrix(labels_, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n",
      "[3187, 0, 638, 2, 399, 269, 199, 0, 967, 42, 4, 128, 1059, 1, 697, 691, 535, 286, 278, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 1]\n"
     ]
    }
   ],
   "source": [
    "input_test_data_list, test_labels_list = get_all_test_data(input_test_data, test_labels)\n",
    "print(len(input_test_data_list))\n",
    "print(input_test_data_list[0])\n",
    "print(test_labels_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def shuffle_data(input_data, input_labels):\n",
    "    output_data = []\n",
    "    for (index,v) in input_data.items():\n",
    "        label = input_labels[index]\n",
    "        output_data.append((index, label, v))\n",
    "    np.random.shuffle(output_data)\n",
    "    return output_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24586\n",
      "2000\n"
     ]
    }
   ],
   "source": [
    "#对输入数据作shuffle处理\n",
    "shuffled_train_data = shuffle_data(input_train_data, train_labels)\n",
    "shuffled_test_data = shuffle_data(input_test_data, test_labels)\n",
    "\n",
    "print(len(shuffled_train_data))\n",
    "print(len(shuffled_test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "428 1 [191, 18, 295, 14, 222, 19, 0, 1307, 1, 0, 18, 0, 1, 125, 502, 397, 439, 4476, 830, 18, 711, 830, 1054, 533, 1, 0, 8, 4, 2139, 0, 71, 338, 4, 101, 155, 56, 288, 0, 0, 4157, 0, 203, 769, 1, 39, 858, 533, 313, 0, 55, 0, 96, 648, 960, 101, 155, 3, 0, 441, 0]\n",
      "外观 和 做工 还 算 不错 档次 的 和 的 东西 不少 如 显卡 切换 功能 和 指纹 功能 等等 送货 的 在 我 拆 时 告诉 我 如果 里面 不是 电脑 砸 挺 可爱 的 但 快递 送货 人员 他 把 货 送到 如果 里面 是 或 \n",
      "1599 0 [23, 3, 2216, 3441, 834, 53, 9, 1, 698, 968, 82, 16, 70, 1431, 9, 961, 669, 1499, 29, 35, 2162, 29, 0, 260, 135, 342, 102, 51, 12, 2506, 2, 135, 3018, 2426, 79, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "我们 是 今年 五一 期间 入住 酒店 的 标间 卫生 一般 房间 有点 异味 酒店 对面 有个 超市 要 买 东东 要 好像 晚上 8 点 多 就 关门 了 晚上 路边 小吃 很多 \n",
      "1502 0 [161, 1, 82, 345, 15, 1050, 7, 197, 35, 35, 2, 6, 7, 197, 22, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "写 的 一般 完全 没有 价值 不 值得 买 买 了 也 不 值得 看 \n",
      "594 1 [4, 193, 510, 514, 2892, 0, 1, 831, 489, 26, 20, 11, 132, 3438, 3594, 587, 0, 409, 1336, 60, 909, 406, 1, 0, 781, 12, 57, 12, 26, 20, 640, 3, 3566, 20, 1, 4527, 20, 3, 3910, 1, 799, 0, 1, 20, 8, 0, 90, 100, 1599, 0, 14, 3910, 2892, 0, 8, 2722, 932, 0, 4, 147]\n",
      "我 一直 相信 关于 生存 的 书籍 每 一个 人 都 应该 看一看 一旦 遇到 情况 或许 你 曾经 看过 的 细节 就 能 就 一个 人 甚至 是 一群 人 的 命 人 是 脆弱 的 离开 的 人 在 里 比 一只 还 脆弱 生存 在 这时 显得 我 希望 \n",
      "211 1 [21, 160, 3, 136, 0, 0, 160, 3, 136, 2776, 1, 4156, 1273, 1, 2455, 194, 8, 0, 62, 717, 2, 0, 1, 794, 599, 1, 0, 8, 0, 1, 1653, 50, 0, 1012, 1, 0, 4595, 44, 8, 370, 1898, 50, 0, 44, 4, 373, 104, 2604, 201, 1273, 0, 46, 1898, 311, 199, 55, 8, 999, 41, 370]\n",
      "说 它 是 一本 它 是 一本 悲伤 的 爱情故事 主人公 的 平淡 生活 在 后 发生 了 的 改变 人生 的 在 的 变化 中 不断 的 前进 . 在 一种 失去 中 . 我 也许 从 最初 开始 主人公 会 失去 所有 只是 他 在 坚持 对 一种 \n"
     ]
    }
   ],
   "source": [
    "\n",
    "for (i, k,v) in shuffled_test_data[:5]:\n",
    "    print i, k, v\n",
    "    s = ''\n",
    "    for w in v:        \n",
    "        if w>0:\n",
    "            s += all_index_dict[w] + ' '\n",
    "    print s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#将label变成one-hot matrix格式\n",
    "def get_label_matrix(input_label, num_l):\n",
    "    out_ = []\n",
    "    for label in input_label:\n",
    "        line = [0] * num_l\n",
    "        line[label] = 1\n",
    "        out_.append(line)    \n",
    "    return out_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#获取单批训练/测试数据\n",
    "def get_batch_data(input_data, index, size, num_l):\n",
    "    data_ = []\n",
    "    labels_ = []\n",
    "    indexs_ = []\n",
    "    for (i, k,v) in input_data[index:index+size]:\n",
    "        data_.append(v)\n",
    "        labels_.append(k)\n",
    "        indexs_.append(i)\n",
    "    return indexs_, data_, get_label_matrix(labels_, num_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[76, 0, 26, 0, 8, 25, 9, 155, 2820, 0, 0, 6, 3, 2688, 1176, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1657, 0, 3388, 2878, 1, 125, 4520, 1, 7, 0, 3543, 902, 3293, 516, 667, 10, 0, 178, 132, 14, 24, 512, 138, 1046, 178, 206, 1415, 228, 1038, 56, 5, 2538, 1541, 380, 66, 167, 26, 183, 172, 1, 25, 6, 337, 127, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [711, 14, 57, 2132, 99, 39, 72, 169, 56, 1438, 80, 5, 2296, 0, 0, 1, 4396, 178, 3505, 22, 1132, 2, 151, 1575, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [533, 184, 272, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [424, 46, 3083, 49, 101, 849, 0, 389, 80, 581, 95, 941, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
      "[[0, 1], [1, 0], [1, 0], [0, 1], [0, 1]]\n",
      "而且 一个 在 到 酒店 里面 闹 也 是 一大 亮点 \n",
      "A 那条 装饰 的 东西 衔接 的 不 功能键 处 手指 按 下去 有 屏幕 应该 还 可以 升级 为 LED 屏幕 4 芯 电池 果然 不是 很 耐用 最高 性能 时候 只有 一个 小时 其他 的 到 也 没什么 不好 的 了 \n",
      "指纹 还 能 忍受 吧 但 觉得 键盘 不是 贴 得 很 结实 的 再就是 屏幕 光线 看 久 了 有些 累 \n",
      "送货 速度 快 \n",
      "以为 会 很远 但是 如果 坐 真 得 十分 方便 到达 \n"
     ]
    }
   ],
   "source": [
    "i_, d_,l_ = get_batch_data(shuffled_train_data, 1, 5, 2)\n",
    "\n",
    "\n",
    "print d_\n",
    "print l_\n",
    "for d in d_:\n",
    "    s = ''\n",
    "    for w in d:        \n",
    "        if w>0:\n",
    "            s += all_index_dict[w] + ' '\n",
    "    print s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def accuracy(predictions, labels):\n",
    "      return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1))\n",
    "          / predictions.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"input_data:0\", shape=(?, 60), dtype=int32)\n",
      "Tensor(\"labels:0\", shape=(?, 2), dtype=int32)\n",
      "Tensor(\"embedding_lookup:0\", shape=(?, 60, 64), dtype=float32)\n",
      "Tensor(\"ExpandDims:0\", shape=(?, 60, 64, 1), dtype=float32)\n",
      "Tensor(\"conv:0\", shape=(?, 58, 1, 64), dtype=float32)\n",
      "Tensor(\"pool:0\", shape=(?, 1, 1, 64), dtype=float32)\n",
      "Tensor(\"dense/Tanh:0\", shape=(?, 1, 1, 10), dtype=float32)\n",
      "Tensor(\"output/Reshape_1:0\", shape=(?, 1, 1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "graph = tf.Graph()\n",
    "sentence_length = SENTENCE_LEN\n",
    "# max_pool\n",
    "with graph.as_default():\n",
    "    filter_num = 64\n",
    "    window_size = 3\n",
    "    num_labels = 2\n",
    "    num_fc_hidden = 10\n",
    "    \n",
    "    tf_input_data = tf.placeholder(tf.int32, shape=[None, sentence_length], name='input_data')    \n",
    "    tf_labels = tf.placeholder(tf.int32, shape=[None, num_labels], name='labels')\n",
    "    \n",
    "    word_embeds = tf.Variable(tf.random_uniform([vocab_size, word_embed_size], -1.0, 1.0), name=\"Word_embed\")\n",
    "    input_embeds = tf.nn.embedding_lookup(word_embeds, tf_input_data)\n",
    "   \n",
    "    tf_embeds_expand = tf.expand_dims(input_embeds, -1)\n",
    "    \n",
    "    print(tf_input_data)\n",
    "    print(tf_labels)\n",
    "    print(input_embeds)\n",
    "    print(tf_embeds_expand)\n",
    "\n",
    "    filter_shape = [window_size, word_embed_size, 1, filter_num]\n",
    "    # W 和 b 是卷积的参数\n",
    "    W = tf.Variable(tf.random_uniform(filter_shape, -1.0, 1.0), name=\"W\")\n",
    "    # bias 和 filter_num 个数是一样的\n",
    "    b = tf.Variable(tf.constant(0.0, shape=[filter_num]), name=\"b\")\n",
    "    # 步长为1，这里不做 Padding，因此句子太短的话可能要丢掉。可自行尝试加 padding（不加也不影响作业评分）\n",
    "    conv = tf.nn.conv2d(\n",
    "                    tf_embeds_expand,\n",
    "                    W,\n",
    "                    strides=[1, 1, 1, 1],\n",
    "                    padding=\"VALID\",\n",
    "                    name=\"conv\")\n",
    "    # 卷积出来的结果加上 bias\n",
    "    conv_hidden = tf.nn.tanh(tf.add(conv, b), name=\"tanh\")\n",
    "    \n",
    "    print(conv)\n",
    "\n",
    "    # 因为没有 padding，出来的结果个数是 sequence_length - window_size + 1，如果加了 padding 这里要对应更改。\n",
    "    pool = tf.nn.max_pool(\n",
    "                    conv_hidden,\n",
    "                    ksize=[1, sentence_length - window_size + 1, 1, 1],\n",
    "                    strides=[1, 1, 1, 1],\n",
    "                    padding='VALID',\n",
    "                    name=\"pool\")\n",
    "    \n",
    "    print(pool)\n",
    "    \n",
    "    #增加一个全连接层\n",
    "    fc = tf.layers.dense(pool, num_fc_hidden, activation=tf.nn.tanh)\n",
    "    \n",
    "    print(fc)\n",
    "   \n",
    "    raw_output = tf.layers.dense(fc, num_labels, name='output')\n",
    "    print(raw_output)\n",
    "    \n",
    "    \n",
    "    cost = tf.nn.softmax_cross_entropy_with_logits(logits=raw_output, labels=tf_labels)\n",
    "    \n",
    "    cost_summary = tf.summary.scalar('cost', tf.reduce_mean(cost))\n",
    "    embed_summary = tf.summary.histogram('embed',input_embeds)\n",
    "    merged = tf.summary.merge_all()\n",
    "\n",
    "    train_step = tf.train.GradientDescentOptimizer(0.005).minimize(cost)\n",
    "    \n",
    "    tf_prediction = tf.nn.softmax(raw_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "writer = tf.summary.FileWriter(\"/root/log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24586\n",
      "2000\n",
      "Initialized\n",
      "Train epoch:0, loss=0.676405, accuracy=51.102253%\n",
      "Train epoch:1, loss=0.678394, accuracy=51.350362%\n",
      "Train epoch:2, loss=0.680900, accuracy=51.635077%\n",
      "Train epoch:3, loss=0.682259, accuracy=51.948263%\n",
      "Train epoch:4, loss=0.686278, accuracy=52.054014%\n",
      "Train epoch:5, loss=0.688845, accuracy=52.241113%\n",
      "Train epoch:6, loss=0.689196, accuracy=52.481087%\n",
      "Train epoch:7, loss=0.688971, accuracy=52.737330%\n",
      "Train epoch:8, loss=0.688926, accuracy=52.973237%\n",
      "Train epoch:9, loss=0.691083, accuracy=53.184739%\n",
      "Train epoch:10, loss=0.695440, accuracy=53.367770%\n",
      "Train epoch:11, loss=0.704683, accuracy=53.656553%\n",
      "Train epoch:12, loss=0.710563, accuracy=54.075490%\n",
      "Train epoch:13, loss=0.708376, accuracy=54.250386%\n",
      "Train epoch:14, loss=0.706119, accuracy=54.453754%\n",
      "Train epoch:15, loss=0.705549, accuracy=54.657122%\n",
      "Train epoch:16, loss=0.704096, accuracy=55.039453%\n",
      "Train epoch:17, loss=0.701088, accuracy=55.226552%\n",
      "Train epoch:18, loss=0.697075, accuracy=55.560075%\n",
      "Train epoch:19, loss=0.695993, accuracy=55.950541%\n",
      "Train epoch:20, loss=0.702315, accuracy=56.133572%\n",
      "Train epoch:21, loss=0.705384, accuracy=56.357276%\n",
      "Train epoch:22, loss=0.709988, accuracy=56.698934%\n",
      "Train epoch:23, loss=0.723434, accuracy=56.869763%\n",
      "Train epoch:24, loss=0.711002, accuracy=57.203286%\n",
      "Train epoch:25, loss=0.730910, accuracy=57.321240%\n",
      "Train epoch:26, loss=0.728174, accuracy=57.862198%\n",
      "Train epoch:27, loss=0.768935, accuracy=58.199788%\n",
      "Train epoch:28, loss=0.745709, accuracy=58.179452%\n",
      "Train epoch:29, loss=0.747499, accuracy=58.578053%\n",
      "Train epoch:30, loss=0.742047, accuracy=58.923778%\n",
      "Train epoch:31, loss=0.753299, accuracy=59.017327%\n",
      "Train epoch:32, loss=0.764657, accuracy=59.468803%\n",
      "Train epoch:33, loss=0.789930, accuracy=59.623363%\n",
      "Train epoch:34, loss=0.832518, accuracy=59.680306%\n",
      "Train epoch:35, loss=0.780845, accuracy=59.936549%\n",
      "Train epoch:36, loss=0.747095, accuracy=60.400228%\n",
      "Train epoch:37, loss=0.791493, accuracy=60.709347%\n",
      "Train epoch:38, loss=0.842492, accuracy=60.798829%\n",
      "Train epoch:39, loss=0.824451, accuracy=61.303181%\n",
      "Train epoch:40, loss=0.810892, accuracy=62.023103%\n",
      "Train epoch:41, loss=0.800238, accuracy=62.185797%\n",
      "Train epoch:42, loss=0.750771, accuracy=62.462377%\n",
      "Train epoch:43, loss=0.828128, accuracy=62.856910%\n",
      "Train epoch:44, loss=0.853654, accuracy=62.982998%\n",
      "Train epoch:45, loss=0.832653, accuracy=63.910355%\n",
      "Train epoch:46, loss=0.850050, accuracy=64.357765%\n",
      "Train epoch:47, loss=0.816551, accuracy=64.748231%\n",
      "Train epoch:48, loss=0.833290, accuracy=65.333930%\n",
      "Train epoch:49, loss=0.847087, accuracy=65.126495%\n",
      "Train epoch:50, loss=0.805396, accuracy=65.956235%\n",
      "Train epoch:51, loss=1.551610, accuracy=66.546002%\n",
      "Train epoch:52, loss=0.892266, accuracy=66.737167%\n",
      "Train epoch:53, loss=1.075358, accuracy=67.192711%\n",
      "Train epoch:54, loss=0.924143, accuracy=67.737737%\n",
      "Train epoch:55, loss=0.955797, accuracy=67.827219%\n",
      "Train epoch:56, loss=1.610656, accuracy=68.604084%\n",
      "Train epoch:57, loss=0.832956, accuracy=69.254860%\n",
      "Train epoch:58, loss=0.904747, accuracy=69.616855%\n",
      "Train epoch:59, loss=0.466767, accuracy=70.080534%\n",
      "Train epoch:60, loss=1.122505, accuracy=70.991621%\n",
      "Train epoch:61, loss=0.693201, accuracy=71.178720%\n",
      "Train epoch:62, loss=0.837558, accuracy=72.057268%\n",
      "Train epoch:63, loss=0.992095, accuracy=72.748719%\n",
      "Train epoch:64, loss=1.327182, accuracy=73.366957%\n",
      "Train epoch:65, loss=0.674245, accuracy=74.038070%\n",
      "Train epoch:66, loss=0.182758, accuracy=74.196697%\n",
      "Train epoch:67, loss=1.059142, accuracy=74.766127%\n",
      "Train epoch:68, loss=0.148272, accuracy=75.221671%\n",
      "Train epoch:69, loss=1.948748, accuracy=75.827707%\n",
      "Train epoch:70, loss=0.000961, accuracy=76.124624%\n",
      "Train epoch:71, loss=0.000657, accuracy=77.174001%\n",
      "Train epoch:72, loss=0.000498, accuracy=77.727162%\n",
      "Train epoch:73, loss=0.000506, accuracy=78.190840%\n",
      "Train epoch:74, loss=0.000760, accuracy=78.089156%\n",
      "Train epoch:75, loss=0.000933, accuracy=78.308794%\n",
      "Train epoch:76, loss=0.000869, accuracy=78.951436%\n",
      "Train epoch:77, loss=0.000584, accuracy=80.017083%\n",
      "Train epoch:78, loss=0.000614, accuracy=80.562109%\n",
      "Train epoch:79, loss=0.000858, accuracy=80.859025%\n",
      "Train epoch:80, loss=0.001141, accuracy=81.294232%\n",
      "Train epoch:81, loss=0.023999, accuracy=81.639958%\n",
      "Train epoch:82, loss=0.001388, accuracy=81.859595%\n",
      "Train epoch:83, loss=0.001509, accuracy=82.449361%\n",
      "Train epoch:84, loss=0.001331, accuracy=82.925242%\n",
      "Train epoch:85, loss=0.001625, accuracy=83.246563%\n",
      "Train epoch:86, loss=0.001111, accuracy=83.515009%\n",
      "Train epoch:87, loss=0.001519, accuracy=83.836330%\n",
      "Train epoch:88, loss=0.001732, accuracy=83.783454%\n",
      "Train epoch:89, loss=0.002261, accuracy=84.263402%\n",
      "Train epoch:90, loss=0.001996, accuracy=84.849101%\n",
      "Train epoch:91, loss=0.002162, accuracy=85.467339%\n",
      "Train epoch:92, loss=0.001817, accuracy=85.959489%\n",
      "Train epoch:93, loss=0.001857, accuracy=86.191328%\n",
      "Train epoch:94, loss=0.001509, accuracy=86.874644%\n",
      "Train epoch:95, loss=0.002317, accuracy=87.220369%\n",
      "Train epoch:96, loss=0.000915, accuracy=87.647442%\n",
      "Train epoch:97, loss=0.001778, accuracy=87.301716%\n",
      "Train epoch:98, loss=0.003250, accuracy=87.025136%\n",
      "Train epoch:99, loss=0.001019, accuracy=87.940291%\n",
      "Train epoch:100, loss=0.002269, accuracy=88.367364%\n",
      "Train epoch:101, loss=0.002145, accuracy=88.953063%\n",
      "Train epoch:102, loss=0.001112, accuracy=89.327259%\n",
      "Train epoch:103, loss=0.000775, accuracy=89.465549%\n",
      "Train epoch:104, loss=0.000424, accuracy=89.522492%\n",
      "Train epoch:105, loss=0.001709, accuracy=89.550964%\n",
      "Train epoch:106, loss=0.000762, accuracy=90.059383%\n",
      "Train epoch:107, loss=0.000872, accuracy=89.811275%\n",
      "Train epoch:108, loss=0.000686, accuracy=90.478321%\n",
      "Train epoch:109, loss=0.000775, accuracy=90.295290%\n",
      "Train epoch:110, loss=0.000385, accuracy=90.852518%\n",
      "Train epoch:111, loss=0.000521, accuracy=91.043683%\n",
      "Train epoch:112, loss=0.000563, accuracy=91.328398%\n",
      "Train epoch:113, loss=0.000396, accuracy=91.218580%\n",
      "Train epoch:114, loss=0.001116, accuracy=91.344668%\n",
      "Train epoch:115, loss=0.000613, accuracy=92.040185%\n",
      "Train epoch:116, loss=0.000285, accuracy=92.202880%\n",
      "Train epoch:117, loss=0.001474, accuracy=91.682258%\n",
      "Train epoch:118, loss=0.002537, accuracy=91.442284%\n",
      "Train epoch:119, loss=0.002673, accuracy=91.747336%\n",
      "Train epoch:120, loss=0.000349, accuracy=92.434719%\n",
      "Train epoch:121, loss=0.001746, accuracy=92.455056%\n",
      "Train epoch:122, loss=0.001244, accuracy=92.410315%\n",
      "Train epoch:123, loss=0.000623, accuracy=92.869926%\n",
      "Train epoch:124, loss=0.001764, accuracy=92.642154%\n",
      "Train epoch:125, loss=0.002292, accuracy=92.459123%\n",
      "Train epoch:126, loss=0.001167, accuracy=93.317335%\n",
      "Train epoch:127, loss=0.000860, accuracy=93.215651%\n",
      "Train epoch:128, loss=0.001441, accuracy=92.780444%\n",
      "Train epoch:129, loss=0.001090, accuracy=93.150573%\n",
      "Train epoch:130, loss=0.002159, accuracy=93.227853%\n",
      "Train epoch:131, loss=0.001393, accuracy=93.126169%\n",
      "Train epoch:132, loss=0.000595, accuracy=93.296998%\n",
      "Train epoch:133, loss=0.001288, accuracy=93.557309%\n",
      "Train epoch:134, loss=0.000182, accuracy=93.585781%\n",
      "Train epoch:135, loss=0.000202, accuracy=93.390547%\n",
      "Train epoch:136, loss=0.000063, accuracy=93.561376%\n",
      "Train epoch:137, loss=0.001024, accuracy=93.500366%\n",
      "Train epoch:138, loss=0.000591, accuracy=94.073863%\n",
      "Train epoch:139, loss=0.000350, accuracy=94.448060%\n",
      "Train epoch:140, loss=0.001219, accuracy=94.256894%\n",
      "Train epoch:141, loss=0.000461, accuracy=94.224355%\n",
      "Train epoch:142, loss=0.001200, accuracy=94.248759%\n",
      "Train epoch:143, loss=0.000156, accuracy=94.147076%\n",
      "Train epoch:144, loss=0.000057, accuracy=94.334174%\n",
      "Train epoch:145, loss=0.000279, accuracy=94.521272%\n",
      "Train epoch:146, loss=0.000094, accuracy=94.712438%\n",
      "Train epoch:147, loss=0.000192, accuracy=94.651428%\n",
      "Train epoch:148, loss=0.000408, accuracy=94.269096%\n",
      "Train epoch:149, loss=0.000425, accuracy=94.130806%\n",
      "Train epoch:150, loss=0.000178, accuracy=94.789718%\n",
      "Train epoch:151, loss=0.000891, accuracy=94.891402%\n",
      "Train epoch:152, loss=0.000257, accuracy=95.228992%\n",
      "Train epoch:153, loss=0.000436, accuracy=95.196453%\n",
      "Train epoch:154, loss=0.000415, accuracy=95.294070%\n",
      "Train epoch:155, loss=0.000761, accuracy=95.102904%\n",
      "Train epoch:156, loss=0.000749, accuracy=95.111039%\n",
      "Train epoch:157, loss=0.000511, accuracy=95.204588%\n",
      "Train epoch:158, loss=0.000653, accuracy=95.428293%\n",
      "Train epoch:159, loss=0.001144, accuracy=95.407956%\n",
      "Train epoch:160, loss=0.001568, accuracy=95.403888%\n",
      "Train epoch:161, loss=0.001309, accuracy=95.473033%\n",
      "Train epoch:162, loss=0.001569, accuracy=95.493370%\n",
      "Train epoch:163, loss=0.002153, accuracy=95.233059%\n",
      "Train epoch:164, loss=0.001097, accuracy=95.525909%\n",
      "Train epoch:165, loss=0.001353, accuracy=95.814691%\n",
      "Train epoch:166, loss=0.001732, accuracy=95.700805%\n",
      "Train epoch:167, loss=0.002125, accuracy=95.562515%\n",
      "Train epoch:168, loss=0.001646, accuracy=95.818759%\n",
      "Train epoch:169, loss=0.001263, accuracy=96.038396%\n",
      "Train epoch:170, loss=0.000292, accuracy=96.184821%\n",
      "Train epoch:171, loss=0.000566, accuracy=96.327178%\n",
      "Train epoch:172, loss=0.000474, accuracy=96.083137%\n",
      "Train epoch:173, loss=0.000776, accuracy=95.948914%\n",
      "Train epoch:174, loss=0.001009, accuracy=95.749614%\n",
      "Train epoch:175, loss=0.000125, accuracy=96.075002%\n",
      "Train epoch:176, loss=0.000083, accuracy=96.270235%\n",
      "Train epoch:177, loss=0.000164, accuracy=96.375986%\n",
      "Train epoch:178, loss=0.000246, accuracy=96.237696%\n",
      "Train epoch:179, loss=0.000370, accuracy=96.453266%\n",
      "Train epoch:180, loss=0.000373, accuracy=96.412593%\n",
      "Train epoch:181, loss=0.000276, accuracy=96.363784%\n",
      "Train epoch:182, loss=0.000202, accuracy=96.493940%\n",
      "Train epoch:183, loss=0.000167, accuracy=96.550883%\n",
      "Train epoch:184, loss=0.000070, accuracy=96.721712%\n",
      "Train epoch:185, loss=0.001227, accuracy=96.461401%\n",
      "Train epoch:186, loss=0.001185, accuracy=96.746116%\n",
      "Train epoch:187, loss=0.001063, accuracy=96.563085%\n",
      "Train epoch:188, loss=0.001183, accuracy=96.213292%\n",
      "Train epoch:189, loss=0.000930, accuracy=96.542748%\n",
      "Train epoch:190, loss=0.000236, accuracy=96.587489%\n",
      "Train epoch:191, loss=0.000171, accuracy=96.705442%\n",
      "Train epoch:192, loss=0.000111, accuracy=96.819328%\n",
      "Train epoch:193, loss=0.000620, accuracy=96.498007%\n",
      "Train epoch:194, loss=0.000117, accuracy=96.847800%\n",
      "Train epoch:195, loss=0.000154, accuracy=96.847800%\n",
      "Train epoch:196, loss=0.000048, accuracy=97.144717%\n",
      "Train epoch:197, loss=0.000836, accuracy=97.201659%\n",
      "Train epoch:198, loss=0.000029, accuracy=97.038965%\n",
      "Train epoch:199, loss=0.000122, accuracy=96.953551%\n",
      "Train epoch:200, loss=0.000011, accuracy=96.965753%\n",
      "Train epoch:201, loss=0.000027, accuracy=97.165053%\n",
      "Train epoch:202, loss=0.000046, accuracy=97.112178%\n",
      "Train epoch:203, loss=0.000013, accuracy=96.831530%\n",
      "Train epoch:204, loss=0.000599, accuracy=96.831530%\n",
      "Train epoch:205, loss=0.000035, accuracy=97.160986%\n",
      "Train epoch:206, loss=0.000019, accuracy=97.299276%\n",
      "Train epoch:207, loss=0.000013, accuracy=97.274872%\n",
      "Train epoch:208, loss=0.000009, accuracy=97.234198%\n",
      "Train epoch:209, loss=0.000066, accuracy=97.319613%\n",
      "Train epoch:210, loss=0.000012, accuracy=97.388758%\n",
      "Train epoch:211, loss=0.000149, accuracy=97.413162%\n",
      "Train epoch:212, loss=0.000006, accuracy=97.429431%\n",
      "Train epoch:213, loss=0.000027, accuracy=97.246400%\n",
      "Train epoch:214, loss=0.000039, accuracy=97.441633%\n",
      "Train epoch:215, loss=0.000017, accuracy=97.372488%\n",
      "Train epoch:216, loss=0.000005, accuracy=97.608395%\n",
      "Train epoch:217, loss=0.000004, accuracy=97.852436%\n",
      "Train epoch:218, loss=0.000005, accuracy=97.653136%\n",
      "Train epoch:219, loss=0.000010, accuracy=97.270805%\n",
      "Train epoch:220, loss=0.000050, accuracy=97.368421%\n",
      "Train epoch:221, loss=0.000006, accuracy=97.327747%\n",
      "Train epoch:222, loss=0.000005, accuracy=97.653136%\n",
      "Train epoch:223, loss=0.000006, accuracy=97.518913%\n",
      "Train epoch:224, loss=0.000006, accuracy=97.636867%\n",
      "Train epoch:225, loss=0.000017, accuracy=97.791426%\n",
      "Train epoch:226, loss=0.000031, accuracy=97.494509%\n",
      "Train epoch:227, loss=0.000007, accuracy=97.287074%\n",
      "Train epoch:228, loss=0.000009, accuracy=97.283007%\n",
      "Train epoch:229, loss=0.000010, accuracy=97.730416%\n",
      "Train epoch:230, loss=0.000008, accuracy=97.909379%\n",
      "Train epoch:231, loss=0.000005, accuracy=97.913447%\n",
      "Train epoch:232, loss=0.000005, accuracy=97.775157%\n",
      "Train epoch:233, loss=0.000007, accuracy=97.396893%\n",
      "Train epoch:234, loss=0.000008, accuracy=97.921581%\n",
      "Train epoch:235, loss=0.000006, accuracy=97.795493%\n",
      "Train epoch:236, loss=0.000007, accuracy=97.775157%\n",
      "Train epoch:237, loss=0.000006, accuracy=98.011063%\n",
      "Train epoch:238, loss=0.000004, accuracy=98.059871%\n",
      "Train epoch:239, loss=0.000008, accuracy=97.893110%\n",
      "Train epoch:240, loss=0.000005, accuracy=97.872773%\n",
      "Train epoch:241, loss=0.000008, accuracy=97.986659%\n",
      "Train epoch:242, loss=0.000038, accuracy=97.889043%\n",
      "Train epoch:243, loss=0.000020, accuracy=97.710079%\n",
      "Train epoch:244, loss=0.000046, accuracy=97.771089%\n",
      "Train epoch:245, loss=0.000193, accuracy=97.738550%\n",
      "Train epoch:246, loss=0.000037, accuracy=98.043602%\n",
      "Train epoch:247, loss=0.000004, accuracy=98.129017%\n",
      "Train epoch:248, loss=0.000004, accuracy=97.921581%\n",
      "Train epoch:249, loss=0.000003, accuracy=98.129017%\n",
      "Train epoch:250, loss=0.000003, accuracy=98.096478%\n",
      "Train epoch:251, loss=0.000003, accuracy=98.218498%\n",
      "Train epoch:252, loss=0.000002, accuracy=98.340519%\n",
      "Train epoch:253, loss=0.000002, accuracy=98.381193%\n",
      "Train epoch:254, loss=0.000002, accuracy=98.405597%\n",
      "Train epoch:255, loss=0.000002, accuracy=98.393395%\n",
      "Train epoch:256, loss=0.000002, accuracy=98.348654%\n",
      "Train epoch:257, loss=0.000009, accuracy=98.051737%\n",
      "Train epoch:258, loss=0.000004, accuracy=97.783291%\n",
      "Train epoch:259, loss=0.000005, accuracy=97.840234%\n",
      "Train epoch:260, loss=0.000005, accuracy=98.133084%\n",
      "Train epoch:261, loss=0.000003, accuracy=98.263239%\n",
      "Train epoch:262, loss=0.000003, accuracy=98.421866%\n",
      "Train epoch:263, loss=0.000003, accuracy=98.499146%\n",
      "Train epoch:264, loss=0.000002, accuracy=98.462540%\n",
      "Train epoch:265, loss=0.000002, accuracy=98.507281%\n",
      "Train epoch:266, loss=0.000002, accuracy=98.552021%\n",
      "Train epoch:267, loss=0.000002, accuracy=98.580493%\n",
      "Train epoch:268, loss=0.000001, accuracy=98.588628%\n",
      "Train epoch:269, loss=0.000001, accuracy=98.596762%\n",
      "Train epoch:270, loss=0.000001, accuracy=98.405597%\n",
      "Train epoch:271, loss=0.000002, accuracy=98.303913%\n",
      "Train epoch:272, loss=0.000002, accuracy=98.417799%\n",
      "Train epoch:273, loss=0.000002, accuracy=98.535752%\n",
      "Train epoch:274, loss=0.000002, accuracy=98.564224%\n",
      "Train epoch:275, loss=0.000002, accuracy=98.084276%\n",
      "Train epoch:276, loss=0.000003, accuracy=98.027333%\n",
      "Train epoch:277, loss=0.000003, accuracy=98.226633%\n",
      "Train epoch:278, loss=0.000003, accuracy=98.153421%\n",
      "Train epoch:279, loss=0.000003, accuracy=98.153421%\n",
      "Train epoch:280, loss=0.000003, accuracy=98.120882%\n",
      "Train epoch:281, loss=0.000004, accuracy=98.120882%\n",
      "Train epoch:282, loss=0.000004, accuracy=98.214431%\n",
      "Train epoch:283, loss=0.000003, accuracy=98.425933%\n",
      "Train epoch:284, loss=0.000002, accuracy=98.474742%\n",
      "Train epoch:285, loss=0.000002, accuracy=98.608964%\n",
      "Train epoch:286, loss=0.000002, accuracy=98.686244%\n",
      "Train epoch:287, loss=0.000002, accuracy=98.739120%\n",
      "Train epoch:288, loss=0.000001, accuracy=98.710648%\n",
      "Train epoch:289, loss=0.000001, accuracy=98.739120%\n",
      "Train epoch:290, loss=0.000002, accuracy=98.446270%\n",
      "Train epoch:291, loss=0.000002, accuracy=98.393395%\n",
      "Train epoch:292, loss=0.000002, accuracy=98.291711%\n",
      "Train epoch:293, loss=0.000002, accuracy=98.413731%\n",
      "Train epoch:294, loss=0.000002, accuracy=98.377125%\n",
      "Train epoch:295, loss=0.000002, accuracy=98.547954%\n",
      "Train epoch:296, loss=0.000002, accuracy=98.413731%\n",
      "Train epoch:297, loss=0.000002, accuracy=98.340519%\n",
      "Train epoch:298, loss=0.000002, accuracy=98.442203%\n",
      "Train epoch:299, loss=0.000002, accuracy=98.539819%\n",
      "Training duration:8459.14\n",
      "\n",
      "-----start testing------------\n",
      "Total test samples: 2000\n",
      "Test accuracy:50.000000%\n",
      "Testing duration:1.15\n",
      "Confusion matrix:\n",
      "[[901  99]\n",
      " [ 84 916]]\n"
     ]
    }
   ],
   "source": [
    "epoches = 300\n",
    "batch_size = 1\n",
    "display_steps = 10000\n",
    "num_labels = 2\n",
    "\n",
    "total_train_batch = len(shuffled_train_data) / batch_size\n",
    "if len(input_train_data) % batch_size > 0:\n",
    "    total_train_batch += 1\n",
    "print(total_train_batch)\n",
    "\n",
    "#total_train_batch = 1\n",
    "\n",
    "total_test_batch = len(shuffled_test_data) / batch_size\n",
    "if len(shuffled_test_data) % batch_size > 0:\n",
    "    total_test_batch += 1\n",
    "print(total_test_batch)\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    tf.global_variables_initializer().run()\n",
    "    print(\"Initialized\")\n",
    "    \n",
    "    train_start = time.time()\n",
    "    costs = []\n",
    "    for epoch in range(epoches):\n",
    "        start_index = 0\n",
    "        \n",
    "        train_acc = []\n",
    "        for i in range(total_train_batch):            \n",
    "            batch_index, batch_data, batch_labels = get_batch_data(shuffled_train_data, start_index, batch_size, num_labels)\n",
    "            \n",
    "            start_index += batch_size\n",
    "            \n",
    "            feed_dict = {tf_input_data : batch_data, tf_labels : batch_labels}\n",
    "            _, c, predictions = session.run(\n",
    "              [train_step, cost, tf_prediction], feed_dict=feed_dict)\n",
    "            #costs.append(c)\n",
    "            \n",
    "            acc = accuracy(np.reshape(predictions,[batch_size,2]), batch_labels)\n",
    "            train_acc.append(np.mean(acc))\n",
    "        \n",
    "            #if (i+1) % display_steps == 0:\n",
    "            #    print(\"Loss at step %d: %f\" % (i+1, c))\n",
    "            #    print(\"Training accuracy: %f%%\" % (np.mean(train_acc)))\n",
    "                #print(acc)\n",
    "                #print(predictions)\n",
    "                #print(batch_labels)\n",
    "                #costs.append(c)\n",
    "                \n",
    "        costs.append(c)    \n",
    "        print(\"Train epoch:%d, loss=%f, accuracy=%f%%\" % (epoch, c, np.mean(train_acc)))\n",
    "        embed_run, cost_summary_run = session.run([embed_summary, cost_summary], feed_dict=feed_dict)\n",
    "        writer.add_summary(cost_summary_run, epoch)\n",
    "        writer.add_summary(embed_run, epoch)\n",
    "    \n",
    "    train_end = time.time()\n",
    "    print(\"Training duration:%.2f\" % (train_end - train_start))\n",
    "     \n",
    "    print(\"\\r\\n-----start testing------------\")\n",
    "\n",
    "    start_index = 0\n",
    "    test_acc = []\n",
    "    #test_batch_size = len(test_labels)\n",
    "    pred_run = []\n",
    "    labels = []\n",
    "    \n",
    "    for i in range(total_test_batch):            \n",
    "        batch_indexs, batch_data, batch_labels = get_batch_data(shuffled_test_data, start_index, batch_size, num_labels)\n",
    "        start_index += batch_size   \n",
    "\n",
    "        feed_dict2 = {tf_input_data : batch_data, tf_labels : batch_labels}\n",
    "        predictions = session.run(\n",
    "                [tf_prediction], feed_dict=feed_dict2)\n",
    "\n",
    "        acc2 = accuracy(np.reshape(predictions,[batch_size, num_labels]), batch_labels)        \n",
    "        test_acc.append(np.mean(acc2))\n",
    "        \n",
    "        pred_run.append(np.argmax(np.reshape(predictions, (-1, num_labels),1)))\n",
    "        labels.append(np.argmax(np.reshape(batch_labels, (-1, num_labels)),1))    \n",
    "    \n",
    "    confusion_matrix = session.run(tf.confusion_matrix(np.reshape(labels,(-1)), pred_run))\n",
    "        \n",
    "    test_end = time.time()\n",
    "    \n",
    "    print(\"Total test samples: %d\" % len(test_labels))\n",
    "    print(\"Test accuracy:%f%%\" % np.mean(acc3))        \n",
    "    print(\"Testing duration:%.2f\" % (test_end - train_end))\n",
    "    print(\"Confusion matrix:\")\n",
    "    print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_confusion_matrix(mat):\n",
    "    tn, fp, fn, tp = mat.reshape(4)\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    \n",
    "    neg_cnt = tn + fp\n",
    "    pos_cnt = tp + fn\n",
    "    \n",
    "    total_cnt = tn+fp+fn+tp\n",
    "    error = 1.0 * (fn + fp) / total_cnt\n",
    "    accuracy = 1.0 - error\n",
    "    tp = pos_cnt - fp\n",
    "    tn = neg_cnt - fn\n",
    "    tp_rate = 1.0 - 1.0 * fp / pos_cnt\n",
    "    fp_rate = 1.0 * fn / neg_cnt\n",
    "    specity = 1.0 - fp_rate\n",
    "    precision = 1.0 * tp /(pos_cnt + fn)\n",
    "    prevalance = 1.0 * pos_cnt / total_cnt\n",
    "    \n",
    "    matrix = {}\n",
    "    \n",
    "    matrix['Total'] = total_cnt\n",
    "    matrix['Acutal N'] = tn+fp\n",
    "    matrix['Acutal P'] = tp+fn    \n",
    "    matrix['TP'] = tp\n",
    "    matrix['TN'] = tn\n",
    "    matrix['FP'] = fp\n",
    "    matrix['FN'] = fn \n",
    "    matrix['Accuracy'] = accuracy\n",
    "    matrix['TP rate'] = tp_rate\n",
    "    matrix['FP rate'] = fp_rate\n",
    "    matrix['Specity'] = specity\n",
    "    matrix['Precision'] = precision\n",
    "    matrix['Prevalance'] = prevalance\n",
    "      \n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_confusion_matrix(matrix):\n",
    "    print '------ Confusion matrix --------'\n",
    "    tags = ['Total', 'Accuracy', 'Precision', \n",
    "            'TP', 'FP', 'TN', 'FN',\n",
    "            'TP rate', 'FP rate',\n",
    "           'Specity', 'Prevalance']\n",
    "    for tag in tags:\n",
    "        print tag, matrix[tag]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Confusion matrix --------\n",
      "Total 2000\n",
      "Accuracy 0.9085\n",
      "Precision 0.831180811808\n",
      "TP 901\n",
      "FP 99\n",
      "TN 916\n",
      "FN 84\n",
      "TP rate 0.901\n",
      "FP rate 0.084\n",
      "Specity 0.916\n",
      "Prevalance 0.5\n"
     ]
    }
   ],
   "source": [
    "mat_out = calc_confusion_matrix(confusion_matrix)\n",
    "print_confusion_matrix(mat_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f1c6a4e6a10>]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1c6ce9e090>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "costs = np.reshape(costs, -1)\n",
    "print(len(costs))\n",
    "plt.plot(costs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
