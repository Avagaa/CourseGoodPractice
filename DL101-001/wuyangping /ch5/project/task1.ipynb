{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The watermark extension is already loaded. To reload it, use:\n",
      "  %reload_ext watermark\n",
      "CPython 2.7.6\n",
      "IPython 5.2.2\n",
      "\n",
      "tensorflow 1.0.0\n",
      "numpy 1.12.0\n",
      "\n",
      "compiler   : GCC 4.8.4\n",
      "system     : Linux\n",
      "release    : 4.4.43-boot2docker\n",
      "machine    : x86_64\n",
      "processor  : x86_64\n",
      "CPU cores  : 1\n",
      "interpreter: 64bit\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -p tensorflow,numpy -v -m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import jieba\n",
    "from jieba import posseg as pseg\n",
    "from collections import defaultdict, Counter\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "NEG = 'N'\n",
    "POS = 'P'\n",
    "\n",
    "train_files = {}\n",
    "train_files[NEG] = 'neg_train.txt'\n",
    "train_files[POS] = 'pos_train.txt'\n",
    "\n",
    "test_files = {}\n",
    "test_files[NEG] = 'neg_test.txt'\n",
    "test_files[POS] = 'pos_test.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#读取文件，分词\n",
    "def load_file(file_name, line_num=0):\n",
    "    f = open(file_name, 'r')    \n",
    "    lines = f.readlines()\n",
    "    cnt = len(lines)\n",
    "    if line_num >0:\n",
    "        cnt = line_num\n",
    "    f.close()\n",
    "    segs = []\n",
    "    seg_lines = []\n",
    "    for line in lines[:cnt]:\n",
    "        line = line.strip()\n",
    "        words = pseg.cut(line)\n",
    "        seg_per_line = []\n",
    "        for (key, flag) in words:\n",
    "            if flag == 'x':\n",
    "                continue           \n",
    "            segs.append(key)\n",
    "            seg_per_line.append(key)\n",
    "        seg_lines.append(seg_per_line)\n",
    "    return segs, seg_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def load_train_dataset(input_data, line_num=0):\n",
    "    segs = {}\n",
    "    seg_lines = {}\n",
    "    for k, v in input_data.items():\n",
    "         segs[k], seg_lines[k] = load_file(v, line_num)\n",
    "    return segs, seg_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136.87362504\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "segs_dict, seg_lines_dict = load_train_dataset(train_files)\n",
    "\n",
    "t1 = time.time()\n",
    "print(t1-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "449708\n",
      "508469\n",
      "13003\n",
      "11583\n"
     ]
    }
   ],
   "source": [
    "print(len(segs_dict[NEG]))\n",
    "print(len(segs_dict[POS]))\n",
    "print(len(seg_lines_dict[NEG]))\n",
    "print(len(seg_lines_dict[POS]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "UNKNOWN_WORD = u'UNK'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#建立vocabulary dict\n",
    "def build_word_dict(input_segs):\n",
    "    all_segs = []\n",
    "    temp = []\n",
    "    for (k, v) in input_segs.items():\n",
    "        all_segs.extend(v)\n",
    "    word_cnt = Counter(all_segs)\n",
    "    word_dict = {}\n",
    "    word_dict[UNKNOWN_WORD] = 0\n",
    "    index_dict = {}\n",
    "    index_dict[0] = UNKNOWN_WORD\n",
    "    i = 1\n",
    "    for (k, v) in word_cnt.items():\n",
    "        word_dict[k] = i\n",
    "        index_dict[i] = k\n",
    "        i += 1\n",
    "    return word_dict, index_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "all_word_dict, all_index_dict = build_word_dict(segs_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37739\n",
      "37739\n"
     ]
    }
   ],
   "source": [
    "print(len(all_word_dict))\n",
    "print(len(all_index_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#把语句转换为词索引\n",
    "def build_line_data(lines, word_dict, isTestdata=False):\n",
    "    lines_index = {}\n",
    "    labels_index = {}\n",
    "    i = 0\n",
    "    max_len = 0\n",
    "    for (k,v) in lines.items():\n",
    "        label = 0\n",
    "        if (k==POS):\n",
    "            label = 1\n",
    "        for line in v:\n",
    "            seg_index = []\n",
    "            labels_index[i] = label            \n",
    "            for word in line:\n",
    "                if isTestdata:                    \n",
    "                    if word in word_dict.keys():\n",
    "                        seg_index.append(word_dict[word])\n",
    "                    else:\n",
    "                        seg_index.append(0)\n",
    "                else:\n",
    "                    seg_index.append(word_dict[word])\n",
    "            lines_index[i] = seg_index\n",
    "            if (max_len < len(seg_index)):\n",
    "                max_len = len(seg_index)                \n",
    "            i+=1\n",
    "    return max_len, lines_index, labels_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "max_sentence_len, train_sentences, train_labels = build_line_data(seg_lines_dict, all_word_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1479\n",
      "24586\n",
      "24586\n",
      "19568\n",
      "5018\n",
      "20.4099894249\n"
     ]
    }
   ],
   "source": [
    "print(max_sentence_len)\n",
    "print(len(train_sentences))\n",
    "print(len(train_labels))\n",
    "\n",
    "i=0\n",
    "#句子长度设为60，训练语料中80%句子长度小于60\n",
    "SENTENCE_LEN=60\n",
    "\n",
    "for (k,s) in train_sentences.items():\n",
    "    \n",
    "    if len(s)<=SENTENCE_LEN:\n",
    "        i+=1\n",
    "\n",
    "total_sentence = len(train_sentences)\n",
    "print i\n",
    "outsider = total_sentence - i\n",
    "print outsider\n",
    "print 100.0 * outsider / total_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#把每行语料变成固定长度，短句后面补未命中词，长句直接截断\n",
    "def build_input_train_data(sentences, max_len):\n",
    "    input_ = {}\n",
    "    for (k,v) in sentences.items():\n",
    "        input_[k] = v[:max_len]\n",
    "        if (len(v) < max_len):\n",
    "            padding = [0] *(max_len-len(v))\n",
    "            input_[k].extend(padding)\n",
    "    return input_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "input_train_data = build_input_train_data(train_sentences, SENTENCE_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24586\n",
      "0 60 [6081, 14657, 22152, 13906, 28458, 2931, 20508, 30214, 26337, 3684, 24381, 17559, 6081, 3684, 14189, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "装 了 xp 系统 后 没有 出现 网友 说 的 驱动 不好 装 的 情况 \n",
      "1 60 [25006, 29693, 31863, 11894, 20102, 1512, 9923, 24385, 35532, 7467, 1489, 9660, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "总的来说 比较 干净 而且 地理位置 很 好 市区 繁华 地段 进出 方便 \n"
     ]
    }
   ],
   "source": [
    "print len(input_train_data)\n",
    "for (k,v) in input_train_data.items()[:2]:\n",
    "    print k, len(v), v\n",
    "    s = ''\n",
    "    for w in v:        \n",
    "        if w>0:\n",
    "            s += all_index_dict[w] + ' '\n",
    "    print s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56.6614871025\n"
     ]
    }
   ],
   "source": [
    "#读入测试语料\n",
    "t0 = time.time()\n",
    "test_segs, test_lines = load_train_dataset(test_files)\n",
    "t1 = time.time()\n",
    "print(t1-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1065.25038099\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "s_len, test_sentences, test_labels = build_line_data(test_lines, all_word_dict,isTestdata=True)\n",
    "t1 = time.time()\n",
    "print(t1-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1217\n",
      "10538\n",
      "10538\n"
     ]
    }
   ],
   "source": [
    "print(s_len)\n",
    "print(len(test_sentences))\n",
    "print(len(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "input_test_data = build_input_train_data(test_sentences, SENTENCE_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37739\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(all_word_dict)\n",
    "word_embed_size = 128\n",
    "\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def shuffle_data(input_data, input_labels):\n",
    "    output_data = []\n",
    "    for (index,v) in input_data.items():\n",
    "        label = input_labels[index]\n",
    "        output_data.append((index, label, v))\n",
    "    np.random.shuffle(output_data)\n",
    "    return output_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24586\n",
      "10538\n"
     ]
    }
   ],
   "source": [
    "#对输入数据作shuffle处理\n",
    "shuffled_train_data = shuffle_data(input_train_data, train_labels)\n",
    "shuffled_test_data = shuffle_data(input_test_data, test_labels)\n",
    "\n",
    "print(len(shuffled_train_data))\n",
    "print(len(shuffled_test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9354 0 [21124, 18655, 14527, 14657, 1512, 5864, 3684, 10681, 36155, 37539, 16910, 17601, 14657, 30237, 19330, 25066, 5049, 30237, 14657, 5665, 33140, 20907, 3684, 33198, 20138, 6683, 24679, 5234, 11978, 9413, 9200, 30237, 14657, 37144, 12039, 14864, 13945, 20650, 36401, 10371, 36058, 28954, 8914, 283, 26337, 3684, 0, 1736, 0, 7058, 34118, 23715, 10516, 21569, 20552, 425, 33230, 20307, 22259, 31414]\n",
      "有人 已经 作 了 很 详尽 的 评述 在 此 不再 重复 了 住 过 两次 第一次 住 了 一晚 半夜 到 的 第二天 一早 离开 只 觉 其 豪华 第二次 住 了 两 晚 有 时间 体会 觉得 这个 酒店 正如 很多 四川人 说 的 蛋 光 电梯 过道 都 有点 阴森 卫生间 大 而 无用 唯一 \n",
      "6401 0 [23002, 3043, 37555, 6554, 3796, 3200, 13886, 3684, 29693, 18454, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "但是 服务 不 象是 豪生 集团 管理 的 比较 差 \n",
      "7919 0 [17958, 32630, 3043, 17559, 35827, 7054, 34469, 37082, 24940, 15349, 2520, 34469, 30852, 21124, 30237, 9987, 7088, 3714, 36167, 26337, 2101, 24940, 14657, 12446, 1717, 9669, 32694, 22633, 26337, 35918, 15373, 30070, 13418, 9112, 29694, 15373, 14657, 16866, 26337, 13418, 9112, 29694, 33646, 11157, 9112, 15964, 31457, 30964, 22940, 9923, 7671, 35661, 22940, 31225, 25464, 4042, 27286, 14657, 21567, 24886]\n",
      "环境 吵 服务 不好 入 房 时 还给 错 房卡 进房 时 吓一跳 有人 住 赶紧 下楼 问 柜台 说 给 错 了 进 房间 烟位 非常 浓 说 要 来 做 无 菸 处理 来 了 竟然 说 无 菸 处理 就是 将 菸 灰 缸 拿掉 就 好 烟味 几天 就 会 散掉 真是 气死 了 跟 他 \n",
      "6936 0 [33512, 14442, 14778, 32266, 29614, 6386, 35918, 27029, 36867, 3684, 30223, 5090, 36538, 32893, 37555, 13299, 12972, 12450, 4065, 8957, 36867, 3684, 12438, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "vista 真难 用 自己 改 XP 要 把 硬盘 的 APCH 模式 改成 IDE 不 知道 这样 是不是 不能 发挥 硬盘 的 性能 \n",
      "885 1 [23651, 27934, 2825, 15602, 15851, 3684, 17070, 5980, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "实话实说 啊 我 不是 联想 的 托 哦 \n"
     ]
    }
   ],
   "source": [
    "\n",
    "for (i, k,v) in shuffled_test_data[:5]:\n",
    "    print i, k, v\n",
    "    s = ''\n",
    "    for w in v:        \n",
    "        if w>0:\n",
    "            s += all_index_dict[w] + ' '\n",
    "    print s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#将label变成one-hot matrix格式\n",
    "def get_label_matrix(input_label, num_l):\n",
    "    out_ = []\n",
    "    for label in input_label:\n",
    "        line = [0] * num_l\n",
    "        line[label] = 1\n",
    "        out_.append(line)    \n",
    "    return out_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#获取单批训练/测试数据\n",
    "def get_batch_data(input_data, index, size, num_l):\n",
    "    data_ = []\n",
    "    labels_ = []\n",
    "    indexs_ = []\n",
    "    for (i, k,v) in input_data[index:index+size]:\n",
    "        data_.append(v)\n",
    "        labels_.append(k)\n",
    "        indexs_.append(i)\n",
    "    return indexs_, data_, get_label_matrix(labels_, num_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2825, 7867, 31564, 24132, 28946, 20907, 36058, 36155, 23836, 27663, 35888, 14542, 34469, 27663, 14657, 20518, 8611, 14864, 14294, 23153, 2825, 34746, 4448, 34282, 34469, 22940, 8739, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [15299, 33458, 2955, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [23836, 993, 14294, 10516, 2525, 1717, 16648, 24492, 29202, 9660, 22536, 3684, 1700, 2517, 8800, 13981, 31414, 4326, 425, 7915, 12233, 17559, 7079, 26599, 15639, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [25721, 2825, 23488, 18874, 35683, 1717, 16478, 18304, 3451, 22595, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [32694, 10232, 3684, 21639, 36058, 5660, 36289, 20067, 21791, 27663, 36058, 23210, 9923, 23002, 1717, 3684, 7671, 32694, 33145, 9575, 30533, 1699, 3684, 22022, 1717, 10396, 34454, 14657, 27605, 6022, 20067, 3684, 36058, 2931, 12378, 33230, 5326, 23002, 19356, 36397, 10340, 27184, 3684, 2825, 21255, 29425, 28628, 3684, 36058, 3684, 25349, 36139, 15099, 25151, 2825, 4966, 7171, 20579, 2825, 10031]]\n",
      "[[0, 1], [0, 1], [0, 1], [0, 1], [1, 0]]\n",
      "我 下午 3 点 左右 到 酒店 在 前台 等 check in 时 等 了 十多分钟 才 有 服务员 替 我 办手续 不过 退房 时 就 很快 \n",
      "外观 稳重 大方 \n",
      "前台 楼层 服务员 都 不错 房间 安静 整洁 交通 方便 吃 的 周围 也 挺 多 唯一 不足 卫生间 地漏 设计 不好 导致 少量 积水 \n",
      "帮 我 拿 行李 送到 房间 开 空调 开灯 泡茶 \n",
      "非常 失望 的 一个 酒店 设施 相对 淄博 宾馆 等 酒店 算 好 但是 房间 的 烟味 非常 重 这 还是 安排 的 无烟 房间 这些 就算 了 本来 对 淄博 的 酒店 没有 太 大 期望 但是 没想到 还有 更 糟糕 的 我 预定 了去 济南 的 酒店 的 车 礼宾 部 告诉 我 是 280 元 我 确认 \n"
     ]
    }
   ],
   "source": [
    "i_, d_,l_ = get_batch_data(shuffled_train_data, 1, 5, 2)\n",
    "\n",
    "\n",
    "print d_\n",
    "print l_\n",
    "for d in d_:\n",
    "    s = ''\n",
    "    for w in d:        \n",
    "        if w>0:\n",
    "            s += all_index_dict[w] + ' '\n",
    "    print s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def accuracy(predictions, labels):\n",
    "      return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1))\n",
    "          / predictions.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"input_data:0\", shape=(?, 60), dtype=int32)\n",
      "Tensor(\"labels:0\", shape=(?, 2), dtype=int32)\n",
      "Tensor(\"embedding_lookup:0\", shape=(?, 60, 128), dtype=float32)\n",
      "Tensor(\"ExpandDims:0\", shape=(?, 60, 128, 1), dtype=float32)\n",
      "Tensor(\"conv:0\", shape=(?, 58, 1, 64), dtype=float32)\n",
      "Tensor(\"pool:0\", shape=(?, 1, 1, 64), dtype=float32)\n",
      "Tensor(\"dense/Tanh:0\", shape=(?, 1, 1, 10), dtype=float32)\n",
      "Tensor(\"output/Reshape_1:0\", shape=(?, 1, 1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "graph = tf.Graph()\n",
    "sentence_length = SENTENCE_LEN\n",
    "# max_pool\n",
    "with graph.as_default():\n",
    "    filter_num = 64\n",
    "    window_size = 3\n",
    "    num_labels = 2\n",
    "    num_fc_hidden = 10\n",
    "    \n",
    "    tf_input_data = tf.placeholder(tf.int32, shape=[None, sentence_length], name='input_data')    \n",
    "    tf_labels = tf.placeholder(tf.int32, shape=[None, num_labels], name='labels')\n",
    "    \n",
    "    word_embeds = tf.Variable(tf.random_uniform([vocab_size, word_embed_size], -1.0, 1.0), name=\"Word_embed\")\n",
    "    input_embeds = tf.nn.embedding_lookup(word_embeds, tf_input_data)\n",
    "   \n",
    "    tf_embeds_expand = tf.expand_dims(input_embeds, -1)\n",
    "    \n",
    "    print(tf_input_data)\n",
    "    print(tf_labels)\n",
    "    print(input_embeds)\n",
    "    print(tf_embeds_expand)\n",
    "\n",
    "    filter_shape = [window_size, word_embed_size, 1, filter_num]\n",
    "    # W 和 b 是卷积的参数\n",
    "    W = tf.Variable(tf.random_uniform(filter_shape, -1.0, 1.0), name=\"W\")\n",
    "    # bias 和 filter_num 个数是一样的\n",
    "    b = tf.Variable(tf.constant(0.0, shape=[filter_num]), name=\"b\")\n",
    "    # 步长为1，这里不做 Padding，因此句子太短的话可能要丢掉。可自行尝试加 padding（不加也不影响作业评分）\n",
    "    conv = tf.nn.conv2d(\n",
    "                    tf_embeds_expand,\n",
    "                    W,\n",
    "                    strides=[1, 1, 1, 1],\n",
    "                    padding=\"VALID\",\n",
    "                    name=\"conv\")\n",
    "    # 卷积出来的结果加上 bias\n",
    "    conv_hidden = tf.nn.tanh(tf.add(conv, b), name=\"tanh\")\n",
    "    \n",
    "    print(conv)\n",
    "\n",
    "    # 因为没有 padding，出来的结果个数是 sequence_length - window_size + 1，如果加了 padding 这里要对应更改。\n",
    "    pool = tf.nn.max_pool(\n",
    "                    conv_hidden,\n",
    "                    ksize=[1, sentence_length - window_size + 1, 1, 1],\n",
    "                    strides=[1, 1, 1, 1],\n",
    "                    padding='VALID',\n",
    "                    name=\"pool\")\n",
    "    \n",
    "    print(pool)\n",
    "    \n",
    "    #增加一个全连接层\n",
    "    fc = tf.layers.dense(pool, num_fc_hidden, activation=tf.nn.tanh)\n",
    "    \n",
    "    print(fc)\n",
    "   \n",
    "    raw_output = tf.layers.dense(fc, num_labels, name='output')\n",
    "    print(raw_output)\n",
    "    \n",
    "    \n",
    "    cost = tf.nn.softmax_cross_entropy_with_logits(logits=raw_output, labels=tf_labels)\n",
    "\n",
    "    train_step = tf.train.GradientDescentOptimizer(0.005).minimize(cost)\n",
    "    \n",
    "    tf_prediction = tf.nn.softmax(raw_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24586\n",
      "10538\n",
      "Initialized\n",
      "Train epoch:1, loss=0.758585, accuracy=51.041243%\n",
      "Train epoch:2, loss=0.751423, accuracy=51.472383%\n",
      "Train epoch:3, loss=0.734180, accuracy=51.716424%\n",
      "Train epoch:4, loss=0.734280, accuracy=51.915724%\n",
      "Train epoch:5, loss=0.735537, accuracy=52.058082%\n",
      "Train epoch:6, loss=0.735814, accuracy=52.285854%\n",
      "Train epoch:7, loss=0.735278, accuracy=52.472952%\n",
      "Train epoch:8, loss=0.734523, accuracy=52.712926%\n",
      "Train epoch:9, loss=0.733822, accuracy=52.916294%\n",
      "Train epoch:10, loss=0.733907, accuracy=53.099325%\n",
      "Train epoch:11, loss=0.737533, accuracy=53.428781%\n",
      "Train epoch:12, loss=0.731311, accuracy=53.542667%\n",
      "Train epoch:13, loss=0.728114, accuracy=53.774506%\n",
      "Train epoch:14, loss=0.719331, accuracy=54.075490%\n",
      "Train epoch:15, loss=0.712595, accuracy=54.230050%\n",
      "Train epoch:16, loss=0.713853, accuracy=54.400879%\n",
      "Train epoch:17, loss=0.713395, accuracy=54.661189%\n",
      "Train epoch:18, loss=0.708501, accuracy=54.962174%\n",
      "Train epoch:19, loss=0.706677, accuracy=54.937769%\n",
      "Train epoch:20, loss=0.705884, accuracy=55.202148%\n",
      "Train epoch:21, loss=0.704877, accuracy=55.344505%\n",
      "Train epoch:22, loss=0.704951, accuracy=55.641422%\n",
      "Train epoch:23, loss=0.723443, accuracy=55.804116%\n",
      "Train epoch:24, loss=0.725379, accuracy=55.958676%\n",
      "Train epoch:25, loss=0.729060, accuracy=56.084764%\n",
      "Train epoch:26, loss=0.731709, accuracy=56.385748%\n",
      "Train epoch:27, loss=0.726652, accuracy=56.450826%\n",
      "Train epoch:28, loss=0.721282, accuracy=56.617587%\n",
      "Train epoch:29, loss=0.721445, accuracy=56.715204%\n",
      "Train epoch:30, loss=0.722023, accuracy=56.906369%\n",
      "Train epoch:31, loss=0.722803, accuracy=57.069064%\n",
      "Train epoch:32, loss=0.714720, accuracy=57.268364%\n",
      "Train epoch:33, loss=0.711916, accuracy=57.435126%\n",
      "Train epoch:34, loss=0.710058, accuracy=57.532742%\n",
      "Train epoch:35, loss=0.708813, accuracy=57.610022%\n",
      "Train epoch:36, loss=0.709863, accuracy=57.683234%\n",
      "Train epoch:37, loss=0.708712, accuracy=57.911006%\n",
      "Train epoch:38, loss=0.707818, accuracy=57.963882%\n",
      "Train epoch:39, loss=0.710711, accuracy=58.004555%\n",
      "Train epoch:40, loss=0.697496, accuracy=58.061498%\n",
      "Train epoch:41, loss=0.697965, accuracy=58.248597%\n",
      "Train epoch:42, loss=0.698865, accuracy=58.354348%\n",
      "Train epoch:43, loss=0.698949, accuracy=58.464167%\n",
      "Train epoch:44, loss=0.698845, accuracy=58.569918%\n",
      "Train epoch:45, loss=0.697820, accuracy=58.598389%\n",
      "Train epoch:46, loss=0.698369, accuracy=58.716343%\n",
      "Train epoch:47, loss=0.698430, accuracy=58.736679%\n",
      "Train epoch:48, loss=0.699473, accuracy=58.842431%\n",
      "Train epoch:49, loss=0.699104, accuracy=59.033596%\n",
      "Train epoch:50, loss=0.699883, accuracy=59.049866%\n",
      "Train epoch:51, loss=0.698831, accuracy=59.074270%\n",
      "Train epoch:52, loss=0.694624, accuracy=59.025462%\n",
      "Train epoch:53, loss=0.694827, accuracy=59.188156%\n",
      "Train epoch:54, loss=0.692086, accuracy=59.460669%\n",
      "Train epoch:55, loss=0.692985, accuracy=59.436265%\n",
      "Train epoch:56, loss=0.691907, accuracy=59.452534%\n",
      "Train epoch:57, loss=0.689092, accuracy=59.623363%\n",
      "Train epoch:58, loss=0.685946, accuracy=59.810461%\n",
      "Train epoch:59, loss=0.684893, accuracy=59.786057%\n",
      "Train epoch:60, loss=0.684129, accuracy=59.773855%\n",
      "Train epoch:61, loss=0.683395, accuracy=59.993492%\n",
      "Train epoch:62, loss=0.682700, accuracy=59.899943%\n",
      "Train epoch:63, loss=0.681806, accuracy=59.993492%\n",
      "Train epoch:64, loss=0.681473, accuracy=60.139917%\n",
      "Train epoch:65, loss=0.681530, accuracy=60.176523%\n",
      "Train epoch:66, loss=0.681083, accuracy=60.294477%\n",
      "Train epoch:67, loss=0.681986, accuracy=60.379891%\n",
      "Train epoch:68, loss=0.680182, accuracy=60.436834%\n",
      "Train epoch:69, loss=0.681927, accuracy=60.505979%\n",
      "Train epoch:70, loss=0.682158, accuracy=60.660539%\n",
      "Train epoch:71, loss=0.684560, accuracy=60.331083%\n",
      "Train epoch:72, loss=0.677401, accuracy=60.473440%\n",
      "Train epoch:73, loss=0.679793, accuracy=60.640202%\n",
      "Train epoch:74, loss=0.680008, accuracy=60.729684%\n",
      "Train epoch:75, loss=0.681482, accuracy=60.713414%\n",
      "Train epoch:76, loss=0.680723, accuracy=60.916782%\n",
      "Train epoch:77, loss=0.681944, accuracy=61.189295%\n",
      "Train epoch:78, loss=0.691040, accuracy=61.290979%\n",
      "Train epoch:79, loss=0.681901, accuracy=61.433336%\n",
      "Train epoch:80, loss=0.680962, accuracy=61.221834%\n",
      "Train epoch:81, loss=0.698780, accuracy=61.535020%\n",
      "Train epoch:82, loss=0.695992, accuracy=61.518751%\n",
      "Train epoch:83, loss=0.696123, accuracy=61.929553%\n",
      "Train epoch:84, loss=0.694773, accuracy=61.921419%\n",
      "Train epoch:85, loss=0.697467, accuracy=62.088180%\n",
      "Train epoch:86, loss=0.692518, accuracy=62.128854%\n",
      "Train epoch:87, loss=0.690474, accuracy=62.023103%\n",
      "Train epoch:88, loss=0.682497, accuracy=62.104450%\n",
      "Train epoch:89, loss=0.701046, accuracy=61.962092%\n",
      "Train epoch:90, loss=0.701840, accuracy=62.149191%\n",
      "Train epoch:91, loss=0.669589, accuracy=62.393232%\n",
      "Train epoch:92, loss=0.680498, accuracy=62.458310%\n",
      "Train epoch:93, loss=0.674140, accuracy=62.710486%\n",
      "Train epoch:94, loss=0.673362, accuracy=62.974864%\n",
      "Train epoch:95, loss=0.684687, accuracy=63.117221%\n",
      "Train epoch:96, loss=0.674565, accuracy=63.259579%\n",
      "Train epoch:97, loss=0.659927, accuracy=63.271781%\n",
      "Train epoch:98, loss=0.681267, accuracy=63.292117%\n",
      "Train epoch:99, loss=0.700938, accuracy=63.523957%\n",
      "Train epoch:100, loss=0.665567, accuracy=63.759863%\n",
      "Train epoch:101, loss=0.738968, accuracy=63.739527%\n",
      "Train epoch:102, loss=0.720662, accuracy=63.788335%\n",
      "Train epoch:103, loss=0.679114, accuracy=64.089319%\n",
      "Train epoch:104, loss=0.732533, accuracy=64.247946%\n",
      "Train epoch:105, loss=0.677758, accuracy=64.512324%\n",
      "Train epoch:106, loss=0.697244, accuracy=64.532661%\n",
      "Train epoch:107, loss=0.704610, accuracy=64.500122%\n",
      "Train epoch:108, loss=0.681827, accuracy=64.223542%\n",
      "Train epoch:109, loss=0.728088, accuracy=64.683153%\n",
      "Train epoch:110, loss=0.709576, accuracy=65.122427%\n",
      "Train epoch:111, loss=0.713977, accuracy=65.187505%\n",
      "Train epoch:112, loss=0.706995, accuracy=65.366469%\n",
      "Train epoch:113, loss=0.706966, accuracy=65.521028%\n",
      "Train epoch:114, loss=0.758188, accuracy=66.025380%\n",
      "Train epoch:115, loss=0.723196, accuracy=65.915562%\n",
      "Train epoch:116, loss=0.753671, accuracy=66.452453%\n",
      "Train epoch:117, loss=0.748663, accuracy=66.448385%\n",
      "Train epoch:118, loss=0.723018, accuracy=66.301960%\n",
      "Train epoch:119, loss=0.729412, accuracy=66.472789%\n",
      "Train epoch:120, loss=0.751435, accuracy=66.672090%\n",
      "Train epoch:121, loss=0.678973, accuracy=67.099162%\n",
      "Train epoch:122, loss=0.752409, accuracy=67.375742%\n",
      "Train epoch:123, loss=0.757230, accuracy=67.692996%\n",
      "Train epoch:124, loss=0.742535, accuracy=68.006182%\n",
      "Train epoch:125, loss=0.748439, accuracy=68.095664%\n",
      "Train epoch:126, loss=0.810667, accuracy=68.111934%\n",
      "Train epoch:127, loss=0.806782, accuracy=68.416985%\n",
      "Train epoch:128, loss=0.765940, accuracy=69.031156%\n",
      "Train epoch:129, loss=0.762807, accuracy=69.173513%\n",
      "Train epoch:130, loss=0.770177, accuracy=69.486700%\n",
      "Train epoch:131, loss=0.809696, accuracy=69.913772%\n",
      "Train epoch:132, loss=0.835746, accuracy=70.475067%\n",
      "Train epoch:133, loss=0.800557, accuracy=70.365249%\n",
      "Train epoch:134, loss=0.726646, accuracy=70.096803%\n",
      "Train epoch:135, loss=0.747644, accuracy=70.348979%\n",
      "Train epoch:136, loss=0.776931, accuracy=71.272269%\n",
      "Train epoch:137, loss=0.764552, accuracy=71.439030%\n",
      "Train epoch:138, loss=0.799410, accuracy=72.199626%\n",
      "Train epoch:139, loss=0.823013, accuracy=72.354185%\n",
      "Train epoch:140, loss=0.819083, accuracy=72.577890%\n",
      "Train epoch:141, loss=0.895294, accuracy=73.086309%\n",
      "Train epoch:142, loss=0.006423, accuracy=73.834703%\n",
      "Train epoch:143, loss=0.003969, accuracy=74.188563%\n",
      "Train epoch:144, loss=0.003743, accuracy=74.969495%\n",
      "Train epoch:145, loss=0.002517, accuracy=75.087448%\n",
      "Train epoch:146, loss=0.009031, accuracy=75.319287%\n",
      "Train epoch:147, loss=0.016083, accuracy=75.441308%\n",
      "Train epoch:148, loss=0.003193, accuracy=75.827707%\n",
      "Train epoch:149, loss=0.004035, accuracy=76.633043%\n",
      "Train epoch:150, loss=0.004152, accuracy=76.767266%\n",
      "Train epoch:151, loss=0.004983, accuracy=76.848613%\n",
      "Train epoch:152, loss=0.003669, accuracy=77.422110%\n",
      "Train epoch:153, loss=0.003271, accuracy=77.889856%\n",
      "Train epoch:154, loss=0.002934, accuracy=78.015944%\n",
      "Train epoch:155, loss=0.003269, accuracy=78.353535%\n",
      "Train epoch:156, loss=0.002974, accuracy=79.065322%\n",
      "Train epoch:157, loss=0.003385, accuracy=79.175140%\n",
      "Train epoch:158, loss=0.003305, accuracy=79.850321%\n",
      "Train epoch:159, loss=0.003371, accuracy=80.277394%\n",
      "Train epoch:160, loss=0.003273, accuracy=80.749207%\n",
      "Train epoch:161, loss=0.003727, accuracy=80.895632%\n",
      "Train epoch:162, loss=0.003857, accuracy=81.343041%\n",
      "Train epoch:163, loss=0.003529, accuracy=81.257626%\n",
      "Train epoch:164, loss=0.003507, accuracy=81.062393%\n",
      "Train epoch:165, loss=0.004455, accuracy=81.119336%\n",
      "Train epoch:166, loss=0.005203, accuracy=81.591149%\n",
      "Train epoch:167, loss=0.003705, accuracy=82.363947%\n",
      "Train epoch:168, loss=0.003747, accuracy=82.660864%\n",
      "Train epoch:169, loss=0.004161, accuracy=82.758480%\n",
      "Train epoch:170, loss=0.004029, accuracy=83.275035%\n",
      "Train epoch:171, loss=0.003987, accuracy=83.401123%\n",
      "Train epoch:172, loss=0.003892, accuracy=83.889205%\n",
      "Train epoch:173, loss=0.003406, accuracy=83.990889%\n",
      "Train epoch:174, loss=0.003450, accuracy=84.092573%\n",
      "Train epoch:175, loss=0.003345, accuracy=84.096640%\n",
      "Train epoch:176, loss=0.003150, accuracy=84.792158%\n",
      "Train epoch:177, loss=0.003841, accuracy=85.056536%\n",
      "Train epoch:178, loss=0.004366, accuracy=84.767754%\n",
      "Train epoch:179, loss=0.004001, accuracy=85.036199%\n",
      "Train epoch:180, loss=0.004030, accuracy=85.499878%\n",
      "Train epoch:181, loss=0.003752, accuracy=85.532417%\n",
      "Train epoch:182, loss=0.003943, accuracy=85.731717%\n",
      "Train epoch:183, loss=0.003900, accuracy=85.987961%\n",
      "Train epoch:184, loss=0.004453, accuracy=86.358090%\n",
      "Train epoch:185, loss=0.004885, accuracy=86.581795%\n",
      "Train epoch:186, loss=0.005083, accuracy=86.789230%\n",
      "Train epoch:187, loss=0.006018, accuracy=87.061742%\n",
      "Train epoch:188, loss=0.005292, accuracy=87.435939%\n",
      "Train epoch:189, loss=0.005724, accuracy=87.391198%\n",
      "Train epoch:190, loss=0.005085, accuracy=87.728789%\n",
      "Train epoch:191, loss=0.005581, accuracy=87.513219%\n",
      "Train epoch:192, loss=0.006039, accuracy=87.529488%\n",
      "Train epoch:193, loss=0.005078, accuracy=87.248841%\n",
      "Train epoch:194, loss=0.004743, accuracy=87.435939%\n",
      "Train epoch:195, loss=0.005117, accuracy=87.732856%\n",
      "Train epoch:196, loss=0.004645, accuracy=87.716587%\n",
      "Train epoch:197, loss=0.004734, accuracy=88.241276%\n",
      "Train epoch:198, loss=0.004244, accuracy=88.452778%\n",
      "Train epoch:199, loss=0.004643, accuracy=88.643944%\n",
      "Train epoch:200, loss=0.004712, accuracy=88.887985%\n",
      "Train epoch:201, loss=0.004139, accuracy=89.266249%\n",
      "Train epoch:202, loss=0.004815, accuracy=89.229643%\n",
      "Train epoch:203, loss=0.004265, accuracy=89.209306%\n",
      "Train epoch:204, loss=0.004353, accuracy=89.526560%\n",
      "Train epoch:205, loss=0.005040, accuracy=89.363866%\n",
      "Train epoch:206, loss=0.004543, accuracy=89.550964%\n",
      "Train epoch:207, loss=0.004817, accuracy=89.347596%\n",
      "Train epoch:208, loss=0.005364, accuracy=89.697389%\n",
      "Train epoch:209, loss=0.004506, accuracy=89.542829%\n",
      "Train epoch:210, loss=0.005994, accuracy=89.819409%\n",
      "Train epoch:211, loss=0.005129, accuracy=89.624176%\n",
      "Train epoch:212, loss=0.005140, accuracy=89.908891%\n",
      "Train epoch:213, loss=0.004594, accuracy=89.689254%\n",
      "Train epoch:214, loss=0.004971, accuracy=90.157000%\n",
      "Train epoch:215, loss=0.005209, accuracy=90.384772%\n",
      "Train epoch:216, loss=0.005078, accuracy=90.502725%\n",
      "Train epoch:217, loss=0.005622, accuracy=90.734564%\n",
      "Train epoch:218, loss=0.005451, accuracy=90.608476%\n",
      "Train epoch:219, loss=1.196861, accuracy=90.771171%\n",
      "Train epoch:220, loss=0.006383, accuracy=90.848450%\n",
      "Train epoch:221, loss=0.005296, accuracy=90.592207%\n",
      "Train epoch:222, loss=0.004967, accuracy=90.815911%\n",
      "Train epoch:223, loss=0.005637, accuracy=90.807777%\n",
      "Train epoch:224, loss=0.006171, accuracy=90.799642%\n",
      "Train epoch:225, loss=0.006690, accuracy=91.116896%\n",
      "Train epoch:226, loss=0.006566, accuracy=91.295859%\n",
      "Train epoch:227, loss=0.005895, accuracy=91.710730%\n",
      "Train epoch:228, loss=0.005230, accuracy=91.857154%\n",
      "Train epoch:229, loss=0.005553, accuracy=91.690393%\n",
      "Train epoch:230, loss=0.004067, accuracy=91.674123%\n",
      "Train epoch:231, loss=0.004436, accuracy=91.735134%\n",
      "Train epoch:232, loss=0.004454, accuracy=91.726999%\n",
      "Train epoch:233, loss=0.004839, accuracy=91.824616%\n",
      "Train epoch:234, loss=0.004009, accuracy=92.019849%\n",
      "Train epoch:235, loss=0.004049, accuracy=92.064590%\n",
      "Train epoch:236, loss=0.005204, accuracy=91.922232%\n",
      "Train epoch:237, loss=0.004788, accuracy=92.202880%\n",
      "Train epoch:238, loss=0.003979, accuracy=92.284227%\n",
      "Train epoch:239, loss=0.003226, accuracy=92.426584%\n",
      "Train epoch:240, loss=0.003907, accuracy=92.394045%\n",
      "Train epoch:241, loss=0.003166, accuracy=92.170341%\n",
      "Train epoch:242, loss=0.003320, accuracy=92.158139%\n",
      "Train epoch:243, loss=0.004070, accuracy=92.300496%\n",
      "Train epoch:244, loss=0.005767, accuracy=92.097128%\n",
      "Train epoch:245, loss=0.004013, accuracy=92.080859%\n",
      "Train epoch:246, loss=0.005223, accuracy=92.398113%\n",
      "Train epoch:247, loss=0.003619, accuracy=92.695030%\n",
      "Train epoch:248, loss=0.003210, accuracy=92.605548%\n",
      "Train epoch:249, loss=0.003371, accuracy=92.564874%\n",
      "Train epoch:250, loss=0.003050, accuracy=92.776377%\n",
      "Train epoch:251, loss=0.003521, accuracy=92.760107%\n",
      "Train epoch:252, loss=0.003697, accuracy=93.016351%\n",
      "Train epoch:253, loss=0.003126, accuracy=93.191247%\n",
      "Train epoch:254, loss=0.003093, accuracy=93.349874%\n",
      "Train epoch:255, loss=0.002983, accuracy=93.520703%\n",
      "Train epoch:256, loss=0.003270, accuracy=93.419019%\n",
      "Train epoch:257, loss=0.003228, accuracy=93.065159%\n",
      "Train epoch:258, loss=0.002800, accuracy=93.240055%\n",
      "Train epoch:259, loss=0.004088, accuracy=93.260392%\n",
      "Train epoch:260, loss=0.006718, accuracy=92.939071%\n",
      "Train epoch:261, loss=0.005822, accuracy=92.963475%\n",
      "Train epoch:262, loss=0.004566, accuracy=93.138371%\n",
      "Train epoch:263, loss=0.002961, accuracy=93.240055%\n",
      "Train epoch:264, loss=0.003644, accuracy=93.113967%\n",
      "Train epoch:265, loss=0.003392, accuracy=93.260392%\n",
      "Train epoch:266, loss=0.003731, accuracy=92.475392%\n",
      "Train epoch:267, loss=0.005132, accuracy=92.369641%\n",
      "Train epoch:268, loss=0.004395, accuracy=92.662491%\n",
      "Train epoch:269, loss=0.004663, accuracy=92.739771%\n",
      "Train epoch:270, loss=0.003783, accuracy=93.150573%\n",
      "Train epoch:271, loss=0.002702, accuracy=93.329537%\n",
      "Train epoch:272, loss=0.002417, accuracy=93.512568%\n",
      "Train epoch:273, loss=0.003082, accuracy=93.532905%\n",
      "Train epoch:274, loss=0.003895, accuracy=93.691532%\n",
      "Train epoch:275, loss=0.003967, accuracy=93.577646%\n",
      "Train epoch:276, loss=0.002435, accuracy=93.805418%\n",
      "Train epoch:277, loss=0.002873, accuracy=93.772879%\n",
      "Train epoch:278, loss=0.001960, accuracy=93.980314%\n",
      "Train epoch:279, loss=0.001486, accuracy=94.033190%\n",
      "Train epoch:280, loss=0.001828, accuracy=94.138941%\n",
      "Train epoch:281, loss=0.001129, accuracy=94.281298%\n",
      "Train epoch:282, loss=0.001334, accuracy=94.037257%\n",
      "Train epoch:283, loss=0.003458, accuracy=94.130806%\n",
      "Train epoch:284, loss=0.004690, accuracy=94.061661%\n",
      "Train epoch:285, loss=0.005412, accuracy=94.122671%\n",
      "Train epoch:286, loss=0.005758, accuracy=94.155210%\n",
      "Train epoch:287, loss=0.004288, accuracy=94.094200%\n",
      "Train epoch:288, loss=0.003358, accuracy=94.191816%\n",
      "Train epoch:289, loss=0.004618, accuracy=93.817620%\n",
      "Train epoch:290, loss=0.003570, accuracy=93.968112%\n",
      "Train epoch:291, loss=0.003290, accuracy=93.805418%\n",
      "Train epoch:292, loss=0.003049, accuracy=93.630521%\n",
      "Train epoch:293, loss=0.004135, accuracy=93.882697%\n",
      "Train epoch:294, loss=0.002445, accuracy=94.382982%\n",
      "Train epoch:295, loss=0.001879, accuracy=94.513138%\n",
      "Train epoch:296, loss=0.000703, accuracy=94.382982%\n",
      "Train epoch:297, loss=0.000496, accuracy=94.509070%\n",
      "Train epoch:298, loss=0.000531, accuracy=94.692101%\n",
      "Train epoch:299, loss=0.002412, accuracy=94.614821%\n",
      "Train epoch:300, loss=0.002810, accuracy=94.496868%\n",
      "\n",
      "-----start testing------------\n",
      "Total test samples: 10538\n",
      "Test accuracy:85.965079%\n",
      "Testing completed-------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "epoches = 300\n",
    "batch_size = 1\n",
    "display_steps = 10000\n",
    "num_labels = 2\n",
    "\n",
    "total_train_batch = len(shuffled_train_data) / batch_size\n",
    "if len(input_train_data) % batch_size > 0:\n",
    "    total_train_batch += 1\n",
    "print(total_train_batch)\n",
    "    \n",
    "total_test_batch = len(shuffled_test_data) / batch_size\n",
    "if len(shuffled_test_data) % batch_size > 0:\n",
    "    total_test_batch += 1\n",
    "print(total_test_batch)\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    tf.global_variables_initializer().run()\n",
    "    print(\"Initialized\")\n",
    "    \n",
    "    costs = []\n",
    "    for epoch in range(epoches):\n",
    "        start_index = 0\n",
    "        \n",
    "        train_acc = []\n",
    "        for i in range(total_train_batch):            \n",
    "            batch_index, batch_data, batch_labels = get_batch_data(shuffled_train_data, start_index, batch_size, num_labels) \n",
    "           \n",
    "            start_index += batch_size\n",
    "            \n",
    "            feed_dict = {tf_input_data : batch_data, tf_labels : batch_labels}\n",
    "            _, c, predictions = session.run(\n",
    "              [train_step, cost, tf_prediction], feed_dict=feed_dict)\n",
    "            #costs.append(c)\n",
    "            \n",
    "            acc = accuracy(np.reshape(predictions,[batch_size,2]), batch_labels)\n",
    "            train_acc.append(np.mean(acc))\n",
    "        \n",
    "            #if (i+1) % display_steps == 0:\n",
    "            #    print(\"Loss at step %d: %f\" % (i+1, c))\n",
    "            #    print(\"Training accuracy: %f%%\" % (np.mean(train_acc)))\n",
    "                #print(acc)\n",
    "                #print(predictions)\n",
    "                #print(batch_labels)\n",
    "                #costs.append(c)\n",
    "                \n",
    "        costs.append(c)    \n",
    "        print(\"Train epoch:%d, loss=%f, accuracy=%f%%\" % (epoch, c, np.mean(train_acc)))\n",
    "                \n",
    "    print(\"\\r\\n-----start testing------------\")\n",
    "\n",
    "    start_index = 0\n",
    "    test_acc = []\n",
    "    for i in range(total_test_batch):            \n",
    "        batch_indexs, batch_data, batch_labels = get_batch_data(shuffled_test_data, start_index, batch_size, num_labels\n",
    "\n",
    "        start_index += batch_size   \n",
    "\n",
    "        feed_dict2 = {tf_input_data : batch_data, tf_labels : batch_labels}\n",
    "        predictions = session.run(\n",
    "                [tf_prediction], feed_dict=feed_dict2)\n",
    "\n",
    "        acc2 = accuracy(np.reshape(predictions,[batch_size,2]), batch_labels)        \n",
    "        test_acc.append(np.mean(acc2))\n",
    "\n",
    "            #if (i+1) % display_steps == 0:\n",
    "            #        print(\"Accuracy after test step %d: %f%%\" % (i+1, np.mean(test_acc)))\n",
    "    \n",
    "        \n",
    "    print(\"Total test samples: %d\" % len(test_acc))\n",
    "    print(\"Test accuracy:%f%%\" % np.mean(test_acc))        \n",
    "    print(\"Testing completed-------\\r\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f0eb2bc5c50>]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDSSdjuAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0eb0cc5a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "costs = np.reshape(costs, -1)\n",
    "print(len(costs))\n",
    "plt.plot(costs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
