{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 运行环境说明："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "系统版本是：debian 8.7 \n",
      "Python 版本是：3.5.2\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import platform\n",
    "\n",
    "\n",
    "print(\"系统版本是：{}\".format(' '.join(platform.linux_distribution())))\n",
    "print(\"Python 版本是：{}\".format(sys.version.split()[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 2w 作业\n",
    "\n",
    "* 任务1：贝叶斯公式的运用    \n",
    "\t利用贝叶斯公式，说明为什么 $P(y|w1, w2) ≠ P(y|w1)P(y|w2)$（即使做了独立假设）\n",
    "    \n",
    "* 任务2：实现 Naive Bayes 方法    \n",
    "\t请你用 Python 实现 Naive Bayes 方法，并在给定的数据集上验证数据。具体要求如下：    \n",
    "    在「训练数据」上拟合一个 Naive Bayes 模型。在训练时模型不能「看见」任何测试数据的信息。    \n",
    "    训练完成后，在测试数据上进行测试。评估标准为你的模型在测试数据上的混淆矩阵（Confusion Matrix）结果。    \n",
    "    根据混淆矩阵的结果，分析一下你模型的表现。    \n",
    "\t参考概念：混淆矩阵 Simple guide to confusion matrix terminology    \n",
    "    \n",
    "* 任务3：实现 Gradient Descent 算法    \n",
    "\t通过梯度下降法，自己实现一种通用的给定数据找到 y = wx + b 中最优的 w 和 b 的程序，并用加噪音数据验证效果。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 贝叶斯公式的运用\n",
    "\n",
    "$P(y|w_1) = \\frac{P(w_1|y)P(y)}{P(w_1)}$\n",
    "\n",
    "$P(y|w_2) = \\frac{P(w_2|y)P(y)}{p(w_2)}$\n",
    "\n",
    "$P(y|w_1)P(y|w_2) = \\frac{P(w_1|y)P(w_2|y)P(y)^2}{p(w_1)P(w_2)}$\n",
    "\n",
    "$P(y|w_1,w_2) = \\frac{P(w_1,w_2|y)p(y)}{P(w_1,w_2)}$\n",
    "\n",
    "从上面两个公式可以看出，哪怕做了独立假设，\n",
    "\n",
    "$P(y|w_1).P(y|w_2) 也是不等于 $P(y|w_1,w_2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 2. 实现 Naive Bayes 方法\n",
    "\n",
    "### 贝叶斯公式和应用：\n",
    "\n",
    "贝叶斯的核心是通过先验概率和逆条件概率从而求出条件概率：\n",
    "\n",
    "* 正面和负面分别占比，是其中之一的先验概率\n",
    "* 已知文本的情感，各个词所占的概率是逆条件概率\n",
    "\n",
    "### 作业思路和解决步骤：\n",
    "\n",
    "1. 分词，并剔除停止词(影响情感)\n",
    "2. 统计各个词在正负面所占的概率，并计算他们的联合概率(考虑独立性)\n",
    "3. 生成模型(还要细化。。。)\n",
    "\n",
    "\n",
    "### Refrences:\n",
    "\n",
    "* [Bayesian Classification withInsect examples](http://www.cs.ucr.edu/~eamonn/CE/Bayesian%20Classification%20withInsect_examples.pdf) 这个 Slide 超赞"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 2.1 读取并分词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import string\n",
    "import re\n",
    "import pyprind\n",
    "import multiprocessing\n",
    "import jieba\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "首先用 linux 命令简单查看下数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1\t装了xp系统后，没有出现网友说的驱动不好装的情况\r\n",
      "     2\t总的来说,比较干净,而且地理位置很好,市区繁华地段.进出方便.\r\n",
      "     3\t2、散热很好，这个不用解释了\r\n",
      "     4\t温度控制的非常好，噪音也不大，\r\n",
      "     5\t早上6点多有\"按摩\"电话过来，^_^；不想被打扰的话拔掉电话插头吧\r\n"
     ]
    }
   ],
   "source": [
    "!head -n 5 data/pos_train.txt | nl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "发现数据每一行都是针对不同商品且不一样的评论，所以一行其实就是一个情绪。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "参考 [rasbt/python-machine-learning-book](https://github.com/rasbt/python-machine-learning-book) 把每行读取出来，且生成标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0%                          100%\n",
      "[############################# ] | ETA: 00:00:02"
     ]
    }
   ],
   "source": [
    "basepath = './data'\n",
    "\n",
    "labels = {'pos_train': 1, 'neg_train':0, 'neg_test': '0?', 'pos_test': '1?'}\n",
    "pbar = pyprind.ProgBar(36000)  # 迭代次数\n",
    "df = pd.DataFrame()\n",
    "for i in labels:\n",
    "    path = os.path.join(basepath, i + '.txt')\n",
    "    with open(path) as f:\n",
    "        lines = (line.strip() for line in f.readlines())\n",
    "    for line in lines:\n",
    "        df = df.append([[line, labels[i]]], ignore_index=True)\n",
    "        pbar.update()\n",
    "df.columns = ['review', 'sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>光驱不大好，给人想散架的的感觉。哈哈，总体上还可以。装系统有点绕手，害的我装了一个小时。</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2，散热是有点问题，CPU cache 是小了点。不能运行很大的软件。</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>上月入住，将近500元一天的房费，卫生间很小，像经济性酒店。走廊房间一股霉味。浴缸下水管漏水...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CTRIP上怎么让它这么忽悠顾客的 ？！！！！！！！</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>于丹教授讲《论语》不能很正确地反映儒家原来的思想，她除了讲《论语》不好外，别的还可以。</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0       光驱不大好，给人想散架的的感觉。哈哈，总体上还可以。装系统有点绕手，害的我装了一个小时。         0\n",
       "1                2，散热是有点问题，CPU cache 是小了点。不能运行很大的软件。         0\n",
       "2  上月入住，将近500元一天的房费，卫生间很小，像经济性酒店。走廊房间一股霉味。浴缸下水管漏水...         0\n",
       "3                         CTRIP上怎么让它这么忽悠顾客的 ？！！！！！！！         0\n",
       "4        于丹教授讲《论语》不能很正确地反映儒家原来的思想，她除了讲《论语》不好外，别的还可以。         0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### 分词：\n",
    "\n",
    "选择一种多进程的 Apply 方式来分词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def _apply_df(args):\n",
    "    df, func, num, kwargs = args\n",
    "    return num, df.apply(func, **kwargs)\n",
    "\n",
    "def apply_by_multiprocessing(df,func,**kwargs):\n",
    "    workers=kwargs.pop('workers')\n",
    "    pool = multiprocessing.Pool(processes=workers)\n",
    "    result = pool.map(_apply_df, [(d, func, i, kwargs) for i,d in enumerate(np.array_split(df, workers))])\n",
    "    pool.close()\n",
    "    result=sorted(result,key=lambda x:x[0])\n",
    "    return pd.concat([i[1] for i in result])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 1.004 seconds.\n",
      "Prefix dict has been built succesfully.\n",
      "Loading model cost 1.022 seconds.\n",
      "Prefix dict has been built succesfully.\n",
      "Loading model cost 1.069 seconds.\n",
      "Prefix dict has been built succesfully.\n",
      "Loading model cost 1.104 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "df['cut_words'] = apply_by_multiprocessing(df.review, jieba.lcut, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>cut_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35119</th>\n",
       "      <td>很多人一直强调研究红楼，我其实真的有点搞不懂为什么一定要研究到底不可。就像刘心武说秦可卿是太...</td>\n",
       "      <td>1?</td>\n",
       "      <td>[很多, 人, 一直, 强调, 研究, 红楼, ，, 我, 其实, 真的, 有点, 搞不懂,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35120</th>\n",
       "      <td>“主管会计必读”这本书独具匠心，一改革以往这类版本书的编排风格，从内容上编排上更加贴近实际工...</td>\n",
       "      <td>1?</td>\n",
       "      <td>[“, 主管, 会计, 必读, ”, 这, 本书, 独具匠心, ，, 一, 改革, 以往, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35121</th>\n",
       "      <td>对明朝的历史基本上是空白的，因为办公室里的一个玩笑，开始接触这本书，越看越喜欢，眼前浮现出一...</td>\n",
       "      <td>1?</td>\n",
       "      <td>[对, 明朝, 的, 历史, 基本上, 是, 空白, 的, ，, 因为, 办公室, 里, 的...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35122</th>\n",
       "      <td>昨天买了这个本本，收到后一看开始搞活动送内存，送硬盘了....订单完成了也没有办法了...感...</td>\n",
       "      <td>1?</td>\n",
       "      <td>[昨天, 买, 了, 这个, 本本, ，, 收到, 后, 一看, 开始, 搞, 活动, 送,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35123</th>\n",
       "      <td>顺便提一句，杭州的司机开车真是野蛮，想怎么开就怎么开，相比之下上海的私家车主自律性真的很好。</td>\n",
       "      <td>1?</td>\n",
       "      <td>[顺便, 提, 一句, ，, 杭州, 的, 司机, 开车, 真是, 野蛮, ，, 想, 怎么...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment  \\\n",
       "35119  很多人一直强调研究红楼，我其实真的有点搞不懂为什么一定要研究到底不可。就像刘心武说秦可卿是太...        1?   \n",
       "35120  “主管会计必读”这本书独具匠心，一改革以往这类版本书的编排风格，从内容上编排上更加贴近实际工...        1?   \n",
       "35121  对明朝的历史基本上是空白的，因为办公室里的一个玩笑，开始接触这本书，越看越喜欢，眼前浮现出一...        1?   \n",
       "35122  昨天买了这个本本，收到后一看开始搞活动送内存，送硬盘了....订单完成了也没有办法了...感...        1?   \n",
       "35123     顺便提一句，杭州的司机开车真是野蛮，想怎么开就怎么开，相比之下上海的私家车主自律性真的很好。        1?   \n",
       "\n",
       "                                               cut_words  \n",
       "35119  [很多, 人, 一直, 强调, 研究, 红楼, ，, 我, 其实, 真的, 有点, 搞不懂,...  \n",
       "35120  [“, 主管, 会计, 必读, ”, 这, 本书, 独具匠心, ，, 一, 改革, 以往, ...  \n",
       "35121  [对, 明朝, 的, 历史, 基本上, 是, 空白, 的, ，, 因为, 办公室, 里, 的...  \n",
       "35122  [昨天, 买, 了, 这个, 本本, ，, 收到, 后, 一看, 开始, 搞, 活动, 送,...  \n",
       "35123  [顺便, 提, 一句, ，, 杭州, 的, 司机, 开车, 真是, 野蛮, ，, 想, 怎么...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "停止词对于情感分析毫无帮助，所以剔除"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with open('data/stop_words_chinese.txt') as file:\n",
    "    data = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "stop_words_chinese = data.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def remove_stop_words(l): return [s for s in l if s not in stop_words_chinese]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df['cleared_words'] = apply_by_multiprocessing(df.cut_words, remove_stop_words, workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "移除中文停止词之后，发现还有英文的标点符号"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def remove_english_punctuation(l): return [s for s in l if s not in string.punctuation ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df['cleared_words'] = apply_by_multiprocessing(df.cleared_words, remove_english_punctuation, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>cut_words</th>\n",
       "      <th>cleared_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>光驱不大好，给人想散架的的感觉。哈哈，总体上还可以。装系统有点绕手，害的我装了一个小时。</td>\n",
       "      <td>0</td>\n",
       "      <td>[光驱, 不大好, ，, 给, 人, 想, 散架, 的, 的, 感觉, 。, 哈哈, ，, ...</td>\n",
       "      <td>[光驱, 不大好, 想, 散架, 感觉, 总体, 装, 系统, 有点, 绕手, 害, 装, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2，散热是有点问题，CPU cache 是小了点。不能运行很大的软件。</td>\n",
       "      <td>0</td>\n",
       "      <td>[2, ，, 散热, 是, 有点, 问题, ，, CPU,  , cache,  , 是, ...</td>\n",
       "      <td>[散热, 有点, 问题, CPU, cache, 点, 不能, 运行, 很大, 软件]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>上月入住，将近500元一天的房费，卫生间很小，像经济性酒店。走廊房间一股霉味。浴缸下水管漏水...</td>\n",
       "      <td>0</td>\n",
       "      <td>[上, 月, 入住, ，, 将近, 500, 元, 一天, 的, 房费, ，, 卫生间, 很...</td>\n",
       "      <td>[月, 入住, 将近, 500, 元, 一天, 房费, 卫生间, 很小, 经济性, 酒店, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CTRIP上怎么让它这么忽悠顾客的 ？！！！！！！！</td>\n",
       "      <td>0</td>\n",
       "      <td>[CTRIP, 上, 怎么, 让, 它, 这么, 忽悠, 顾客, 的,  , ？, ！, ！...</td>\n",
       "      <td>[CTRIP, 忽悠, 顾客]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>于丹教授讲《论语》不能很正确地反映儒家原来的思想，她除了讲《论语》不好外，别的还可以。</td>\n",
       "      <td>0</td>\n",
       "      <td>[于, 丹, 教授, 讲, 《, 论语, 》, 不能, 很, 正确, 地, 反映, 儒家, ...</td>\n",
       "      <td>[丹, 教授, 讲, 论语, 不能, 正确, 反映, 儒家, 原来, 思想, 讲, 论语, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment  \\\n",
       "0       光驱不大好，给人想散架的的感觉。哈哈，总体上还可以。装系统有点绕手，害的我装了一个小时。         0   \n",
       "1                2，散热是有点问题，CPU cache 是小了点。不能运行很大的软件。         0   \n",
       "2  上月入住，将近500元一天的房费，卫生间很小，像经济性酒店。走廊房间一股霉味。浴缸下水管漏水...         0   \n",
       "3                         CTRIP上怎么让它这么忽悠顾客的 ？！！！！！！！         0   \n",
       "4        于丹教授讲《论语》不能很正确地反映儒家原来的思想，她除了讲《论语》不好外，别的还可以。         0   \n",
       "\n",
       "                                           cut_words  \\\n",
       "0  [光驱, 不大好, ，, 给, 人, 想, 散架, 的, 的, 感觉, 。, 哈哈, ，, ...   \n",
       "1  [2, ，, 散热, 是, 有点, 问题, ，, CPU,  , cache,  , 是, ...   \n",
       "2  [上, 月, 入住, ，, 将近, 500, 元, 一天, 的, 房费, ，, 卫生间, 很...   \n",
       "3  [CTRIP, 上, 怎么, 让, 它, 这么, 忽悠, 顾客, 的,  , ？, ！, ！...   \n",
       "4  [于, 丹, 教授, 讲, 《, 论语, 》, 不能, 很, 正确, 地, 反映, 儒家, ...   \n",
       "\n",
       "                                       cleared_words  \n",
       "0  [光驱, 不大好, 想, 散架, 感觉, 总体, 装, 系统, 有点, 绕手, 害, 装, ...  \n",
       "1        [散热, 有点, 问题, CPU, cache, 点, 不能, 运行, 很大, 软件]  \n",
       "2  [月, 入住, 将近, 500, 元, 一天, 房费, 卫生间, 很小, 经济性, 酒店, ...  \n",
       "3                                    [CTRIP, 忽悠, 顾客]  \n",
       "4  [丹, 教授, 讲, 论语, 不能, 正确, 反映, 儒家, 原来, 思想, 讲, 论语, ...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df['counter'] = apply_by_multiprocessing(df.cleared_words, Counter, workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "数据长度，方便计算总长度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df['words_count'] = df.cleared_words.map(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>cut_words</th>\n",
       "      <th>cleared_words</th>\n",
       "      <th>counter</th>\n",
       "      <th>words_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>光驱不大好，给人想散架的的感觉。哈哈，总体上还可以。装系统有点绕手，害的我装了一个小时。</td>\n",
       "      <td>0</td>\n",
       "      <td>[光驱, 不大好, ，, 给, 人, 想, 散架, 的, 的, 感觉, 。, 哈哈, ，, ...</td>\n",
       "      <td>[光驱, 不大好, 想, 散架, 感觉, 总体, 装, 系统, 有点, 绕手, 害, 装, ...</td>\n",
       "      <td>{'绕手': 1, '一个': 1, '想': 1, '装': 2, '总体': 1, '散...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2，散热是有点问题，CPU cache 是小了点。不能运行很大的软件。</td>\n",
       "      <td>0</td>\n",
       "      <td>[2, ，, 散热, 是, 有点, 问题, ，, CPU,  , cache,  , 是, ...</td>\n",
       "      <td>[散热, 有点, 问题, CPU, cache, 点, 不能, 运行, 很大, 软件]</td>\n",
       "      <td>{'cache': 1, '不能': 1, '散热': 1, '软件': 1, '很大': ...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         review sentiment  \\\n",
       "0  光驱不大好，给人想散架的的感觉。哈哈，总体上还可以。装系统有点绕手，害的我装了一个小时。         0   \n",
       "1           2，散热是有点问题，CPU cache 是小了点。不能运行很大的软件。         0   \n",
       "\n",
       "                                           cut_words  \\\n",
       "0  [光驱, 不大好, ，, 给, 人, 想, 散架, 的, 的, 感觉, 。, 哈哈, ，, ...   \n",
       "1  [2, ，, 散热, 是, 有点, 问题, ，, CPU,  , cache,  , 是, ...   \n",
       "\n",
       "                                       cleared_words  \\\n",
       "0  [光驱, 不大好, 想, 散架, 感觉, 总体, 装, 系统, 有点, 绕手, 害, 装, ...   \n",
       "1        [散热, 有点, 问题, CPU, cache, 点, 不能, 运行, 很大, 软件]   \n",
       "\n",
       "                                             counter  words_count  \n",
       "0  {'绕手': 1, '一个': 1, '想': 1, '装': 2, '总体': 1, '散...           14  \n",
       "1  {'cache': 1, '不能': 1, '散热': 1, '软件': 1, '很大': ...           10  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_train = df[(df.sentiment == 1 )| (df.sentiment ==0)]\n",
    "df_train_pos =  df[df.sentiment == 1]\n",
    "df_train_neg = df[df.sentiment == 0]\n",
    "df_test_pos = df[df.sentiment == '1?']\n",
    "df_test_neg = df[df.sentiment == '0?']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "$$\\hat{P}(c) = \\frac{N_{c}}{N}$$\n",
    "$$\\hat{P}(w|c) = \\frac{count(w,c)+1}{count(c)+|V|}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "首先计算 $\\hat{P}(c)$，即先验概率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos 的先验概率是 0.47112177662084115\n",
      "neg 的先验概率是 0.5288782233791589\n"
     ]
    }
   ],
   "source": [
    "p_pos = df_train_pos.shape[0] / df_train.shape[0]\n",
    "p_neg = 1 - p_pos\n",
    "\n",
    "\n",
    "print('pos 的先验概率是 {}'.format(p_pos))\n",
    "print('neg 的先验概率是 {}'.format(p_neg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "计算 $count(c)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "count_pos = df_train_pos.words_count.sum()\n",
    "count_neg = df_train_neg.words_count.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "计算 $V$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "直接用 pandas 或 numpy 的 sum 函数、方法计算 Couter 总数时，速度太慢，所以还是多进程吧"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def other_multiprocessing(df, func, workers):\n",
    "\n",
    "    chunk_size = int(df.shape[0] / workers)\n",
    "    chunks = (df.ix[df.index[i:i + chunk_size]] for i in range(0, df.shape[0], chunk_size))\n",
    "\n",
    "    pool = multiprocessing.Pool(processes=4)\n",
    "    result = pool.map(func, chunks)\n",
    "    return result\n",
    "\n",
    "\n",
    "def sum_func(d):\n",
    "    return d.counter.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.12 s, sys: 284 ms, total: 1.41 s\n",
      "Wall time: 1min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result = other_multiprocessing(df_train, sum_func, workers=4)\n",
    "train_counter_sum = np.sum(np.asarray(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "V = len(train_counter_sum.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "计算 $count(c)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "count_pos = df_train_pos.words_count.sum()\n",
    "count_neg = df_train_neg.words_count.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 532 ms, sys: 184 ms, total: 716 ms\n",
      "Wall time: 22.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "p_counter_sum_list = other_multiprocessing(df_train_pos, sum_func, workers=4)\n",
    "pos_counter_sum = np.sum(np.asarray(p_counter_sum_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 524 ms, sys: 136 ms, total: 660 ms\n",
      "Wall time: 21.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "n_counter_sum_list = other_multiprocessing(df_train_neg, sum_func, workers=4)\n",
    "neg_counter_sum = np.sum(np.asarray(n_counter_sum_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "写两个验证情绪的函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def compute_ppd(lst):\n",
    "    l = []\n",
    "    for key in lst:\n",
    "        l.append((pos_counter_sum[key] + 1) / (count_pos + V + 1))\n",
    "    l.append(p_pos)\n",
    "    a = np.asarray(l)\n",
    "    return a.prod()\n",
    "\n",
    "\n",
    "def compute_pnd(lst):\n",
    "    l = []\n",
    "    for key in lst:\n",
    "        l.append((neg_counter_sum[key] + 1) / (count_neg + V + 1))\n",
    "    l.append(p_neg)\n",
    "    a = np.asarray(l)\n",
    "    return a.prod()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_test_pos['ppd'] = apply_by_multiprocessing(\n",
    "    df_test_pos.cleared_words, compute_ppd, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_test_pos['pnd'] = apply_by_multiprocessing(\n",
    "    df_test_pos.cleared_words, compute_pnd, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_test_neg['pnd'] = apply_by_multiprocessing(\n",
    "    df_test_neg.cleared_words, compute_pnd, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_test_neg['ppd'] = apply_by_multiprocessing(\n",
    "    df_test_neg.cleared_words, compute_ppd, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_test_pos['predict_sentiment'] = np.where(df_test_pos.ppd > df_test_pos.pnd, 1, 0)\n",
    "df_test_neg['predict_sentiment'] = np.where(df_test_neg.ppd > df_test_neg.pnd, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4965 entries, 30159 to 35123\n",
      "Data columns (total 9 columns):\n",
      "review               4965 non-null object\n",
      "sentiment            4965 non-null object\n",
      "cut_words            4965 non-null object\n",
      "cleared_words        4965 non-null object\n",
      "counter              4965 non-null object\n",
      "words_count          4965 non-null int64\n",
      "ppd                  4965 non-null float64\n",
      "pnd                  4965 non-null float64\n",
      "predict_sentiment    4965 non-null int64\n",
      "dtypes: float64(2), int64(2), object(5)\n",
      "memory usage: 387.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df_test_pos.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "生成混淆矩阵"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "名称|含义|预测方向\n",
    "----|----|--------\n",
    "True Negative|正确预测成负例|0 -> 0\n",
    "True Positive|正确预测成正例|1 -> 1\n",
    "False Positive|错误预测成正例(即负例预测成正例)|0 -> 1\n",
    "False Negative|错误预测成负例(即正例预测成负例)|1 -> 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "actual_positive= df_test_pos.predict_sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "actual_negative = df_test_neg.predict_sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "TN = actual_negative[0]\n",
    "FN = actual_positive[0]\n",
    "\n",
    "TP = actual_positive[1]\n",
    "FP = actual_negative[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted_no</th>\n",
       "      <th>predicted_yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>actual_no</th>\n",
       "      <td>4843</td>\n",
       "      <td>730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual_yes</th>\n",
       "      <td>1161</td>\n",
       "      <td>3804</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            predicted_no  predicted_yes\n",
       "actual_no           4843            730\n",
       "actual_yes          1161           3804"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix = pd.DataFrame(\n",
    "    {'predicted_no': [TN, FN], 'predicted_yes': [FP, TP]}, \n",
    "    index=['actual_no', 'actual_yes'])\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predicted_no = confusion_matrix['predicted_no'].sum()\n",
    "predicted_yes = confusion_matrix['predicted_yes'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "total = actual_negative.sum() + actual_positive.sum()\n",
    "actual_yes = confusion_matrix.loc['actual_yes'].sum()\n",
    "actual_no = confusion_matrix.loc['actual_no'].sum()\n",
    "predicted_no = confusion_matrix['predicted_no'].sum()\n",
    "predicted_yes = confusion_matrix['predicted_yes'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "accuracy = (TP + TN) / total\n",
    "misclassification_rate = (FP + FN)/ total\n",
    "ture_positive_rate = TP / actual_yes\n",
    "false_positive_rate = FP / actual_no\n",
    "specificity = TN / actual_no\n",
    "precision = TP / predicted_yes\n",
    "prevalence = actual_yes / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is: 0.82\n",
      "misclassification_rate is: 0.18\n",
      "ture_positive_rate is: 0.77\n",
      "false_positive_rate is: 0.13\n",
      "specificity is: 0.87\n",
      "precision is: 0.84\n",
      "prevalence is: 0.47\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy is: {:.2f}\".format(accuracy))\n",
    "print(\"misclassification_rate is: {:.2f}\".format(misclassification_rate))\n",
    "print(\"ture_positive_rate is: {:.2f}\".format(ture_positive_rate))\n",
    "print(\"false_positive_rate is: {:.2f}\".format(false_positive_rate))\n",
    "print(\"specificity is: {:.2f}\".format(specificity))\n",
    "print(\"precision is: {:.2f}\".format(precision))\n",
    "print(\"prevalence is: {:.2f}\".format(prevalence))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
