{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPython 3.6.0\n",
      "IPython 6.0.0\n",
      "\n",
      "tensorflow 1.0.1\n",
      "numpy 1.12.1\n",
      "\n",
      "compiler   : GCC 4.9.2\n",
      "system     : Linux\n",
      "release    : 3.16.0-4-amd64\n",
      "machine    : x86_64\n",
      "processor  : \n",
      "CPU cores  : 4\n",
      "interpreter: 64bit\n"
     ]
    }
   ],
   "source": [
    "# 示例代码运行环境\n",
    "%load_ext watermark\n",
    "%watermark -p tensorflow,numpy -v -m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.contrib.legacy_seq2seq import basic_rnn_seq2seq, embedding_rnn_seq2seq, sequence_loss\n",
    "from tensorflow.python.ops import variable_scope\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "?basic_rnn_seq2seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {\n",
    "    'A': 0,\n",
    "    'B': 1,\n",
    "    'C': 2,\n",
    "    'D': 3,\n",
    "    'E': 4,\n",
    "    'F': 5,\n",
    "    '<GO>': 6,\n",
    "    '<EOS>': 7,\n",
    "    '<PAD>': 8\n",
    "}\n",
    "reverse_vocab = dict([(v, k) for (k, v) in vocab.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder_inputs = map(lambda _: tf.constant([vocab[_]]), ['A', 'B', 'C'])\n",
    "# decoder_inputs = map(lambda _: tf.constant([vocab[_]]), ['<GO>', 'D', 'E', 'F', 'F', '<EOS>'])\n",
    "\n",
    "encoder_data = list('ABC')\n",
    "decoder_data = ['<GO>', 'D', 'E', 'F', 'F', '<EOS>']\n",
    "\n",
    "encoder_inputs = [tf.constant([vocab[_]]) for _ in encoder_data]\n",
    "decoder_inputs = [tf.constant([vocab[_]]) for _ in decoder_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell = tf.contrib.rnn.BasicRNNCell(128)\n",
    "num_encoder_symbols = 9\n",
    "num_decoder_symbols = 9\n",
    "embedding_size = 128\n",
    "\n",
    "outputs, states = embedding_rnn_seq2seq(\n",
    "    encoder_inputs, decoder_inputs, cell,\n",
    "    num_encoder_symbols, num_decoder_symbols,\n",
    "    embedding_size, output_projection=None,\n",
    "    feed_previous=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = list(map(lambda _: tf.constant([_], dtype=tf.float32),  [1, 1, 1, 1, 1]))\n",
    "loss = sequence_loss(outputs[:-1], decoder_inputs[1:], weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_step = tf.train.GradientDescentOptimizer(0.01).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1471\n",
      "1.89836\n",
      "1.68108\n",
      "1.49578\n",
      "1.33911\n",
      "1.20611\n",
      "1.09201\n",
      "0.993014\n",
      "0.90634\n",
      "0.82995\n",
      "0.762314\n",
      "0.702227\n",
      "0.648699\n",
      "0.600891\n",
      "0.558084\n",
      "0.519653\n",
      "0.48506\n",
      "0.453838\n",
      "0.425587\n",
      "0.399958\n",
      "0.376653\n",
      "0.355411\n",
      "0.336008\n",
      "0.318245\n",
      "0.301951\n",
      "0.286975\n",
      "0.273183\n",
      "0.260458\n",
      "0.248697\n",
      "0.237805\n",
      "0.227702\n",
      "0.218314\n",
      "0.209576\n",
      "0.201429\n",
      "0.193822\n",
      "0.186707\n",
      "0.180042\n",
      "0.17379\n",
      "0.167917\n",
      "0.162391\n",
      "0.157186\n",
      "0.152276\n",
      "0.147639\n",
      "0.143254\n",
      "0.139101\n",
      "0.135166\n",
      "0.131431\n",
      "0.127883\n",
      "0.124508\n",
      "0.121296\n",
      "---Deocding----\n",
      "D\n",
      "E\n",
      "F\n",
      "F\n",
      "<EOS>\n",
      "<EOS>\n",
      "D\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    # Training\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for iteration in range(50):\n",
    "        sess.run(train_step)\n",
    "        print(sess.run(loss))\n",
    "        \n",
    "    print(\"---Deocding----\")\n",
    "    \n",
    "    # Decoding\n",
    "    with variable_scope.variable_scope(variable_scope.get_variable_scope(), reuse=True):\n",
    "        decode_decoder_inputs = map(lambda _: tf.constant([vocab[_]]), ['<GO>', 'A', 'A', 'A', 'A', 'A', 'A'])\n",
    "        outputs, states = embedding_rnn_seq2seq(\n",
    "            encoder_inputs, decode_decoder_inputs, cell,\n",
    "            num_encoder_symbols, num_decoder_symbols,\n",
    "            embedding_size, output_projection=None,\n",
    "            feed_previous=True)\n",
    "\n",
    "        for o in outputs:\n",
    "            m = np.argmax(o.eval(), axis=1)\n",
    "            print(reverse_vocab[m[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 用 placeholder 代替 Tensor\n",
    "\n",
    "placeholder 的类型是 Tensor，因此上述 API 中的 Tensor 都可以用 placeholder 代替，使得训练、测试过程的数据可以变动"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.framework.ops.Tensor"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tf.placeholder(tf.int32, shape=[None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_length = 5\n",
    "decoder_length = 5\n",
    "\n",
    "cell = tf.contrib.rnn.BasicRNNCell(128)\n",
    "num_encoder_symbols = 9\n",
    "num_decoder_symbols = 9\n",
    "embedding_size = 128\n",
    "\n",
    "encoder_placeholders = [tf.placeholder(tf.int32, shape=[None],\n",
    "                                       name=\"encoder_%d\" % i) for i in range(encoder_length)]\n",
    "decoder_placeholders = [tf.placeholder(tf.int32, shape=[None],\n",
    "                                       name=\"decoder_%d\" % i) for i in range(decoder_length)]\n",
    "target_placeholders = [tf.placeholder(tf.int32, shape=[None],\n",
    "                                       name=\"target_%d\" % i) for i in range(decoder_length)]\n",
    "target_weights_placeholders = [tf.placeholder(tf.float32, shape=[None],\n",
    "                                       name=\"decoder_weight_%d\" % i) for i in range(decoder_length)]\n",
    "outputs, states = embedding_rnn_seq2seq(\n",
    "    encoder_placeholders, decoder_placeholders, cell,\n",
    "    num_encoder_symbols, num_decoder_symbols,\n",
    "    embedding_size, output_projection=None,\n",
    "    feed_previous=False)\n",
    "\n",
    "loss = sequence_loss(outputs, target_placeholders, target_weights_placeholders)\n",
    "train_step = tf.train.GradientDescentOptimizer(0.01).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def seq2seq_pad(encoder_inputs, encoder_length, decoder_inputs, decoder_length, vocab, pad_symbol='<PAD>'):\n",
    "    \"\"\"\n",
    "    - encoder_input: A nested list of symbol str for encoding, length: batch_size\n",
    "    - encoder_length: max length of encoder input\n",
    "    - decoder_input: A nested list of symbol str for decoding, length: batch_size\n",
    "    - decoder_length: max length of decoder input\n",
    "    - vocab: vocabulary index, symbol (str) -> index (int)\n",
    "    \n",
    "    Example: \n",
    "    [\"hello\", \"world\"] -> [\"hi\", \"<EOS>\"]\n",
    "    [\"cover\", \"me\"] -> [\"roger\", \"<EOS>\"]\n",
    "    \n",
    "    seq2seq_pad([['hello', 'world'], ['cover', 'me']], 4, [['hi', '<EOS>'], ['roger', '<EOS>']], 4, vocab)\n",
    "    \n",
    "    Assume that index of \"<PAD>\" is 0\n",
    "\n",
    "    Output:\n",
    "    [[0, 0, <index of 'hello'>, <index of 'world'>], [0, 0, <index of 'cover'>, <index of 'me'>]],\n",
    "    [[<index of 'hi'>, <index of 'EOS'>, 0, 0], [<index of 'roger'>, <index of 'EOS'>, 0, 0]]\n",
    "    \"\"\"\n",
    "    pad_index = vocab[pad_symbol]\n",
    "    def to_index(inputs, length, pad_from_start=True):\n",
    "        inputs_to_index = []\n",
    "        for cur_input in inputs:\n",
    "            cur_input_to_index = [pad_index] * length\n",
    "            l = len(cur_input)\n",
    "            if l < length:\n",
    "                if pad_from_start:\n",
    "                    cur_input_to_index[(length - l):] = [vocab[i] for i in cur_input]\n",
    "                else:\n",
    "                    cur_input_to_index[:l] = [vocab[i] for i in cur_input]\n",
    "            else:\n",
    "                cur_input_to_index = [vocab[i] for i in cur_input[:length]]\n",
    "            inputs_to_index.append(cur_input_to_index)    \n",
    "        return inputs_to_index\n",
    "    return to_index(encoder_inputs, encoder_length, True), to_index(decoder_inputs, decoder_length, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[8, 8, 8, 0, 1], [8, 8, 8, 1, 0]], [[6, 2, 3, 7, 8], [6, 3, 2, 7, 8]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq2seq_pad([['A', 'B'], ['B', 'A']], 5, [['<GO>', 'C', 'D', '<EOS>'], ['<GO>', 'D', 'C', '<EOS>']], 5, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inputs, decoder_inputs = seq2seq_pad([['A', 'B'], ['B', 'A']],\n",
    "                                             5, [['<GO>', 'C', 'D', '<EOS>'], ['<GO>', 'D', 'C', '<EOS>']], 5, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<zip object at 0x7f89cb1a9308>\n"
     ]
    }
   ],
   "source": [
    "# 对 nested list 进行『转置』，得到 TF seq2seq 需要的输入形状\n",
    "print(zip(*encoder_inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def left_shift(decoder_inputs, pad_idx):\n",
    "    # for generating targets\n",
    "    return [list(input_[1:]) + [pad_idx] for input_ in decoder_inputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    # 两对翻译 pairs\n",
    "    # AB -> CD\n",
    "    # BA -> EFF\n",
    "    encoder_inputs, decoder_inputs = seq2seq_pad([['A', 'B'], ['B', 'A']],\n",
    "                                                 5, [['<GO>', 'C', 'D', '<EOS>'], ['<GO>', 'E', 'F', 'F', '<EOS>']], 8, vocab)\n",
    "    encoder_inputs = list(zip(*encoder_inputs))\n",
    "    # 还有一种方案是直接通过 shift decoder_placeholders 来得到 target_placeholders，这样只需要提供 decoder_placeholders 即可\n",
    "    target_inputs = list(zip(*left_shift(decoder_inputs, vocab['<PAD>'])))\n",
    "    decoder_inputs = list(zip(*decoder_inputs))\n",
    "    \n",
    "    feed_dict = dict()\n",
    "    # Prepare input data    \n",
    "    for (i, placeholder) in enumerate(encoder_placeholders):\n",
    "        # 这里用 placeholder 或者 placeholder.name 都可以\n",
    "        feed_dict[placeholder.name] = np.asarray(encoder_inputs[i], dtype=int)\n",
    "    for i in range(len(decoder_placeholders)):\n",
    "        feed_dict[decoder_placeholders[i].name] = np.asarray(decoder_inputs[i], dtype=int)\n",
    "        feed_dict[target_placeholders[i].name] = np.asarray(target_inputs[i], dtype=int)        \n",
    "        # 这里使用 weights 把 <PAD> 的损失屏蔽了\n",
    "        feed_dict[target_weights_placeholders[i].name] = np.asarray([float(idx != vocab['<PAD>']) for idx in target_inputs[i]],\n",
    "                                                      dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<EOS>': 7,\n",
       " '<GO>': 6,\n",
       " '<PAD>': 8,\n",
       " 'A': 0,\n",
       " 'B': 1,\n",
       " 'C': 2,\n",
       " 'D': 3,\n",
       " 'E': 4,\n",
       " 'F': 5}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A', 'B', 'C']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(8, 8), (8, 8), (8, 8), (0, 1), (1, 0)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'encoder_0:0' shape=(?,) dtype=int32>,\n",
       " <tf.Tensor 'encoder_1:0' shape=(?,) dtype=int32>,\n",
       " <tf.Tensor 'encoder_2:0' shape=(?,) dtype=int32>,\n",
       " <tf.Tensor 'encoder_3:0' shape=(?,) dtype=int32>,\n",
       " <tf.Tensor 'encoder_4:0' shape=(?,) dtype=int32>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(6, 6), (2, 4), (3, 5), (7, 5), (8, 7), (8, 8), (8, 8), (8, 8)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'decoder_0:0': array([6, 6]),\n",
       " 'decoder_1:0': array([2, 4]),\n",
       " 'decoder_2:0': array([3, 5]),\n",
       " 'decoder_3:0': array([7, 5]),\n",
       " 'decoder_4:0': array([8, 7]),\n",
       " 'decoder_weight_0:0': array([ 1.,  1.]),\n",
       " 'decoder_weight_1:0': array([ 1.,  1.]),\n",
       " 'decoder_weight_2:0': array([ 1.,  1.]),\n",
       " 'decoder_weight_3:0': array([ 0.,  1.]),\n",
       " 'decoder_weight_4:0': array([ 0.,  0.]),\n",
       " 'encoder_0:0': array([8, 8]),\n",
       " 'encoder_1:0': array([8, 8]),\n",
       " 'encoder_2:0': array([8, 8]),\n",
       " 'encoder_3:0': array([0, 1]),\n",
       " 'encoder_4:0': array([1, 0]),\n",
       " 'target_0:0': array([2, 4]),\n",
       " 'target_1:0': array([3, 5]),\n",
       " 'target_2:0': array([7, 5]),\n",
       " 'target_3:0': array([8, 7]),\n",
       " 'target_4:0': array([8, 8])}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feed_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Attempted to use a closed Session.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-35166383b6f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0miteration\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/scott/.pyenv/versions/3.6.0/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/scott/.pyenv/versions/3.6.0/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    901\u001b[0m     \u001b[0;31m# Check session.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_closed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 903\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Attempted to use a closed Session.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    904\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    905\u001b[0m       raise RuntimeError('The Session graph is empty.  Add operations to the '\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Attempted to use a closed Session."
     ]
    }
   ],
   "source": [
    "    \n",
    "    # Training\n",
    "    for iteration in range(50):\n",
    "        sess.run(train_step, feed_dict)\n",
    "        print(sess.run(loss, feed_dict)) \n",
    "\n",
    "    print(\"---Deocding----\")\n",
    "    \n",
    "    # Decoding\n",
    "    with variable_scope.variable_scope(variable_scope.get_variable_scope(), reuse=True):\n",
    "        outputs, states = embedding_rnn_seq2seq(\n",
    "            encoder_placeholders, decoder_placeholders, cell,\n",
    "            num_encoder_symbols, num_decoder_symbols,\n",
    "            embedding_size, output_projection=None,\n",
    "            feed_previous=True)\n",
    "\n",
    "        for o in outputs:\n",
    "            # 注意这里也需要提供 feed_dict\n",
    "            m = np.argmax(o.eval(feed_dict), axis=1)\n",
    "            print(reverse_vocab[m[0]], reverse_vocab[m[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
