{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 应用卷积神经网络实现情感分类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 思路：\n",
    "\n",
    "* 数据清理：\n",
    "    + 删除停止词\n",
    "    + 统计 counter\n",
    "    + 导出 train 和 test 各自的 data 以及 target\n",
    "* 构造模型：\n",
    "    + 设定模型神经网络框架\n",
    "    + 设定参数\n",
    "    + 设定卷积层和池化层\n",
    "    + 输出\n",
    "* 展示：\n",
    "    + 脚本化：数据清理和模型训练分为不一样的脚本\n",
    "    + 矩阵图"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 笔记和思考：\n",
    "\n",
    "* 卷积层的作用是什么？\n",
    "* 卷积层有什么特性？\n",
    "* 为什么卷积核的深度和当前层一样？为什么卷积不会改变深度？\n",
    "* 池化层的作用和特性分别是什么？\n",
    "* Max pooling 和 average pooling 的区别是什么？\n",
    "* 构造卷积神经网络有哪些通用框架？处理图像数据和文本分类数据有什么注意的地方？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 环境说明："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scott Ming 2017-04-14 \n",
      "\n",
      "CPython 3.6.0\n",
      "IPython 5.3.0\n",
      "\n",
      "numpy 1.12.1\n",
      "pandas 0.19.2\n",
      "matplotlib 2.0.0\n",
      "tensorflow 1.0.1\n",
      "\n",
      "compiler   : GCC 4.9.2\n",
      "system     : Linux\n",
      "release    : 3.16.0-4-amd64\n",
      "machine    : x86_64\n",
      "processor  : \n",
      "CPU cores  : 4\n",
      "interpreter: 64bit\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -a 'Scott Ming' -v -m -d -p numpy,pandas,matplotlib,tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 清理数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ch5_task1.ipynb   data\t\t\t   saved_model\r\n",
      "ch5_task2.ipynb   lena512.png\t\t   script_introduction.ipynb\r\n",
      "ch5_task4.ipynb   nn_language_model.ipynb  test_shuffle.txt\r\n",
      "cnn.py\t\t  practice\t\t   text_cnn.py\r\n",
      "conv_image.ipynb  __pycache__\t\t   text_helpers.py\r\n",
      "conv_nlp.ipynb\t  README.md\t\t   train_shuffle.txt\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "装了xp系统后，没有出现网友说的驱动不好装的情况\t1\r\n",
      "总的来说,比较干净,而且地理位置很好,市区繁华地段.进出方便.\t1\r\n",
      "2、散热很好，这个不用解释了\t1\r\n",
      "温度控制的非常好，噪音也不大，\t1\r\n",
      "早上6点多有\"按摩\"电话过来，^_^；不想被打扰的话拔掉电话插头吧\t1\r\n"
     ]
    }
   ],
   "source": [
    "!head -n 5 train_shuffle.txt  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "检查下数据的列总数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column counts: 2\r\n"
     ]
    }
   ],
   "source": [
    "!awk -F'\\t' '{print \"Column counts: \" NF; exit}' train_shuffle.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column counts: 2\r\n"
     ]
    }
   ],
   "source": [
    "!awk -F'\\t' '{print \"Column counts: \" NF; exit}' test_shuffle.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ch5_task1.ipynb   data\t\t\t   saved_model\r\n",
      "ch5_task2.ipynb   lena512.png\t\t   script_introduction.ipynb\r\n",
      "ch5_task4.ipynb   nn_language_model.ipynb  test_shuffle.txt\r\n",
      "cnn.py\t\t  practice\t\t   text_cnn.py\r\n",
      "conv_image.ipynb  __pycache__\t\t   text_helpers.py\r\n",
      "conv_nlp.ipynb\t  README.md\t\t   train_shuffle.txt\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据清理由 text_helper.py 执行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from text_helpers import build_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# build_dataset('train_shuffle.txt', 'test_shuffle.txt', \n",
    "#               'data/stop_words_chinese.txt', n=10, max_words=20)\n",
    "# 2 mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleared_data.pkl  loss.png\t     stop_words_chinese.txt  train_data.txt\r\n",
      "embed.png\t  reversed_dict.pkl  test_data.txt\t     word_dict.pkl\r\n"
     ]
    }
   ],
   "source": [
    "!ls ../data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 创建数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = np.loadtxt('data/train_data.txt', dtype=int)\n",
    "test = np.loadtxt('data/test_data.txt', dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = train[:, :-1]\n",
    "y_train = train[:, -1:].reshape((-1,))\n",
    "x_test = test[:, :-1]\n",
    "y_test = test[:, -1:].reshape((-1,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 构建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reversed_dict = pickle.load(open('data/reversed_dict.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab_size = 80000\n",
    "sentence_length = x_train.shape[1]\n",
    "word_embed_size = 128\n",
    "data_size = train.shape[0]\n",
    "batch_size = 50\n",
    "num_filters = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.int32, shape=[None, sentence_length], name='x-input')\n",
    "y_ = tf.placeholder(tf.int32, shape=[None,], name='y-input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_embedding = tf.Variable(\n",
    "    tf.random_uniform([vocab_size, word_embed_size])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "embeds = tf.nn.embedding_lookup(word_embedding, x)\n",
    "embeds_expand = tf.expand_dims(embeds, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def inference(input_tensor):\n",
    "    with tf.name_scope(\"conv-maxpool\"):\n",
    "        filter_num = 64\n",
    "        window_size = 3\n",
    "        filter_shape = [window_size, word_embed_size, 1, filter_num]\n",
    "        # W 和 b 是卷积的参数\n",
    "        W = tf.Variable(tf.random_uniform(filter_shape, -1.0, 1.0), name=\"W\")\n",
    "        # bias 和 filter_num 个数是一样的\n",
    "        b = tf.Variable(tf.constant(0.0, shape=[filter_num]), name=\"b\")\n",
    "        # 步长为1，这里不做 Padding，因此句子太短的话可能要丢掉。可自行尝试加 padding（不加也不影响作业评分）\n",
    "        conv = tf.nn.conv2d(\n",
    "                        input_tensor,\n",
    "                        W,\n",
    "                        strides=[1, 1, 1, 1],\n",
    "                        padding=\"VALID\",\n",
    "                        name=\"conv\")\n",
    "        # 卷积出来的结果加上 bias\n",
    "        conv_hidden = tf.nn.tanh(tf.add(conv, b), name=\"tanh\")\n",
    "    \n",
    "        # 因为没有 padding，出来的结果个数是 sequence_length - window_size + 1，如果加了 padding 这里要对应更改。\n",
    "        pool = tf.nn.max_pool(\n",
    "                        conv_hidden,\n",
    "                        ksize=[1, sentence_length - window_size + 1, 1, 1],\n",
    "                        strides=[1, 1, 1, 1],\n",
    "                        padding='VALID',\n",
    "                        name=\"pool\")\n",
    "    \n",
    "        pool_shape = pool.get_shape().as_list()\n",
    "        # pool_shape[0] 为一个 batch 中数据的个数，即评论条数\n",
    "        nodes = pool_shape[1] * pool_shape[2] * pool_shape[3]\n",
    "        # 通过 tf.reshape 函数把 pool 层的输出编程一个 batch 的向量\n",
    "        reshaped = tf.reshape(pool, [-1, nodes])  # -1 表示尽可能的展平\n",
    "        logits = tf.layers.dense(reshaped, 2)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "logits = inference(embeds_expand)\n",
    "cost = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "    logits=logits, labels=y_)  \n",
    "y = tf.nn.softmax(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 计算预测值\n",
    "prediction = tf.arg_max(y, 1)\n",
    "# 判断两个张亮的每一维度是否相等\n",
    "correct_prediction = tf.equal(\n",
    "    tf.cast(prediction, tf.int32), y_)\n",
    "# 先将布尔型的数值转为实数型，然后计算平均值\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "# 设定两者的 feed_dict 方便计算 accuracy\n",
    "train_feed_dict = {\n",
    "    x: x_train, \n",
    "    y_: y_train,\n",
    "}\n",
    "test_feed_dict = {\n",
    "    x: x_test, \n",
    "    y_: y_test,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 0 training step(s), cross entropy on batch data is 1.515462, trian accuracy is 0.54, test accuracy is 0.53\n",
      "After 500 training step(s), cross entropy on batch data is 0.646886, trian accuracy is 0.84, test accuracy is 0.78\n",
      "After 1000 training step(s), cross entropy on batch data is 0.101600, trian accuracy is 0.93, test accuracy is 0.84\n",
      "After 1500 training step(s), cross entropy on batch data is 0.034075, trian accuracy is 0.96, test accuracy is 0.87\n",
      "After 2000 training step(s), cross entropy on batch data is 0.005170, trian accuracy is 0.98, test accuracy is 0.89\n",
      "After 2500 training step(s), cross entropy on batch data is 0.040701, trian accuracy is 0.99, test accuracy is 0.90\n",
      "After 3000 training step(s), cross entropy on batch data is 0.002401, trian accuracy is 0.99, test accuracy is 0.91\n",
      "After 3500 training step(s), cross entropy on batch data is 0.000302, trian accuracy is 0.99, test accuracy is 0.91\n",
      "After 4000 training step(s), cross entropy on batch data is 0.000007, trian accuracy is 0.99, test accuracy is 0.91\n",
      "After 4500 training step(s), cross entropy on batch data is 0.000014, trian accuracy is 0.99, test accuracy is 0.91\n"
     ]
    }
   ],
   "source": [
    "train_step = tf.train.AdamOptimizer(0.001).minimize(cost)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    STEP = 5000\n",
    "    for i in range(STEP):\n",
    "        batch_data = train[np.random.randint(train.shape[0], size=batch_size), :]\n",
    "        X = batch_data[:, :-1]\n",
    "        Y = batch_data[:, -1:].reshape((-1,))\n",
    "        feed_dict={x: X, y_: Y}\n",
    "        sess.run(train_step, feed_dict=feed_dict)\n",
    "        if i % 500 == 0:\n",
    "            total_cross_entropy = cost.eval(feed_dict=feed_dict)[0]\n",
    "            train_accuracy = accuracy.eval(feed_dict=train_feed_dict)\n",
    "            test_accuracy = accuracy.eval(feed_dict=test_feed_dict)\n",
    "            test_prediction = prediction.eval(feed_dict=test_feed_dict)\n",
    "            print(\"After %d training step(s), cross entropy on batch data is \"\n",
    "                  \"%f, trian accuracy is %.2f, test accuracy is %.2f\" % (\n",
    "                      i, total_cross_entropy, train_accuracy, test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里调用 [Plot confusion matrix - mlxtend](http://rasbt.github.io/mlxtend/user_guide/plotting/plot_confusion_matrix/)，函数详情可以参考 [Reading-a-confusion-matrix](http://nbviewer.jupyter.org/github/rasbt/python-machine-learning-book/blob/master/code/ch06/ch06.ipynb#Reading-a-confusion-matrix)。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "binary = confusion_matrix(y_true=y_test, y_pred=test_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAALUAAAC4CAYAAAClza13AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAERVJREFUeJzt3Xl4FNWax/HvmwgCKmEJUfY1bC5cJCOKjAgDV1DADZXl\n6oA4+iA7LiDDdUPWQS+rYmQREQiIG0SQixhBwxoRCQpcdglwWQMJIIvhzB9dSTpAkiJJpZvj+3ke\nnlSdPtX1Fs8vJ6e7q6vEGINSNgkJdAFKFTQNtbKOhlpZR0OtrKOhVtbRUCvraKiVdTTUyjoaamWd\nawJdgL+wUqVNxE0VAl1G0Ai7vnigSwgaGxMTU86dPRvmpm9QhTripgqMi44JdBlB476mtwa6hKBR\nLrzMIbd9dfqhrKOhVtbRUCvraKiVdTTUyjoaamUdDbWyjoZaWUdDrayjoVbW0VAr62iolXU01Mo6\nGmplHQ21so6GWllHQ62so6FW1tFQK+toqJV1NNTKOhpqZR0NtbKOhlpZR0OtrKOhVtbRUCvraKiV\ndYLqApFe6vZEa4oXL0FIaCihoaGMi47h+7h/MvvD99i7Zyf/mDybyLo3A/DTulVMjx7LH+fPc02R\nInTvMYAGtzcG4Pz587w3djiJGxIICRGeeqY3dzdrFchDKxBpaWk0viOKChUqsmBhbEZ7v759mD59\nGidSTgIwYEB/ln8XB8Dp06c5dOgQR48dD0jN2fE01CLSGhgHhAJTjDEjvdxfbkaMnUpYqdIZ61Wr\n1+J/h77DxLeHZulXMqwUr42YQNnwCHbv3MarL/Xgo0+/AWDuzGhKlS7DB7MWcuHCBVJTThTqMXhl\n/Phx1K1bj5SUlIy2hIQEkpOTs/R7551/ZCxPnDiBDT/9VGg1uuXZ9ENEQoFJQBugPtBJROp7tb+8\nqFKtBpWqVL+kvWbtepQNjwB8wT979gznz50DYOmiL3i8S3cAQkJCsvySXK2SkpJYtOgrnu7+TEZb\nWloaAwe+xMhRo7PdLiZmDk907FQYJV4RL0fqO4DtxpidACISAzwI/OrhPrMlwN9ffA5EaNPuMdq0\n7+Bqu/jlS6lZux5FihblZKpvFJs5dRKJG9ZxU4XK9Og3mNJlynpYufcG9O/HyJGjSU1NzWibNGki\n7dq1p3z58pfdZs+ePezetYsWLVoUVpmueflCsSKw1289yWnLQkSeFZEEEUk4cTz54ocLzOiJMxg/\nZR5vjn6Xr76IYdPPCblus2fXdqa/P5beL7wK+EavI4cPUu+WBoyfMo96Nzdg6rtve1ZzYYiNjSUi\nIoJGjRpltO3fv5/58z+hV6/e2W43d24Mjz7agdDQ0MIo84oE/N0PY0y0MSbKGBPl5Z/y8HI3AlCq\ndFnu+s8WbN28Kcf+Rw79m7eG9OeFwcMoX7Ey4JtrX1usGE3uaQlA0+Z/Zce2zZ7VXBhWroxn4cIF\n1KxRjS6dOxIX9y233XozO7Zvp07tWtSsUY3Tp09Tp3atLNvNmxsTlFMP8DbU+4DKfuuVnLZCd+b3\n05w+fSpjef26VVStXivb/idTU3h9UC+6PteX+rc2zGgXERo3uZfEDesA2PDjGipXreFt8R4bPnwE\ne35LYsfO3cyaHUPz5i04cjSZffv/zY6du9mxczclSpRg67+2Z2yzZcsWkpOTueuuuwJYefa8nFOv\nAyJFpDq+MHcEOnu4v2wlJx9j2JB+gG8K0axlG6IaN2XlimVMHj+CE8eTeX1QT2rUqsvQMZOJ/TyG\n/ft+Y86M95kz430A3hozmVKly9LtuX6MGTaY6AmjCStVmn6Dhua0ayvNnRvD4090REQCXcpliTHG\nuycXuR8Yi+8tvWnGmGE59Y+se7PRGxll0hsZZSoXXmb7sWPHIt309fR9amPMImCRl/tQ6mIBf6Go\nVEHTUCvraKiVdTTUyjoaamUdDbWyjoZaWSfb96lFJBVI/2Qm/aMj4ywbY0xJj2tTKk+yDbUx5obC\nLESpguJq+iEiTUWkm7Mc7pzPoVRQyjXUIvIaMBB4xWkqCnzsZVFK5YebkfphoD1wCsAYsx/QqYkK\nWm5Cfc74TuUzACJynbclKZU/bkI9T0TeB0qJyP8A3wAfeFuWUnmX66mnxpgxItIKSAFqA68aY5Z6\nXplSeeT2fOpEoDi+KUiid+UolX9u3v14BlgLPAJ0AFaLyNNeF6ZUXrkZqV8CGhpjjgKISFlgJTDN\ny8KUyis3LxSPAql+66lOm1JBKadzPwY4i9uBNSLyJb459YPAxkKoTak8yWn6kf4Byw7nX7ovvStH\nqfzL6YSmNwqzEKUKSq4vFEWkHPAycDNQLL3dGBN8VwZUCncvFGcBW4DqwBvAbnxXX1IqKLkJdVlj\nzFTgvDFmuTHmaUBHaRW03LxPfd75eUBEHgD2A2W8K0mp/HET6rdEJAx4AZgAlAT6e1qVUvng5oSm\n9LvanACae1uOUvmX04cvE8j84u0ljDF9CrqYsOuLc1/TWwr6aa9aS9b/FugSgkbyyXOu++Y0Uud+\n/wilglBOH77MKMxClCooejEbZR0NtbKOhlpZx803X2qLyDIR2eSs3yYiQ7wvTam8cTNSf4DvQjbn\nAYwxG/HdaUupoOQm1CWMMWsvavvDi2KUKghuQn1ERGqSeTGbDsABT6tSKh/cnPvRE4gG6orIPmAX\n8DdPq1IqH9yc+7ETaOlcbizEGJOa2zZKBZKbb768etE6AMaYNz2qSal8cTP9OOW3XAxoC2z2phyl\n8s/N9ONt/3URGQMs8awipfIpL58olgAqFXQhShUUN3PqRDLPqw4FygE6n1ZBy82cuq3f8h/AQWOM\nfviiglaOoRaRUGCJMaZuIdWjVL7lOKc2xqQBW0WkSiHVo1S+uZl+lAZ+EZG1+L29Z4xp71lVSuWD\nm1D/3fMqlCpAbkJ9vzFmoH+DiIwClntTklL54+Z96laXaWtT0IUoVVByuu5HD+B5oIaI+F9k/QYg\n3uvClMqrnKYfs4HFwAhgkF97qjHmmKdVKZUPOV334wS+S411KrxylMo//Ta5so6GWllHQ62s86cN\ndVpaGlGNbqd9u3YANGt2D41ub0ij2xtSuVJFHnn4YQCMMfTr24c6tSNp+JcGrF+/PpBlF5i0tDR6\nd2nD6/27ZWmfPOY1Hr2nXsb6oQNJDO7RiZ6d7mPQc09w5GDmd67bNa5Or85t6NW5DW8M6F5otefG\n7b3Jr5iITMN3ht8hY0zQXZ93/Phx1K1bj5SUFACWL1+R8dhjHTrQvr3vLIDFixezbdt2tmz9F2vW\nrKFnz+dZtWp1QGouSAtiplG5ei1OnzqZ0bbt142cTDmRpd+UccNo8cCjtGzbgZ/XxfPhpFG8+OZY\nAIpeW4yJsxcXat1ueDlSfwi09vD58ywpKYlFixbxdPdLR5eUlBTi4r7lwYceAmDhgi958sknERHu\nvPNOThw/zoEDV/cVIo4cPMC6H77lvgczr0mUlpbG1PHDeLrPK1n67t25jQZRTQC4LaoJq1csLdRa\n88KzUBtjVgBB+X72gP79GTlyFCEhlx7+l198QYsW/0XJkiUB2LdvP5UqV854vGKlSuzbt6/QavVC\n9Dtv0K3PYMTv+GPnzaDxPa0oE35jlr7Va9djZdzXAKyM+5rfT50k5XgyAOfOnaXvU20Z0O0hVn0X\nPN/wC/icWkSeFZEEEUk4fPiw5/uLjY0lIqIcjRo1uuzjMTExdOxo71XV1n6/jLDSZYmsd2tG29HD\nB/lh2Ve0f7zrJf279x1C4vrV9O7Shk3r11A24iZCQn2xmb5gJeM+iuWloeOJfudNDiTtKazDyJFn\nc2q3jDHR+C6WQ1RUVLa34ygoK1fGs3DhQhYvXsyZM2dISUnhqSef5KOZMzly5Ajr1q3l088+y+hf\nsWIFkvbuzVjfl5RExYoVvS7TM7/+nMCa778hYeV3nDt7lt9PpdLjiZYUKXItzzzSDICzZ37nmYfv\nYcrnKyhb7kaG/F80AL+fPkV83GKuvyEMgPCImwAoX6kKt95+Jzu2bqJ8paoBOS5/AR+pC9vw4SPY\n89teduzcxazZc2jevAUfzZwJwKfz5/PAA20pVizjxr60bdeemTNnYoxh9erVlAwLo3z58oEqP9+6\n9hrIR1+tYfqCeAYOn8Bt/9GEed8mMmtJAtMXxDN9QTzXFivOlM99L5xPHD/GhQsXAJj34SRatXsc\ngNSUE5w/dzajz+aNCVSpHhmYg7pIwEfqYDJ33lxefjnLWbbcf//9fL14EXVqR1KiRAmmTJ0WoOoC\nI/HHVcyYNBpEuKXhHTz/8lAA9u7axsQRgwkJCeHChQt0+O8eVKlRO8DV+ogx3vzFF5E5wL1AOHAQ\neM25c262oqKizJq1eofodEvW782905/EA03qbzfnTrr6U+DZSG2M0ROhVED86ebUyn4aamUdDbWy\njoZaWUdDrayjoVbW0VAr62iolXU01Mo6GmplHQ21so6GWllHQ62so6FW1tFQK+toqJV1NNTKOhpq\nZR0NtbKOhlpZR0OtrKOhVtbRUCvraKiVdTTUyjoaamUdDbWyjoZaWcezq57mhYgcBoLhcvThwJFA\nFxFEguH/o6oxppybjkEV6mAhIgnGmKhA1xEsrrb/D51+KOtoqJV1NNSXFx3oAoLMVfX/oXNqZR0d\nqZV1NNTKOhpqPyLSWkS2ish2ERkU6HoCSUSmicghEdkU6FqulIbaISKhwCSgDVAf6CQi9QNbVUB9\nCLQOdBF5oaHOdAew3Riz0xhzDogBHgxwTQFjjFkBHAt0HXmhoc5UEfC/G2eS06auMhpqZR0NdaZ9\nQGW/9UpOm7rKaKgzrQMiRaS6iBQFOgILAlyTygMNtcMY8wfQC1gCbAbmGWN+CWxVgSMic4BVQB0R\nSRKR7oGuyS39mFxZR0dqZR0NtbKOhlpZR0OtrKOhVtbRUHtERE46PyuIyPxc+vYTkRJX+Pz3ikis\n2/aL+nQVkYlXuL/dIhJ+JdsEiob6Cjhn8l0RY8x+Y0yHXLr1A64o1Cp7GmpARKqJyBYRmSUim0Vk\nfvrI6YxQo0RkPfCYiNQUka9F5EcR+V5E6jr9qovIKhFJFJG3LnruTc5yqIiMEZFNIrJRRHqLSB+g\nAhAnInFOv786z7VeRD4Rkeud9tZOneuBR1wc1x3O8/wkIitFpI7fw5VF5DsR2SYir/lt8zcRWSsi\nG0Tk/bz8IgecMeZP/w+oBhjgbmd9GvCis7wbeNmv7zIg0lluDHzrLC8AnnKWewIn/Z57k7PcA5gP\nXOOsl/HbR7izHA6sAK5z1gcCrwLF8J1FGAkIMA+Ivcyx3JveDpT021dL4FNnuStwACgLFAc2AVFA\nPWAhUMTp967fMWXUGOz/rsnD74Gt9hpj4p3lj4E+wBhnfS6AM2I2AT4RkfTtrnV+3g086izPBEZd\nZh8tgcnG95E8xpjLna98J74vKcQ7+yiK7+PqusAuY8w2p5aPgWdzOaYwYIaIROL7pS3i99hSY8xR\n57k+A5oCfwCNgHXOvosDh3LZR9DRUGe6+HwB//VTzs8Q4Lgx5i8unyMvBF/gOmVpFMlunzkZCsQZ\nYx4WkWrAd36PXe54BZhhjHklD/sKGjqnzlRFRO5yljsDP1zcwRiTAuwSkccAxKeB83A8vjP7ALpk\ns4+lwHMico2zfRmnPRW4wVleDdwtIrWcPteJSG1gC1BNRGo6/bKEPhthZJ4+2/Wix1qJSBkRKQ48\n5NS/DOggIhHp9YlIVRf7CSoa6kxbgZ4ishkoDbyXTb8uQHcR+Rn4hcyvfPV1tk8k+2/MTAF+AzY6\n23d22qOBr0UkzhhzGF8A54jIRpyphzHmDL7pxlfOC0U304LRwAgR+YlL/yqvBT4FNuKbaycYY34F\nhgD/dPa9FCjvYj9BRc/Sw/cOBb4XV7cEuBRVAHSkVtbRkVpZR0dqZR0NtbKOhlpZR0OtrKOhVtb5\nf68XP1R2OsY2AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f885d4bb9b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refrences:\n",
    "\n",
    "* [CNN在情感分析上的应用之论文列表 | Sentiment Mining](http://sentiment-mining.blogspot.com/2015/10/cnn.html)\n",
    "* [卷积神经网络(CNN)在句子建模上的应用 | Jey Zhang](http://www.jeyzhang.com/cnn-apply-on-modelling-sentence.html)\n",
    "* [卷积神经网络（CNN）概述及其在NLP中的应用（一） - liuyuemaicha的专栏 - 博客频道 - CSDN.NET](http://blog.csdn.net/liuyuemaicha/article/details/53728242)\n",
    "* [利用TensorFlow实现卷积神经网络做文本分类 - 简书](http://www.jianshu.com/p/ed3eac3dcb39)\n",
    "* [CNN笔记：通俗理解卷积神经网络 - 结构之法 算法之道 - 博客频道 - CSDN.NET](http://blog.csdn.net/v_july_v/article/details/51812459).\n",
    "* [用深度学习（CNN RNN Attention）解决大规模文本分类问题 - 综述和实践 - 知乎专栏](https://zhuanlan.zhihu.com/p/25928551)\n",
    "\n",
    "\n",
    "#### 脚本化：\n",
    "\n",
    "* [coding style - What is the standard Python docstring format? - Stack Overflow](http://stackoverflow.com/questions/3898572/what-is-the-standard-python-docstring-format)\n",
    "* [Example Google Style Python Docstrings — napoleon 0.6.0 documentation](http://sphinxcontrib-napoleon.readthedocs.io/en/latest/example_google.html)\n",
    "* [PEP 257 -- Docstring Conventions | Python.org](https://www.python.org/dev/peps/pep-0257/)\n",
    "* [numpy/numeric.py at master · numpy/numpy](https://github.com/numpy/numpy/blob/master/numpy/core/numeric.py)\n",
    "* [How to write effective Docstrings (Example) | hack.guides()](https://www.pluralsight.com/guides/python/how-to-write-effective-docstrings?status=in-review)\n",
    "\n",
    "\n",
    "#### Stackoverflow\n",
    "\n",
    "* [python - Rank mismatch: Rank of labels (received 2) should equal rank of logits minus 1 (received 2) - Stack Overflow](http://stackoverflow.com/questions/40350849/rank-mismatch-rank-of-labels-received-2-should-equal-rank-of-logits-minus-1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
