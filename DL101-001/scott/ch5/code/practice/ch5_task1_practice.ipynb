{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import operator\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import multiprocessing\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "直接导入之前清理好的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_pickle('data/cleared_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 35124 entries, 0 to 35123\n",
      "Data columns (total 6 columns):\n",
      "review           35124 non-null object\n",
      "sentiment        35124 non-null object\n",
      "cut_words        35124 non-null object\n",
      "cleared_words    35124 non-null object\n",
      "counter          35124 non-null object\n",
      "words_count      35124 non-null int64\n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 1.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def other_multiprocessing(df, func, workers):\n",
    "\n",
    "    chunk_size = int(df.shape[0] / workers)\n",
    "    chunks = (df.ix[df.index[i:i + chunk_size]] for i in range(0, df.shape[0], chunk_size))\n",
    "\n",
    "    pool = multiprocessing.Pool(processes=4)\n",
    "    result = pool.map(func, chunks)\n",
    "    return result\n",
    "\n",
    "\n",
    "def sum_func(d):\n",
    "    return d.counter.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.06 s, sys: 460 ms, total: 2.52 s\n",
      "Wall time: 2min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result = other_multiprocessing(df, sum_func, workers=4)\n",
    "counter_sum = np.sum(np.asarray(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "高频截断，出现次数 10 次以下的词作为 unknown 词，同时用此计算 vocabulary_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d = {i: j for i, j in counter_sum.items() if j > 10}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sorted_dict = sorted(d.items(), key=operator.itemgetter(1), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7920"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary_size = len(sorted_dict)\n",
    "vocabulary_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentences = df.cleared_words.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_dataset(word_counts):\n",
    "    # Build word dictionary\n",
    "    count = [['UNK', -1]]\n",
    "    count.extend(word_counts)\n",
    "    word_dict = {}\n",
    "    for word, _ in count:\n",
    "        word_dict[word] = len(word_dict)\n",
    "\n",
    "    # Build reversed dictionary\n",
    "    reversed_dict = {j: i for i, j in word_dict.items()}\n",
    "\n",
    "    return word_dict, reversed_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_dict, reversed_dict = build_dataset(sorted_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def word_to_number(sentences, word_dict):\n",
    "    # Word to number\n",
    "    data = []\n",
    "    for sentence in sentences:\n",
    "        sentence_data = []\n",
    "        for word in sentence:\n",
    "            if word in word_dict:\n",
    "                index = word_dict[word]\n",
    "            else:\n",
    "                index = 0\n",
    "            sentence_data.append(index)\n",
    "        data.append(sentence_data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = word_to_number(sentences, word_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['word_to_number'] = np.asarray(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 设定数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df[df.words_count > 2]  # 至少能形成一个 windows_size\n",
    "train = df[(df.sentiment == 1) | (df.sentiment == 0)]\n",
    "test  = df[~df.index.isin(train.index)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test['sentiment'] = test.sentiment.map(lambda x: int(x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_data_train = train.word_to_number.values\n",
    "text_data_test = test.word_to_number.values\n",
    "\n",
    "target_train = train.sentiment.values\n",
    "target_test = test.sentiment.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    34051.000000\n",
       "mean        24.038648\n",
       "std         24.401450\n",
       "min          3.000000\n",
       "25%          9.000000\n",
       "50%         16.000000\n",
       "75%         31.000000\n",
       "max        894.000000\n",
       "Name: words_count, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.words_count.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "大部分评论是在 100 字以下，所以为了更好的训练模型，设定句子长度为 100，不足 100 以 0 填充:\n",
    "\n",
    "* 利用 list 相加会合并的特性\n",
    "* array + list 也有上述特性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_words = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_data_train = np.array([x[0:max_words] for x in [y+[0]*max_words for y in text_data_train]])\n",
    "text_data_test = np.array([x[0:max_words] for x in [y+[0]*max_words for y in text_data_test]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  95,  946,   67, ...,    0,    0,    0],\n",
       "       [   1,   81,  279, ...,    0,    0,    0],\n",
       "       [  60,  393,   36, ...,    0,    0,    0],\n",
       "       ..., \n",
       "       [2147,  261,  645, ...,    0,    0,    0],\n",
       "       [1108,   10,  251, ...,    0,    0,    0],\n",
       "       [2460, 1055,  531, ...,    0,    0,    0]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8885"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.randint(0, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23864,)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tst_text_train = ['酒店 不好'.split(),\n",
    "                  '很 失望'.split(),\n",
    "                  '床 好'.split(),\n",
    "                  '非常 棒'.split(),]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tst_text_test = ['棒 棒'.split(),\n",
    "                  '我 失望'.split(),\n",
    "                  '这个 好'.split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tst_target_train = np.array([0, 0, 1, 1]).reshape((4, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tst_text_data_test = word_to_number(tst_text_test, word_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1424, 1424], [0, 137], [0, 0]]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst_text_data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst_target_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tst_text_data_trian = word_to_number(tst_text_train, word_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 51], [0, 137], [347, 0], [14, 1424]]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst_text_data_trian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst_target_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tst_target_data_train = np.zeros(shape=(tst_target_train.shape[0], 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tst_target_data_train[:, 1] = tst_target_train[:, 0]  # 用 2 维的方式表示 (0, 1)，0 -> (1, 0); 1 -> (0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tst_target_data_train[:, 0] = np.where(tst_target_data_train[:, 1]==0, 1, 0)  # 第 2 列跟 1 维表示时是一样的，第 1 列刚好相反"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst_target_data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 定义一个判断 accuracy 的函数\n",
    "def accuracy(preds, labels):\n",
    "    preds = preds[:, 1]  # 是第 2 列判断即可\n",
    "    labels = labels[:, 1]\n",
    "    return ((preds > 0.5) == labels).sum() / float(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1424, 1424], [0, 137], [0, 0]]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst_text_data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tst_target_data_test = np.array([\n",
    "    [0, 1],\n",
    "    [1, 0],\n",
    "    [0, 1],\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst_target_data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_embedding_dim = 128\n",
    "# 决定了词表数量, 预留一个未登录词\n",
    "vocab_size = 7920\n",
    "UNK_IDX = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_embedding = tf.word_embedding = tf.Variable(tf.random_uniform([vocab_size, word_embedding_dim]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_data = tf.placeholder(tf.int32, shape=[None, 2], name='input_data')\n",
    "input_embeds = tf.nn.embedding_lookup(word_embedding, input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'embedding_lookup:0' shape=(?, 2, 128) dtype=float32>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "context_embeds = tf.reduce_sum(input_embeds, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Sum:0' shape=(?, 128) dtype=float32>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_output = tf.layers.dense(context_embeds, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'dense/BiasAdd:0' shape=(?, 2) dtype=float32>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output = tf.nn.softmax(raw_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Softmax:0' shape=(?, 2) dtype=float32>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 样本的 labels 也需要用 placeholder 放置\n",
    "labels = tf.placeholder(tf.int32, shape=[None, 2], name='labels')\n",
    "\n",
    "# 因为我们每个样本的 label 只有一个，使用稠密的 softmax 算 cost 及求导太浪费了。这里使用 sparse 版本即可。\n",
    "# 如果你的 label 是完整的 N 个词上的概率分布，这时候可以使用 tf.nn.softmax_cross_entropy_with_logits\n",
    "# cost = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=raw_output, labels=labels)\n",
    "cost = tf.nn.softmax_cross_entropy_with_logits(logits=raw_output, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0\n",
      "Cost: 1.799619\n",
      "After 0 training step(s), cross entropy on all data is 1.799619, trian accuracy is 0.50, test accuracy is 0.67\n",
      "------\n",
      "Iteration 20\n",
      "Cost: 0.080121\n",
      "After 20 training step(s), cross entropy on all data is 0.080121, trian accuracy is 1.00, test accuracy is 0.67\n",
      "------\n",
      "Iteration 40\n",
      "Cost: 0.041444\n",
      "After 40 training step(s), cross entropy on all data is 0.041444, trian accuracy is 1.00, test accuracy is 0.67\n",
      "------\n",
      "Iteration 60\n",
      "Cost: 0.027410\n",
      "After 60 training step(s), cross entropy on all data is 0.027410, trian accuracy is 1.00, test accuracy is 0.67\n",
      "------\n",
      "Iteration 80\n",
      "Cost: 0.020279\n",
      "After 80 training step(s), cross entropy on all data is 0.020279, trian accuracy is 1.00, test accuracy is 0.67\n",
      "------\n"
     ]
    }
   ],
   "source": [
    "train_step = tf.train.GradientDescentOptimizer(0.01).minimize(cost)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    dummy_feed_dict = {input_data: tst_text_data_trian,\n",
    "                       labels: tst_target_data_train}\n",
    "    for i in range(100):\n",
    "        sess.run(train_step, feed_dict=dummy_feed_dict)\n",
    "        if i % 20 == 0:\n",
    "            print(\"Iteration %d\" % i)\n",
    "            print(\"Cost: %f\" % cost.eval(feed_dict=dummy_feed_dict)[0])\n",
    "            # 查看输出中 ID == 3 的概率\n",
    "            total_cross_entropy = cost.eval(feed_dict=dummy_feed_dict)[0]\n",
    "            output_tst = output.eval(feed_dict=dummy_feed_dict)\n",
    "            output_test = output.eval(feed_dict={input_data: tst_text_data_test})\n",
    "            train_accuracy = accuracy(output_tst, tst_target_data_train) \n",
    "            test_accuracy = accuracy(output_test, tst_target_data_test)\n",
    "            print(\"After %d training step(s), cross entropy on all data is \"\n",
    "                  \"%3f, trian accuracy is %.2f, test accuracy is %.2f\" % (\n",
    "                      i, total_cross_entropy, train_accuracy, test_accuracy))\n",
    "#             print(\"The ouput shape is {}\".format(output.eval(feed_dict=dummy_feed_dict).shape))\n",
    "            print(\"------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.04456415,  0.95543581],\n",
       "       [ 0.95574987,  0.04425012],\n",
       "       [ 0.68150365,  0.31849635]], dtype=float32)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
