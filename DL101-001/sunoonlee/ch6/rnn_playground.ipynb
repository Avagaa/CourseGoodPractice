{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## RNN 语言模型入门探索\n",
    "\n",
    "先试着用简单的例子来学习上手."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPython 3.4.3\n",
      "IPython 5.3.0\n",
      "\n",
      "tensorflow 1.0.1\n",
      "numpy 1.12.0\n",
      "\n",
      "compiler   : GCC 4.8.4\n",
      "system     : Linux\n",
      "release    : 4.9.8-moby\n",
      "machine    : x86_64\n",
      "processor  : x86_64\n",
      "CPU cores  : 4\n",
      "interpreter: 64bit\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -p tensorflow,numpy -v -m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 1. RNN 定长输入的简单例子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "vocab_size = 20\n",
    "word_embedding_dim = 15\n",
    "num_units = 10\n",
    "sentence_len = 5\n",
    "batch_size = 2\n",
    "\n",
    "tf.reset_default_graph()\n",
    "cell = tf.contrib.rnn.BasicRNNCell(num_units)  # bacis rnn cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### 简单制造一点语料数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 3 5 7]\n",
      " [8 4 2 6]] \n",
      " [[3 5 7 1]\n",
      " [4 2 6 1]]\n"
     ]
    }
   ],
   "source": [
    "# 人为制造两个等长句子数据, shape = [batch_size, sentence_len]\n",
    "data = np.asarray(\n",
    "    [[2, 3, 5, 7, 1], \n",
    "     [8, 4, 2, 6, 1]])\n",
    "\n",
    "inputs_train = data[:, :-1]\n",
    "labels_train = data[:, 1:]\n",
    "print(inputs_train, '\\n', labels_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### 构建 RNN 神经网络\n",
    "\n",
    "word_ids -> word embedding -> rnn outputs -> sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Reshape:0' shape=(8,) dtype=int32>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_embedding = tf.Variable(tf.random_uniform([vocab_size, word_embedding_dim]))\n",
    "\n",
    "inputs = tf.placeholder(tf.int32, shape=[batch_size, sentence_len - 1], name='inputs')\n",
    "labels = tf.placeholder(tf.int32, shape=[batch_size, sentence_len - 1], name='labels')\n",
    "labels_flat = tf.reshape(labels, (-1,))\n",
    "labels_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'embedding_lookup:0' shape=(2, 4, 15) dtype=float32>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_embeds = tf.nn.embedding_lookup(word_embedding, inputs)\n",
    "input_embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor 'rnn/transpose:0' shape=(2, 4, 10) dtype=float32>,\n",
       " <tf.Tensor 'Reshape_1:0' shape=(8, 10) dtype=float32>,\n",
       " <tf.Tensor 'rnn/while/Exit_2:0' shape=(?, 10) dtype=float32>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output, states = tf.nn.dynamic_rnn(cell, input_embeds, dtype=tf.float32)  # tf.nn.dynamic_rnn 可实现多步计算\n",
    "output_flat = tf.reshape(output, (-1, num_units))\n",
    "output, output_flat, states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "softmax_w = tf.Variable(tf.random_uniform([num_units, vocab_size]))\n",
    "softmax_b = tf.Variable(tf.random_uniform([vocab_size]))\n",
    "\n",
    "logits_flat = tf.matmul(output_flat, softmax_w) + softmax_b\n",
    "probs_flat = tf.sigmoid(logits_flat)\n",
    "probs = tf.reshape(probs_flat, (batch_size, sentence_len - 1, -1))\n",
    "preds = tf.argmax(probs, axis=2)\n",
    "\n",
    "losses = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits_flat, labels=labels_flat)\n",
    "loss = tf.reduce_mean(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0: cost = 2.8206260204315186\n",
      "epoch 1: cost = 2.611342430114746\n",
      "epoch 2: cost = 2.444389820098877\n",
      "epoch 3: cost = 2.311234474182129\n",
      "epoch 4: cost = 2.1996729373931885\n",
      "epoch 5: cost = 2.099348306655884\n",
      "epoch 6: cost = 2.004868268966675\n",
      "epoch 7: cost = 1.9141072034835815\n",
      "epoch 8: cost = 1.826167345046997\n",
      "epoch 9: cost = 1.7404463291168213\n",
      "epoch 10: cost = 1.6564154624938965\n",
      "epoch 11: cost = 1.5736474990844727\n",
      "epoch 12: cost = 1.4918718338012695\n",
      "epoch 13: cost = 1.4110069274902344\n",
      "epoch 14: cost = 1.3311593532562256\n",
      "epoch 15: cost = 1.2525956630706787\n",
      "epoch 16: cost = 1.1756908893585205\n",
      "epoch 17: cost = 1.100874423980713\n",
      "epoch 18: cost = 1.0285818576812744\n",
      "epoch 19: cost = 0.9592243432998657\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.3\n",
    "epochs = 20\n",
    "\n",
    "train_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n",
    "batch_feed = {inputs: inputs_train, labels: labels_train}\n",
    "loss_history1 = []\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(epochs):\n",
    "        sess.run(train_step, feed_dict=batch_feed)\n",
    "        loss_val = sess.run(loss, feed_dict=batch_feed)\n",
    "        loss_history1.append(loss_val)\n",
    "        print('epoch {}: cost = {}'.format(i, loss_val))\n",
    "    \n",
    "    preds_val = sess.run(preds, feed_dict={inputs: inputs_train})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### 检查模型准确性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True]], dtype=bool)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_val == labels_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 2. RNN 变长输入的简单例子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "vocab_size = 20\n",
    "word_embedding_dim = 15\n",
    "num_units = 10\n",
    "sentence_len = 8\n",
    "batch_size = 2\n",
    "\n",
    "tf.reset_default_graph()\n",
    "cell = tf.contrib.rnn.BasicRNNCell(num_units)  # bacis rnn cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### \"制造\"语料数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 3 5 7 2 4 6]\n",
      " [2 4 2 6 1 0 0]] \n",
      " [[3 5 7 2 4 6 1]\n",
      " [4 2 6 1 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# 人为制造两个句子数据, 句子长度分别为 8, 5. 第二个句子补了3个padding\n",
    "data = np.asarray(\n",
    "    [[1, 3, 5, 7, 2, 4, 6, 1], \n",
    "     [2, 4, 2, 6, 1, 0, 0, 0]])\n",
    "\n",
    "inputs_train = data[:, :-1]\n",
    "labels_train = data[:, 1:]\n",
    "print(inputs_train, '\\n', labels_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### 搭建 RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "word_embedding = tf.Variable(tf.random_uniform([vocab_size, word_embedding_dim]))\n",
    "\n",
    "inputs = tf.placeholder(tf.int32, shape=[batch_size, sentence_len - 1], name='inputs')\n",
    "labels = tf.placeholder(tf.int32, shape=[batch_size, sentence_len - 1], name='labels')\n",
    "labels_flat = tf.reshape(labels, (-1,))\n",
    "\n",
    "input_embeds = tf.nn.embedding_lookup(word_embedding, inputs)\n",
    "\n",
    "output, states = tf.nn.dynamic_rnn(cell, input_embeds, dtype=tf.float32, sequence_length=[8, 5])\n",
    "output_flat = tf.reshape(output, (-1, num_units))\n",
    "\n",
    "softmax_w = tf.Variable(tf.random_uniform([num_units, vocab_size]))\n",
    "softmax_b = tf.Variable(tf.random_uniform([vocab_size]))\n",
    "\n",
    "logits_flat = tf.matmul(output_flat, softmax_w) + softmax_b\n",
    "probs_flat = tf.sigmoid(logits_flat)\n",
    "probs = tf.reshape(probs_flat, (batch_size, sentence_len - 1, -1))\n",
    "preds = tf.argmax(probs, axis=2)\n",
    "\n",
    "losses = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits_flat, labels=labels_flat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### 用 mask 来修正 loss 函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  0.], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = tf.cast(tf.sign(labels_flat), tf.float32)\n",
    "with tf.Session() as sess:\n",
    "    mask_val = sess.run(mask, feed_dict={labels: labels_train})\n",
    "mask_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "loss2 = tf.reduce_sum(losses * mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0: cost = 27.346179962158203\n",
      "epoch 1: cost = 23.194448471069336\n",
      "epoch 2: cost = 20.332326889038086\n",
      "epoch 3: cost = 17.682546615600586\n",
      "epoch 4: cost = 15.473355293273926\n",
      "epoch 5: cost = 13.398550987243652\n",
      "epoch 6: cost = 11.77105712890625\n",
      "epoch 7: cost = 9.906399726867676\n",
      "epoch 8: cost = 8.594326972961426\n",
      "epoch 9: cost = 7.438560485839844\n",
      "epoch 10: cost = 6.5897016525268555\n",
      "epoch 11: cost = 5.872864246368408\n",
      "epoch 12: cost = 5.252179145812988\n",
      "epoch 13: cost = 4.671937942504883\n",
      "epoch 14: cost = 4.158555507659912\n",
      "epoch 15: cost = 3.7934341430664062\n",
      "epoch 16: cost = 3.847944974899292\n",
      "epoch 17: cost = 4.744208812713623\n",
      "epoch 18: cost = 3.473471164703369\n",
      "epoch 19: cost = 2.7029590606689453\n",
      "epoch 20: cost = 2.2751803398132324\n",
      "epoch 21: cost = 2.0305259227752686\n",
      "epoch 22: cost = 1.8455851078033447\n",
      "epoch 23: cost = 1.6901209354400635\n",
      "epoch 24: cost = 1.5549675226211548\n",
      "epoch 25: cost = 1.4360249042510986\n",
      "epoch 26: cost = 1.3308978080749512\n",
      "epoch 27: cost = 1.2376933097839355\n",
      "epoch 28: cost = 1.1547962427139282\n",
      "epoch 29: cost = 1.0808162689208984\n",
      "epoch 30: cost = 1.01455557346344\n",
      "epoch 31: cost = 0.9549870491027832\n",
      "epoch 32: cost = 0.9012356996536255\n",
      "epoch 33: cost = 0.8525553941726685\n",
      "epoch 34: cost = 0.8083103895187378\n",
      "epoch 35: cost = 0.7679592370986938\n",
      "epoch 36: cost = 0.7310410737991333\n",
      "epoch 37: cost = 0.6971584558486938\n",
      "epoch 38: cost = 0.6659721732139587\n",
      "epoch 39: cost = 0.6371891498565674\n",
      "epoch 40: cost = 0.6105565428733826\n",
      "epoch 41: cost = 0.5858539342880249\n",
      "epoch 42: cost = 0.5628901720046997\n",
      "epoch 43: cost = 0.5414960384368896\n",
      "epoch 44: cost = 0.521526575088501\n",
      "epoch 45: cost = 0.5028496384620667\n",
      "epoch 46: cost = 0.48535269498825073\n",
      "epoch 47: cost = 0.46893322467803955\n",
      "epoch 48: cost = 0.4535004794597626\n",
      "epoch 49: cost = 0.4389723539352417\n",
      "epoch 50: cost = 0.4252777695655823\n",
      "epoch 51: cost = 0.4123491048812866\n",
      "epoch 52: cost = 0.400129497051239\n",
      "epoch 53: cost = 0.3885633945465088\n",
      "epoch 54: cost = 0.37760263681411743\n",
      "epoch 55: cost = 0.3672043979167938\n",
      "epoch 56: cost = 0.35732734203338623\n",
      "epoch 57: cost = 0.3479347229003906\n",
      "epoch 58: cost = 0.338992714881897\n",
      "epoch 59: cost = 0.33047226071357727\n",
      "epoch 60: cost = 0.3223435878753662\n",
      "epoch 61: cost = 0.3145815134048462\n",
      "epoch 62: cost = 0.3071622848510742\n",
      "epoch 63: cost = 0.3000643253326416\n",
      "epoch 64: cost = 0.29326698184013367\n",
      "epoch 65: cost = 0.2867509424686432\n",
      "epoch 66: cost = 0.28050023317337036\n",
      "epoch 67: cost = 0.27449890971183777\n",
      "epoch 68: cost = 0.26873236894607544\n",
      "epoch 69: cost = 0.2631862759590149\n",
      "epoch 70: cost = 0.25784850120544434\n",
      "epoch 71: cost = 0.25270646810531616\n",
      "epoch 72: cost = 0.24775049090385437\n",
      "epoch 73: cost = 0.24296890199184418\n",
      "epoch 74: cost = 0.2383536994457245\n",
      "epoch 75: cost = 0.2338956892490387\n",
      "epoch 76: cost = 0.2295866161584854\n",
      "epoch 77: cost = 0.2254176139831543\n",
      "epoch 78: cost = 0.2213830053806305\n",
      "epoch 79: cost = 0.21747547388076782\n",
      "epoch 80: cost = 0.21368850767612457\n",
      "epoch 81: cost = 0.21001684665679932\n",
      "epoch 82: cost = 0.20645397901535034\n",
      "epoch 83: cost = 0.20299600064754486\n",
      "epoch 84: cost = 0.19963757693767548\n",
      "epoch 85: cost = 0.19637326896190643\n",
      "epoch 86: cost = 0.1932000070810318\n",
      "epoch 87: cost = 0.19011308252811432\n",
      "epoch 88: cost = 0.18711009621620178\n",
      "epoch 89: cost = 0.18418589234352112\n",
      "epoch 90: cost = 0.18133802711963654\n",
      "epoch 91: cost = 0.17856377363204956\n",
      "epoch 92: cost = 0.17585957050323486\n",
      "epoch 93: cost = 0.1732231080532074\n",
      "epoch 94: cost = 0.17065301537513733\n",
      "epoch 95: cost = 0.16814540326595306\n",
      "epoch 96: cost = 0.16569861769676208\n",
      "epoch 97: cost = 0.16331133246421814\n",
      "epoch 98: cost = 0.16098123788833618\n",
      "epoch 99: cost = 0.15870612859725952\n",
      "epoch 100: cost = 0.15648452937602997\n",
      "epoch 101: cost = 0.1543152928352356\n",
      "epoch 102: cost = 0.15219737589359283\n",
      "epoch 103: cost = 0.1501275599002838\n",
      "epoch 104: cost = 0.14810702204704285\n",
      "epoch 105: cost = 0.14613226056098938\n",
      "epoch 106: cost = 0.1442030966281891\n",
      "epoch 107: cost = 0.1423180103302002\n",
      "epoch 108: cost = 0.14047689735889435\n",
      "epoch 109: cost = 0.1386772245168686\n",
      "epoch 110: cost = 0.13691921532154083\n",
      "epoch 111: cost = 0.13520032167434692\n",
      "epoch 112: cost = 0.1335202306509018\n",
      "epoch 113: cost = 0.1318792700767517\n",
      "epoch 114: cost = 0.13027361035346985\n",
      "epoch 115: cost = 0.12870371341705322\n",
      "epoch 116: cost = 0.12717045843601227\n",
      "epoch 117: cost = 0.125669926404953\n",
      "epoch 118: cost = 0.12420286238193512\n",
      "epoch 119: cost = 0.12276716530323029\n",
      "epoch 120: cost = 0.1213626116514206\n",
      "epoch 121: cost = 0.1199900358915329\n",
      "epoch 122: cost = 0.1186455637216568\n",
      "epoch 123: cost = 0.11733025312423706\n",
      "epoch 124: cost = 0.11604330688714981\n",
      "epoch 125: cost = 0.11478248238563538\n",
      "epoch 126: cost = 0.11354933679103851\n",
      "epoch 127: cost = 0.11234115809202194\n",
      "epoch 128: cost = 0.11115795373916626\n",
      "epoch 129: cost = 0.10999809205532074\n",
      "epoch 130: cost = 0.10886333882808685\n",
      "epoch 131: cost = 0.107749804854393\n",
      "epoch 132: cost = 0.10665997862815857\n",
      "epoch 133: cost = 0.10559046268463135\n",
      "epoch 134: cost = 0.10454241931438446\n",
      "epoch 135: cost = 0.10351456701755524\n",
      "epoch 136: cost = 0.10250644385814667\n",
      "epoch 137: cost = 0.1015181690454483\n",
      "epoch 138: cost = 0.10054808855056763\n",
      "epoch 139: cost = 0.09959621727466583\n",
      "epoch 140: cost = 0.09866256266832352\n",
      "epoch 141: cost = 0.09774582087993622\n",
      "epoch 142: cost = 0.09684588015079498\n",
      "epoch 143: cost = 0.09596312046051025\n",
      "epoch 144: cost = 0.09509431570768356\n",
      "epoch 145: cost = 0.09424315392971039\n",
      "epoch 146: cost = 0.09340551495552063\n",
      "epoch 147: cost = 0.09258316457271576\n",
      "epoch 148: cost = 0.09177515655755997\n",
      "epoch 149: cost = 0.09098173677921295\n",
      "epoch 150: cost = 0.09020018577575684\n",
      "epoch 151: cost = 0.08943334221839905\n",
      "epoch 152: cost = 0.08867837488651276\n",
      "epoch 153: cost = 0.08793731033802032\n",
      "epoch 154: cost = 0.08720764517784119\n",
      "epoch 155: cost = 0.08648999035358429\n",
      "epoch 156: cost = 0.08578409999608994\n",
      "epoch 157: cost = 0.08508963137865067\n",
      "epoch 158: cost = 0.08440610766410828\n",
      "epoch 159: cost = 0.08373375982046127\n",
      "epoch 160: cost = 0.08307261019945145\n",
      "epoch 161: cost = 0.08242052048444748\n",
      "epoch 162: cost = 0.08177962899208069\n",
      "epoch 163: cost = 0.08114778995513916\n",
      "epoch 164: cost = 0.080526202917099\n",
      "epoch 165: cost = 0.07991333305835724\n",
      "epoch 166: cost = 0.0793105959892273\n",
      "epoch 167: cost = 0.07871657609939575\n",
      "epoch 168: cost = 0.07813163101673126\n",
      "epoch 169: cost = 0.07755446434020996\n",
      "epoch 170: cost = 0.07698601484298706\n",
      "epoch 171: cost = 0.07642640173435211\n",
      "epoch 172: cost = 0.0758742243051529\n",
      "epoch 173: cost = 0.07533028721809387\n",
      "epoch 174: cost = 0.07479437440633774\n",
      "epoch 175: cost = 0.07426493614912033\n",
      "epoch 176: cost = 0.07374387234449387\n",
      "epoch 177: cost = 0.07322976738214493\n",
      "epoch 178: cost = 0.07272285968065262\n",
      "epoch 179: cost = 0.07222266495227814\n",
      "epoch 180: cost = 0.07172919809818268\n",
      "epoch 181: cost = 0.0712432786822319\n",
      "epoch 182: cost = 0.07076337933540344\n",
      "epoch 183: cost = 0.07028937339782715\n",
      "epoch 184: cost = 0.06982232630252838\n",
      "epoch 185: cost = 0.06936106085777283\n",
      "epoch 186: cost = 0.06890556961297989\n",
      "epoch 187: cost = 0.06845693290233612\n",
      "epoch 188: cost = 0.06801313161849976\n",
      "epoch 189: cost = 0.06757546961307526\n",
      "epoch 190: cost = 0.06714347004890442\n",
      "epoch 191: cost = 0.06671701371669769\n",
      "epoch 192: cost = 0.06629528105258942\n",
      "epoch 193: cost = 0.06587909162044525\n",
      "epoch 194: cost = 0.0654686987400055\n",
      "epoch 195: cost = 0.06506243348121643\n",
      "epoch 196: cost = 0.06466171145439148\n",
      "epoch 197: cost = 0.06426618993282318\n",
      "epoch 198: cost = 0.06387491524219513\n",
      "epoch 199: cost = 0.06348848342895508\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.1\n",
    "epochs = 200\n",
    "\n",
    "train_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss2)\n",
    "batch_feed = {inputs: inputs_train, labels: labels_train}\n",
    "loss_history2 = []\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(epochs):\n",
    "        sess.run(train_step, feed_dict=batch_feed)\n",
    "        loss_val = sess.run(loss2, feed_dict=batch_feed)\n",
    "        loss_history2.append(loss_val)\n",
    "        print('epoch {}: cost = {}'.format(i, loss_val))\n",
    "    \n",
    "    preds_val = sess.run(preds, feed_dict={inputs: inputs_train})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### 检查模型准确性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 5, 7, 2, 4, 6, 1],\n",
       "       [4, 2, 6, 1, 3, 6, 6]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True,  True,  True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True, False, False, False]], dtype=bool)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_val == labels_train"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
